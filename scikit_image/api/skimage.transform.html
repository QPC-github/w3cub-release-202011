
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Transform - Scikit-image - W3cubDocs</title>
  
  <meta name="description" content=" Perform a circular Hough transform. ">
  <meta name="keywords" content="module, transform, scikit-image, scikit_image">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_image/api/skimage.transform.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/scikit_image.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_image/" class="_nav-link" title="" style="margin-left:0;">scikit-image</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="module-transform">Module: transform</h1> <table class="longtable docutils" id="module-skimage.transform">   <tr>
<td>
<a class="reference internal" href="#skimage.transform.hough_circle" title="skimage.transform.hough_circle"><code>skimage.transform.hough_circle</code></a>(image, radius)</td> <td>Perform a circular Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.hough_ellipse" title="skimage.transform.hough_ellipse"><code>skimage.transform.hough_ellipse</code></a>(image[, …])</td> <td>Perform an elliptical Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.hough_line" title="skimage.transform.hough_line"><code>skimage.transform.hough_line</code></a>(image[, theta])</td> <td>Perform a straight line Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.probabilistic_hough_line" title="skimage.transform.probabilistic_hough_line"><code>skimage.transform.probabilistic_hough_line</code></a>(image)</td> <td>Return lines from a progressive probabilistic line Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.hough_circle_peaks" title="skimage.transform.hough_circle_peaks"><code>skimage.transform.hough_circle_peaks</code></a>(…[, …])</td> <td>Return peaks in a circle Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.hough_line_peaks" title="skimage.transform.hough_line_peaks"><code>skimage.transform.hough_line_peaks</code></a>(hspace, …)</td> <td>Return peaks in a straight line Hough transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.radon" title="skimage.transform.radon"><code>skimage.transform.radon</code></a>(image[, theta, circle])</td> <td>Calculates the radon transform of an image given specified projection angles.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.iradon" title="skimage.transform.iradon"><code>skimage.transform.iradon</code></a>(radon_image[, …])</td> <td>Inverse radon transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.iradon_sart" title="skimage.transform.iradon_sart"><code>skimage.transform.iradon_sart</code></a>(radon_image[, …])</td> <td>Inverse radon transform</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.order_angles_golden_ratio" title="skimage.transform.order_angles_golden_ratio"><code>skimage.transform.order_angles_golden_ratio</code></a>(theta)</td> <td>Order angles to reduce the amount of correlated information in subsequent projections.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.frt2" title="skimage.transform.frt2"><code>skimage.transform.frt2</code></a>(a)</td> <td>Compute the 2-dimensional finite radon transform (FRT) for an n x n integer array.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.ifrt2" title="skimage.transform.ifrt2"><code>skimage.transform.ifrt2</code></a>(a)</td> <td>Compute the 2-dimensional inverse finite radon transform (iFRT) for an (n+1) x n integer array.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.integral_image" title="skimage.transform.integral_image"><code>skimage.transform.integral_image</code></a>(image)</td> <td>Integral image / summed area table.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.integrate" title="skimage.transform.integrate"><code>skimage.transform.integrate</code></a>(ii, start, end)</td> <td>Use an integral image to integrate over a given window.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.warp" title="skimage.transform.warp"><code>skimage.transform.warp</code></a>(image, inverse_map[, …])</td> <td>Warp an image according to a given coordinate transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.warp_coords" title="skimage.transform.warp_coords"><code>skimage.transform.warp_coords</code></a>(coord_map, shape)</td> <td>Build the source coordinates for the output of a 2-D image warp.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.estimate_transform" title="skimage.transform.estimate_transform"><code>skimage.transform.estimate_transform</code></a>(ttype, …)</td> <td>Estimate 2D geometric transformation parameters.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.matrix_transform" title="skimage.transform.matrix_transform"><code>skimage.transform.matrix_transform</code></a>(coords, …)</td> <td>Apply 2D matrix transform.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.swirl" title="skimage.transform.swirl"><code>skimage.transform.swirl</code></a>(image[, center, …])</td> <td>Perform a swirl transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.resize" title="skimage.transform.resize"><code>skimage.transform.resize</code></a>(image, output_shape)</td> <td>Resize image to match a certain size.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.rotate" title="skimage.transform.rotate"><code>skimage.transform.rotate</code></a>(image, angle[, …])</td> <td>Rotate image by a certain angle around its center.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.rescale" title="skimage.transform.rescale"><code>skimage.transform.rescale</code></a>(image, scale[, …])</td> <td>Scale image by a certain factor.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.downscale_local_mean" title="skimage.transform.downscale_local_mean"><code>skimage.transform.downscale_local_mean</code></a>(…)</td> <td>Down-sample N-dimensional image by local averaging.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.pyramid_reduce" title="skimage.transform.pyramid_reduce"><code>skimage.transform.pyramid_reduce</code></a>(image[, …])</td> <td>Smooth and then downsample image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.pyramid_expand" title="skimage.transform.pyramid_expand"><code>skimage.transform.pyramid_expand</code></a>(image[, …])</td> <td>Upsample and then smooth image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.pyramid_gaussian" title="skimage.transform.pyramid_gaussian"><code>skimage.transform.pyramid_gaussian</code></a>(image[, …])</td> <td>Yield images of the Gaussian pyramid formed by the input image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.pyramid_laplacian" title="skimage.transform.pyramid_laplacian"><code>skimage.transform.pyramid_laplacian</code></a>(image[, …])</td> <td>Yield images of the laplacian pyramid formed by the input image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.seam_carve" title="skimage.transform.seam_carve"><code>skimage.transform.seam_carve</code></a>(image, …[, …])</td> <td>Carve vertical or horizontal seams off an image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.EuclideanTransform" title="skimage.transform.EuclideanTransform"><code>skimage.transform.EuclideanTransform</code></a>([…])</td> <td>2D Euclidean transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.SimilarityTransform" title="skimage.transform.SimilarityTransform"><code>skimage.transform.SimilarityTransform</code></a>([…])</td> <td>2D similarity transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.AffineTransform" title="skimage.transform.AffineTransform"><code>skimage.transform.AffineTransform</code></a>([matrix, …])</td> <td>2D affine transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.ProjectiveTransform" title="skimage.transform.ProjectiveTransform"><code>skimage.transform.ProjectiveTransform</code></a>([matrix])</td> <td>Projective transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.EssentialMatrixTransform" title="skimage.transform.EssentialMatrixTransform"><code>skimage.transform.EssentialMatrixTransform</code></a>([…])</td> <td>Essential matrix transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.FundamentalMatrixTransform" title="skimage.transform.FundamentalMatrixTransform"><code>skimage.transform.FundamentalMatrixTransform</code></a>([…])</td> <td>Fundamental matrix transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.PolynomialTransform" title="skimage.transform.PolynomialTransform"><code>skimage.transform.PolynomialTransform</code></a>([params])</td> <td>2D polynomial transformation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.transform.PiecewiseAffineTransform" title="skimage.transform.PiecewiseAffineTransform"><code>skimage.transform.PiecewiseAffineTransform</code></a>()</td> <td>2D piecewise affine transformation.</td> </tr>  </table>  <h2 id="hough-circle">hough_circle</h2> <dl class="function"> <dt id="skimage.transform.hough_circle">
<code>skimage.transform.hough_circle(image, radius, normalize=True, full_output=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L70"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform a circular Hough transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (M, N) ndarray</code> </dt> <dd>
<p class="first last">Input image with nonzero values representing edges.</p> </dd> <dt>
<code>radius : scalar or sequence of scalars</code> </dt> <dd>
<p class="first last">Radii at which to compute the Hough transform. Floats are converted to integers.</p> </dd> <dt>
<code>normalize : boolean, optional (default True)</code> </dt> <dd>
<p class="first last">Normalize the accumulator with the number of pixels used to draw the radius.</p> </dd> <dt>
<code>full_output : boolean, optional (default False)</code> </dt> <dd>
<p class="first last">Extend the output size by twice the largest radius in order to detect centers outside the input picture.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>H : 3D ndarray (radius index, (M + 2R, N + 2R) ndarray)</code> </dt> <dd>
<p class="first last">Hough transform accumulator for each radius. R designates the larger radius if full_output is True. Otherwise, R = 0.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import hough_circle
&gt;&gt;&gt; from skimage.draw import circle_perimeter
&gt;&gt;&gt; img = np.zeros((100, 100), dtype=np.bool_)
&gt;&gt;&gt; rr, cc = circle_perimeter(25, 35, 23)
&gt;&gt;&gt; img[rr, cc] = 1
&gt;&gt;&gt; try_radii = np.arange(5, 50)
&gt;&gt;&gt; res = hough_circle(img, try_radii)
&gt;&gt;&gt; ridx, r, c = np.unravel_index(np.argmax(res), res.shape)
&gt;&gt;&gt; r, c, try_radii[ridx]
(25, 35, 23)
</pre> </dd>
</dl>   <h2 id="hough-ellipse">hough_ellipse</h2> <dl class="function"> <dt id="skimage.transform.hough_ellipse">
<code>skimage.transform.hough_ellipse(image, threshold=4, accuracy=1, min_size=4, max_size=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L114"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform an elliptical Hough transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (M, N) ndarray</code> </dt> <dd>
<p class="first last">Input image with nonzero values representing edges.</p> </dd> <dt><strong>threshold: int, optional</strong></dt> <dd>
<p class="first last">Accumulator threshold value.</p> </dd> <dt>
<code>accuracy : double, optional</code> </dt> <dd>
<p class="first last">Bin size on the minor axis used in the accumulator.</p> </dd> <dt>
<code>min_size : int, optional</code> </dt> <dd>
<p class="first last">Minimal major axis length.</p> </dd> <dt>
<code>max_size : int, optional</code> </dt> <dd>
<p class="first last">Maximal minor axis length. If None, the value is set to the half of the smaller image dimension.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>result : ndarray with fields [(accumulator, yc, xc, a, b, orientation)].</code> </dt> <dd>
<p class="first last">Where <code>(yc, xc)</code> is the center, <code>(a, b)</code> the major and minor axes, respectively. The <code>orientation</code> value follows <code>skimage.draw.ellipse_perimeter</code> convention.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The accuracy must be chosen to produce a peak in the accumulator distribution. In other words, a flat accumulator distribution with low values may be caused by a too low bin size.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rf2ef66e2ec1f-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id1">[1]</a></td>
<td>Xie, Yonghong, and Qiang Ji. “A new efficient ellipse detection method.” Pattern Recognition, 2002. Proceedings. 16th International Conference on. Vol. 2. IEEE, 2002</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import hough_ellipse
&gt;&gt;&gt; from skimage.draw import ellipse_perimeter
&gt;&gt;&gt; img = np.zeros((25, 25), dtype=np.uint8)
&gt;&gt;&gt; rr, cc = ellipse_perimeter(10, 10, 6, 8)
&gt;&gt;&gt; img[cc, rr] = 1
&gt;&gt;&gt; result = hough_ellipse(img, threshold=8)
&gt;&gt;&gt; result.tolist()
[(10, 10.0, 10.0, 8.0, 6.0, 0.0)]
</pre> </dd>
</dl>   <h2 id="hough-line">hough_line</h2> <dl class="function"> <dt id="skimage.transform.hough_line">
<code>skimage.transform.hough_line(image, theta=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L166"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform a straight line Hough transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (M, N) ndarray</code> </dt> <dd>
<p class="first last">Input image with nonzero values representing edges.</p> </dd> <dt>
<code>theta : 1D ndarray of double, optional</code> </dt> <dd>
<p class="first last">Angles at which to compute the transform, in radians. Defaults to a vector of 180 angles evenly spaced from -pi/2 to pi/2.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>hspace : 2-D ndarray of uint64</code> </dt> <dd>
<p class="first last">Hough transform accumulator.</p> </dd> <dt>
<code>angles : ndarray</code> </dt> <dd>
<p class="first last">Angles at which the transform is computed, in radians.</p> </dd> <dt>
<code>distances : ndarray</code> </dt> <dd>
<p class="first last">Distance values.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The origin is the top left corner of the original image. X and Y axis are horizontal and vertical edges respectively. The distance is the minimal algebraic distance from the origin to the detected line. The angle accuracy can be improved by decreasing the step size in the <code>theta</code> array.</p> <h4 class="rubric">Examples</h4> <p>Generate a test image:</p> <pre data-language="python">&gt;&gt;&gt; img = np.zeros((100, 150), dtype=bool)
&gt;&gt;&gt; img[30, :] = 1
&gt;&gt;&gt; img[:, 65] = 1
&gt;&gt;&gt; img[35:45, 35:50] = 1
&gt;&gt;&gt; for i in range(90):
...     img[i, i] = 1
&gt;&gt;&gt; img += np.random.random(img.shape) &gt; 0.95
</pre> <p>Apply the Hough transform:</p> <pre data-language="python">&gt;&gt;&gt; out, angles, d = hough_line(img)
</pre> <pre data-language="python">import numpy as np
import matplotlib.pyplot as plt

from skimage.transform import hough_line
from skimage.draw import line

img = np.zeros((100, 150), dtype=bool)
img[30, :] = 1
img[:, 65] = 1
img[35:45, 35:50] = 1
rr, cc = line(60, 130, 80, 10)
img[rr, cc] = 1
img += np.random.random(img.shape) &gt; 0.95

out, angles, d = hough_line(img)

fix, axes = plt.subplots(1, 2, figsize=(7, 4))

axes[0].imshow(img, cmap=plt.cm.gray)
axes[0].set_title('Input image')

axes[1].imshow(
    out, cmap=plt.cm.bone,
    extent=(np.rad2deg(angles[-1]), np.rad2deg(angles[0]), d[-1], d[0]))
axes[1].set_title('Hough transform')
axes[1].set_xlabel('Angle (degree)')
axes[1].set_ylabel('Distance (pixel)')

plt.tight_layout()
plt.show()
</pre> <p>(<a class="reference external" href="http://scikit-image.org/docs/0.14.x/plots/hough_tf.py">Source code</a>, <a class="reference external" href="http://scikit-image.org/docs/0.14.x/plots/hough_tf.png">png</a>, <a class="reference external" href="http://scikit-image.org/docs/0.14.x/plots/hough_tf.pdf">pdf</a>)</p> <div class="figure"> <img alt="../_images/hough_tf.png" src="data:image/png;base64,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"> </div> </dd>
</dl>   <h2 id="probabilistic-hough-line">probabilistic_hough_line</h2> <dl class="function"> <dt id="skimage.transform.probabilistic_hough_line">
<code>skimage.transform.probabilistic_hough_line(image, threshold=10, line_length=50, line_gap=10, theta=None, seed=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L224"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return lines from a progressive probabilistic line Hough transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (M, N) ndarray</code> </dt> <dd>
<p class="first last">Input image with nonzero values representing edges.</p> </dd> <dt>
<code>threshold : int, optional</code> </dt> <dd>
<p class="first last">Threshold</p> </dd> <dt>
<code>line_length : int, optional</code> </dt> <dd>
<p class="first last">Minimum accepted length of detected lines. Increase the parameter to extract longer lines.</p> </dd> <dt>
<code>line_gap : int, optional</code> </dt> <dd>
<p class="first last">Maximum gap between pixels to still form a line. Increase the parameter to merge broken lines more aggresively.</p> </dd> <dt>
<code>theta : 1D ndarray, dtype=double, optional</code> </dt> <dd>
<p class="first last">Angles at which to compute the transform, in radians. If None, use a range from -pi/2 to pi/2.</p> </dd> <dt>
<code>seed : int, optional</code> </dt> <dd>
<p class="first last">Seed to initialize the random number generator.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>lines : list</code> </dt> <dd>
<p class="first last">List of lines identified, lines in format ((x0, y0), (x1, y1)), indicating line start and end.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rd9a46cdb16bc-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id2">[1]</a></td>
<td>C. Galamhos, J. Matas and J. Kittler, “Progressive probabilistic Hough transform for line detection”, in IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1999.</td>
</tr>  </table> </dd>
</dl>   <h2 id="hough-circle-peaks">hough_circle_peaks</h2> <dl class="function"> <dt id="skimage.transform.hough_circle_peaks">
<code>skimage.transform.hough_circle_peaks(hspaces, radii, min_xdistance=1, min_ydistance=1, threshold=None, num_peaks=inf, total_num_peaks=inf, normalize=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L269"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return peaks in a circle Hough transform.</p> <p>Identifies most prominent circles separated by certain distances in a Hough space. Non-maximum suppression with different sizes is applied separately in the first and second dimension of the Hough space to identify peaks.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>hspaces : (N, M) array</code> </dt> <dd>
<p class="first last">Hough spaces returned by the <code>hough_circle</code> function.</p> </dd> <dt>
<code>radii : (M,) array</code> </dt> <dd>
<p class="first last">Radii corresponding to Hough spaces.</p> </dd> <dt>
<code>min_xdistance : int, optional</code> </dt> <dd>
<p class="first last">Minimum distance separating centers in the x dimension.</p> </dd> <dt>
<code>min_ydistance : int, optional</code> </dt> <dd>
<p class="first last">Minimum distance separating centers in the y dimension.</p> </dd> <dt>
<code>threshold : float, optional</code> </dt> <dd>
<p class="first last">Minimum intensity of peaks in each Hough space. Default is <code>0.5 * max(hspace)</code>.</p> </dd> <dt>
<code>num_peaks : int, optional</code> </dt> <dd>
<p class="first last">Maximum number of peaks in each Hough space. When the number of peaks exceeds <code>num_peaks</code>, only <code>num_peaks</code> coordinates based on peak intensity are considered for the corresponding radius.</p> </dd> <dt>
<code>total_num_peaks : int, optional</code> </dt> <dd>
<p class="first last">Maximum number of peaks. When the number of peaks exceeds <code>num_peaks</code>, return <code>num_peaks</code> coordinates based on peak intensity.</p> </dd> <dt>
<code>normalize : bool, optional</code> </dt> <dd>
<p class="first last">If True, normalize the accumulator by the radius to sort the prominent peaks.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>accum, cx, cy, rad : tuple of array</code> </dt> <dd>
<p class="first last">Peak values in Hough space, x and y center coordinates and radii.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import transform, draw
&gt;&gt;&gt; img = np.zeros((120, 100), dtype=int)
&gt;&gt;&gt; radius, x_0, y_0 = (20, 99, 50)
&gt;&gt;&gt; y, x = draw.circle_perimeter(y_0, x_0, radius)
&gt;&gt;&gt; img[x, y] = 1
&gt;&gt;&gt; hspaces = transform.hough_circle(img, radius)
&gt;&gt;&gt; accum, cx, cy, rad = hough_circle_peaks(hspaces, [radius,])
</pre> </dd>
</dl>   <h2 id="hough-line-peaks">hough_line_peaks</h2> <dl class="function"> <dt id="skimage.transform.hough_line_peaks">
<code>skimage.transform.hough_line_peaks(hspace, angles, dists, min_distance=9, min_angle=10, threshold=None, num_peaks=inf)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/hough_transform.py#L8"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return peaks in a straight line Hough transform.</p> <p>Identifies most prominent lines separated by a certain angle and distance in a Hough transform. Non-maximum suppression with different sizes is applied separately in the first (distances) and second (angles) dimension of the Hough space to identify peaks.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>hspace : (N, M) array</code> </dt> <dd>
<p class="first last">Hough space returned by the <code>hough_line</code> function.</p> </dd> <dt>
<code>angles : (M,) array</code> </dt> <dd>
<p class="first last">Angles returned by the <code>hough_line</code> function. Assumed to be continuous. (<code>angles[-1] - angles[0] == PI</code>).</p> </dd> <dt>
<code>dists : (N, ) array</code> </dt> <dd>
<p class="first last">Distances returned by the <code>hough_line</code> function.</p> </dd> <dt>
<code>min_distance : int, optional</code> </dt> <dd>
<p class="first last">Minimum distance separating lines (maximum filter size for first dimension of hough space).</p> </dd> <dt>
<code>min_angle : int, optional</code> </dt> <dd>
<p class="first last">Minimum angle separating lines (maximum filter size for second dimension of hough space).</p> </dd> <dt>
<code>threshold : float, optional</code> </dt> <dd>
<p class="first last">Minimum intensity of peaks. Default is <code>0.5 * max(hspace)</code>.</p> </dd> <dt>
<code>num_peaks : int, optional</code> </dt> <dd>
<p class="first last">Maximum number of peaks. When the number of peaks exceeds <code>num_peaks</code>, return <code>num_peaks</code> coordinates based on peak intensity.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>accum, angles, dists : tuple of array</code> </dt> <dd>
<p class="first last">Peak values in Hough space, angles and distances.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import hough_line, hough_line_peaks
&gt;&gt;&gt; from skimage.draw import line
&gt;&gt;&gt; img = np.zeros((15, 15), dtype=np.bool_)
&gt;&gt;&gt; rr, cc = line(0, 0, 14, 14)
&gt;&gt;&gt; img[rr, cc] = 1
&gt;&gt;&gt; rr, cc = line(0, 14, 14, 0)
&gt;&gt;&gt; img[cc, rr] = 1
&gt;&gt;&gt; hspace, angles, dists = hough_line(img)
&gt;&gt;&gt; hspace, angles, dists = hough_line_peaks(hspace, angles, dists)
&gt;&gt;&gt; len(angles)
2
</pre> </dd>
</dl>   <h2 id="radon">radon</h2> <dl class="function"> <dt id="skimage.transform.radon">
<code>skimage.transform.radon(image, theta=None, circle=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/radon_transform.py#L14"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculates the radon transform of an image given specified projection angles.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : array_like, dtype=float</code> </dt> <dd>
<p class="first last">Input image. The rotation axis will be located in the pixel with indices <code>(image.shape[0] // 2, image.shape[1] // 2)</code>.</p> </dd> <dt>
<code>theta : array_like, dtype=float, optional (default np.arange(180))</code> </dt> <dd>
<p class="first last">Projection angles (in degrees).</p> </dd> <dt>
<code>circle : boolean, optional</code> </dt> <dd>
<p class="first last">Assume image is zero outside the inscribed circle, making the width of each projection (the first dimension of the sinogram) equal to <code>min(image.shape)</code>. The default behavior (None) is equivalent to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>radon_image : ndarray</code> </dt> <dd>
<p class="first last">Radon transform (sinogram). The tomography rotation axis will lie at the pixel index <code>radon_image.shape[0] // 2</code> along the 0th dimension of <code>radon_image</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Based on code of Justin K. Romberg (<a class="reference external" href="http://www.clear.rice.edu/elec431/projects96/DSP/bpanalysis.html">http://www.clear.rice.edu/elec431/projects96/DSP/bpanalysis.html</a>)</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r0eb755fc1fae-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id3">[1]</a></td>
<td>AC Kak, M Slaney, “Principles of Computerized Tomographic Imaging”, IEEE Press 1988.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r0eb755fc1fae-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id4">[2]</a></td>
<td>B.R. Ramesh, N. Srinivasa, K. Rajgopal, “An Algorithm for Computing the Discrete Radon Transform With Some Applications”, Proceedings of the Fourth IEEE Region 10 International Conference, TENCON ‘89, 1989</td>
</tr>  </table> </dd>
</dl>   <h2 id="iradon">iradon</h2> <dl class="function"> <dt id="skimage.transform.iradon">
<code>skimage.transform.iradon(radon_image, theta=None, output_size=None, filter='ramp', interpolation='linear', circle=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/radon_transform.py#L127"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Inverse radon transform.</p> <p>Reconstruct an image from the radon transform, using the filtered back projection algorithm.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>radon_image : array_like, dtype=float</code> </dt> <dd>
<p class="first last">Image containing radon transform (sinogram). Each column of the image corresponds to a projection along a different angle. The tomography rotation axis should lie at the pixel index <code>radon_image.shape[0] // 2</code> along the 0th dimension of <code>radon_image</code>.</p> </dd> <dt>
<code>theta : array_like, dtype=float, optional</code> </dt> <dd>
<p class="first last">Reconstruction angles (in degrees). Default: m angles evenly spaced between 0 and 180 (if the shape of <code>radon_image</code> is (N, M)).</p> </dd> <dt>
<code>output_size : int</code> </dt> <dd>
<p class="first last">Number of rows and columns in the reconstruction.</p> </dd> <dt>
<code>filter : str, optional (default ramp)</code> </dt> <dd>
<p class="first last">Filter used in frequency domain filtering. Ramp filter used by default. Filters available: ramp, shepp-logan, cosine, hamming, hann. Assign None to use no filter.</p> </dd> <dt>
<code>interpolation : str, optional (default ‘linear’)</code> </dt> <dd>
<p class="first last">Interpolation method used in reconstruction. Methods available: ‘linear’, ‘nearest’, and ‘cubic’ (‘cubic’ is slow).</p> </dd> <dt>
<code>circle : boolean, optional</code> </dt> <dd>
<p class="first last">Assume the reconstructed image is zero outside the inscribed circle. Also changes the default output_size to match the behaviour of <code>radon</code> called with <code>circle=True</code>. The default behavior (None) is equivalent to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>reconstructed : ndarray</code> </dt> <dd>
<p class="first last">Reconstructed image. The rotation axis will be located in the pixel with indices <code>(reconstructed.shape[0] // 2, reconstructed.shape[1] // 2)</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>It applies the Fourier slice theorem to reconstruct an image by multiplying the frequency domain of the filter with the FFT of the projection data. This algorithm is called filtered back projection.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r19c92af887b5-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id5">[1]</a></td>
<td>AC Kak, M Slaney, “Principles of Computerized Tomographic Imaging”, IEEE Press 1988.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r19c92af887b5-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id6">[2]</a></td>
<td>B.R. Ramesh, N. Srinivasa, K. Rajgopal, “An Algorithm for Computing the Discrete Radon Transform With Some Applications”, Proceedings of the Fourth IEEE Region 10 International Conference, TENCON ‘89, 1989</td>
</tr>  </table> </dd>
</dl>   <h2 id="iradon-sart">iradon_sart</h2> <dl class="function"> <dt id="skimage.transform.iradon_sart">
<code>skimage.transform.iradon_sart(radon_image, theta=None, image=None, projection_shifts=None, clip=None, relaxation=0.15)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/radon_transform.py#L329"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Inverse radon transform</p> <p>Reconstruct an image from the radon transform, using a single iteration of the Simultaneous Algebraic Reconstruction Technique (SART) algorithm.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>radon_image : 2D array, dtype=float</code> </dt> <dd>
<p class="first last">Image containing radon transform (sinogram). Each column of the image corresponds to a projection along a different angle. The tomography rotation axis should lie at the pixel index <code>radon_image.shape[0] // 2</code> along the 0th dimension of <code>radon_image</code>.</p> </dd> <dt>
<code>theta : 1D array, dtype=float, optional</code> </dt> <dd>
<p class="first last">Reconstruction angles (in degrees). Default: m angles evenly spaced between 0 and 180 (if the shape of <code>radon_image</code> is (N, M)).</p> </dd> <dt>
<code>image : 2D array, dtype=float, optional</code> </dt> <dd>
<p class="first last">Image containing an initial reconstruction estimate. Shape of this array should be <code>(radon_image.shape[0], radon_image.shape[0])</code>. The default is an array of zeros.</p> </dd> <dt>
<code>projection_shifts : 1D array, dtype=float</code> </dt> <dd>
<p class="first last">Shift the projections contained in <code>radon_image</code> (the sinogram) by this many pixels before reconstructing the image. The i’th value defines the shift of the i’th column of <code>radon_image</code>.</p> </dd> <dt>
<code>clip : length-2 sequence of floats</code> </dt> <dd>
<p class="first last">Force all values in the reconstructed tomogram to lie in the range <code>[clip[0], clip[1]]</code></p> </dd> <dt>
<code>relaxation : float</code> </dt> <dd>
<p class="first last">Relaxation parameter for the update step. A higher value can improve the convergence rate, but one runs the risk of instabilities. Values close to or higher than 1 are not recommended.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>reconstructed : ndarray</code> </dt> <dd>
<p class="first last">Reconstructed image. The rotation axis will be located in the pixel with indices <code>(reconstructed.shape[0] // 2, reconstructed.shape[1] // 2)</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Algebraic Reconstruction Techniques are based on formulating the tomography reconstruction problem as a set of linear equations. Along each ray, the projected value is the sum of all the values of the cross section along the ray. A typical feature of SART (and a few other variants of algebraic techniques) is that it samples the cross section at equidistant points along the ray, using linear interpolation between the pixel values of the cross section. The resulting set of linear equations are then solved using a slightly modified Kaczmarz method.</p> <p>When using SART, a single iteration is usually sufficient to obtain a good reconstruction. Further iterations will tend to enhance high-frequency information, but will also often increase the noise.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r5a4015ea6a92-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id7">[1]</a></td>
<td>AC Kak, M Slaney, “Principles of Computerized Tomographic Imaging”, IEEE Press 1988.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r5a4015ea6a92-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id8">[2]</a></td>
<td>AH Andersen, AC Kak, “Simultaneous algebraic reconstruction technique (SART): a superior implementation of the ART algorithm”, Ultrasonic Imaging 6 pp 81–94 (1984)</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r5a4015ea6a92-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id9">[3]</a></td>
<td>S Kaczmarz, “Angenäherte auflösung von systemen linearer gleichungen”, Bulletin International de l’Academie Polonaise des Sciences et des Lettres 35 pp 355–357 (1937)</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r5a4015ea6a92-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id10">[4]</a></td>
<td>Kohler, T. “A projection access scheme for iterative reconstruction based on the golden section.” Nuclear Science Symposium Conference Record, 2004 IEEE. Vol. 6. IEEE, 2004.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r5a4015ea6a92-5" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id11">[5]</a></td>
<td>Kaczmarz’ method, Wikipedia, <a class="reference external" href="http://en.wikipedia.org/wiki/Kaczmarz_method">http://en.wikipedia.org/wiki/Kaczmarz_method</a>
</td>
</tr>  </table> </dd>
</dl>   <h2 id="order-angles-golden-ratio">order_angles_golden_ratio</h2> <dl class="function"> <dt id="skimage.transform.order_angles_golden_ratio">
<code>skimage.transform.order_angles_golden_ratio(theta)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/radon_transform.py#L271"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Order angles to reduce the amount of correlated information in subsequent projections.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>theta : 1D array of floats</code> </dt> <dd>
<p class="first last">Projection angles in degrees. Duplicate angles are not allowed.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>indices_generator : generator yielding unsigned integers</code> </dt> <dd>
<p class="first last">The returned generator yields indices into <code>theta</code> such that <code>theta[indices]</code> gives the approximate golden ratio ordering of the projections. In total, <code>len(theta)</code> indices are yielded. All non-negative integers &lt; <code>len(theta)</code> are yielded exactly once.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The method used here is that of the golden ratio introduced by T. Kohler.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r88d6c0557044-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id12">[1]</a></td>
<td>Kohler, T. “A projection access scheme for iterative reconstruction based on the golden section.” Nuclear Science Symposium Conference Record, 2004 IEEE. Vol. 6. IEEE, 2004.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r88d6c0557044-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id13">[2]</a></td>
<td>Winkelmann, Stefanie, et al. “An optimal radial profile order based on the Golden Ratio for time-resolved MRI.” Medical Imaging, IEEE Transactions on 26.1 (2007): 68-76.</td>
</tr>  </table> </dd>
</dl>   <h2 id="frt2">frt2</h2> <dl class="function"> <dt id="skimage.transform.frt2">
<code>skimage.transform.frt2(a)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/finite_radon_transform.py#L12"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the 2-dimensional finite radon transform (FRT) for an n x n integer array.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>a : array_like</code> </dt> <dd>
<p class="first last">A 2-D square n x n integer array.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>FRT : 2-D ndarray</code> </dt> <dd>
<p class="first last">Finite Radon Transform array of (n+1) x n integer coefficients.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="#skimage.transform.ifrt2" title="skimage.transform.ifrt2"><code>ifrt2</code></a>
</dt> <dd>The two-dimensional inverse FRT.</dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>The FRT has a unique inverse if and only if n is prime. [FRT] The idea for this algorithm is due to Vlad Negnevitski.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rdb433381c1a5-frt" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id14">[FRT]</a></td>
<td>A. Kingston and I. Svalbe, “Projective transforms on periodic discrete image arrays,” in P. Hawkes (Ed), Advances in Imaging and Electron Physics, 139 (2006)</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <p>Generate a test image: Use a prime number for the array dimensions</p> <pre data-language="python">&gt;&gt;&gt; SIZE = 59
&gt;&gt;&gt; img = np.tri(SIZE, dtype=np.int32)
</pre> <p>Apply the Finite Radon Transform:</p> <pre data-language="python">&gt;&gt;&gt; f = frt2(img)
</pre> </dd>
</dl>   <h2 id="ifrt2">ifrt2</h2> <dl class="function"> <dt id="skimage.transform.ifrt2">
<code>skimage.transform.ifrt2(a)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/finite_radon_transform.py#L71"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the 2-dimensional inverse finite radon transform (iFRT) for an (n+1) x n integer array.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>a : array_like</code> </dt> <dd>
<p class="first last">A 2-D (n+1) row x n column integer array.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>iFRT : 2-D n x n ndarray</code> </dt> <dd>
<p class="first last">Inverse Finite Radon Transform array of n x n integer coefficients.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="#skimage.transform.frt2" title="skimage.transform.frt2"><code>frt2</code></a>
</dt> <dd>The two-dimensional FRT</dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>The FRT has a unique inverse if and only if n is prime. See <a class="reference internal" href="#r3b76f892cb20-1" id="id15">[1]</a> for an overview. The idea for this algorithm is due to Vlad Negnevitski.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r3b76f892cb20-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id15">1</a>, <a class="fn-backref" href="#id16">2</a>)</em> A. Kingston and I. Svalbe, “Projective transforms on periodic discrete image arrays,” in P. Hawkes (Ed), Advances in Imaging and Electron Physics, 139 (2006)</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; SIZE = 59
&gt;&gt;&gt; img = np.tri(SIZE, dtype=np.int32)
</pre> <p>Apply the Finite Radon Transform:</p> <pre data-language="python">&gt;&gt;&gt; f = frt2(img)
</pre> <p>Apply the Inverse Finite Radon Transform to recover the input</p> <pre data-language="python">&gt;&gt;&gt; fi = ifrt2(f)
</pre> <p>Check that it’s identical to the original</p> <pre data-language="python">&gt;&gt;&gt; assert len(np.nonzero(img-fi)[0]) == 0
</pre> </dd>
</dl>   <h2 id="integral-image">integral_image</h2> <dl class="function"> <dt id="skimage.transform.integral_image">
<code>skimage.transform.integral_image(image)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/integral.py#L7"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Integral image / summed area table.</p> <p>The integral image contains the sum of all elements above and to the left of it, i.e.:</p> <div class="math notranslate nohighlight"> \[S[m, n] = \sum_{i \leq m} \sum_{j \leq n} X[i, j]\]</div> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>S : ndarray</code> </dt> <dd>
<p class="first last">Integral image/summed area table of same shape as input image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rd91ebd979f08-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id17">[1]</a></td>
<td>F.C. Crow, “Summed-area tables for texture mapping,” ACM SIGGRAPH Computer Graphics, vol. 18, 1984, pp. 207-212.</td>
</tr>  </table> </dd>
</dl>   <h2 id="integrate">integrate</h2> <dl class="function"> <dt id="skimage.transform.integrate">
<code>skimage.transform.integrate(ii, start, end)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/integral.py#L39"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Use an integral image to integrate over a given window.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>ii : ndarray</code> </dt> <dd>
<p class="first last">Integral image.</p> </dd> <dt>
<code>start : List of tuples, each tuple of length equal to dimension of ii</code> </dt> <dd>
<p class="first last">Coordinates of top left corner of window(s). Each tuple in the list contains the starting row, col, … index i.e <code>[(row_win1, col_win1, …), (row_win2, col_win2,…), …]</code>.</p> </dd> <dt>
<code>end : List of tuples, each tuple of length equal to dimension of ii</code> </dt> <dd>
<p class="first last">Coordinates of bottom right corner of window(s). Each tuple in the list containing the end row, col, … index i.e <code>[(row_win1, col_win1, …), (row_win2, col_win2, …), …]</code>.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>S : scalar or ndarray</code> </dt> <dd>
<p class="first last">Integral (sum) over the given window(s).</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; arr = np.ones((5, 6), dtype=np.float)
&gt;&gt;&gt; ii = integral_image(arr)
&gt;&gt;&gt; integrate(ii, (1, 0), (1, 2))  # sum from (1, 0) to (1, 2)
array([ 3.])
&gt;&gt;&gt; integrate(ii, [(3, 3)], [(4, 5)])  # sum from (3, 3) to (4, 5)
array([ 6.])
&gt;&gt;&gt; # sum from (1, 0) to (1, 2) and from (3, 3) to (4, 5)
&gt;&gt;&gt; integrate(ii, [(1, 0), (3, 3)], [(1, 2), (4, 5)])
array([ 3.,  6.])
</pre> </dd>
</dl>   <h2 id="warp">warp</h2> <dl class="function"> <dt id="skimage.transform.warp">
<code>skimage.transform.warp(image, inverse_map, map_args={}, output_shape=None, order=1, mode='constant', cval=0.0, clip=True, preserve_range=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L663"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Warp an image according to a given coordinate transformation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>inverse_map : transformation object, callable cr = f(cr, **kwargs), or ndarray</code> </dt> <dd>
<p class="first">Inverse coordinate map, which transforms coordinates in the output images into their corresponding coordinates in the input image.</p> <p>There are a number of different options to define this map, depending on the dimensionality of the input image. A 2-D image can have 2 dimensions for gray-scale images, or 3 dimensions with color information.</p>  <ul class="simple"> <li>For 2-D images, you can directly pass a transformation object, e.g. <code>skimage.transform.SimilarityTransform</code>, or its inverse.</li> <li>For 2-D images, you can pass a <code>(3, 3)</code> homogeneous transformation matrix, e.g. <code>skimage.transform.SimilarityTransform.params</code>.</li> <li>For 2-D images, a function that transforms a <code>(M, 2)</code> array of <code>(col, row)</code> coordinates in the output image to their corresponding coordinates in the input image. Extra parameters to the function can be specified through <code>map_args</code>.</li> <li>For N-D images, you can directly pass an array of coordinates. The first dimension specifies the coordinates in the input image, while the subsequent dimensions determine the position in the output image. E.g. in case of 2-D images, you need to pass an array of shape <code>(2, rows, cols)</code>, where <code>rows</code> and <code>cols</code> determine the shape of the output image, and the first dimension contains the <code>(row, col)</code> coordinate in the input image. See <code>scipy.ndimage.map_coordinates</code> for further documentation.</li> </ul>  <p>Note, that a <code>(3, 3)</code> matrix is interpreted as a homogeneous transformation matrix, so you cannot interpolate values from a 3-D input, if the output is of shape <code>(3,)</code>.</p> <p class="last">See example section for usage.</p> </dd> <dt>
<code>map_args : dict, optional</code> </dt> <dd>
<p class="first last">Keyword arguments passed to <code>inverse_map</code>.</p> </dd> <dt>
<code>output_shape : tuple (rows, cols), optional</code> </dt> <dd>
<p class="first last">Shape of the output image generated. By default the shape of the input image is preserved. Note that, even for multi-band images, only rows and columns need to be specified.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<dl class="first last docutils"> <dt>The order of interpolation. The order has to be in the range 0-5:</dt> <dd>
<ul class="first last simple"> <li>0: Nearest-neighbor</li> <li>1: Bi-linear (default)</li> <li>2: Bi-quadratic</li> <li>3: Bi-cubic</li> <li>4: Bi-quartic</li> <li>5: Bi-quintic</li> </ul> </dd> </dl> </dd> <dt>
<code>mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of <code>numpy.pad</code>.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>clip : bool, optional</code> </dt> <dd>
<p class="first last">Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.</p> </dd> <dt>
<code>preserve_range : bool, optional</code> </dt> <dd>
<p class="first last">Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of <code>img_as_float</code>.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>warped : double ndarray</code> </dt> <dd>
<p class="first last">The warped input image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <ul class="simple"> <li>The input image is converted to a <code>double</code> image.</li> <li>In case of a <code>SimilarityTransform</code>, <code>AffineTransform</code> and <code>ProjectiveTransform</code> and <code>order</code> in [0, 3] this function uses the underlying transformation matrix to warp the image with a much faster routine.</li> </ul> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import warp
&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; image = data.camera()
</pre> <p>The following image warps are all equal but differ substantially in execution time. The image is shifted to the bottom.</p> <p>Use a geometric transform to warp an image (fast):</p> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import SimilarityTransform
&gt;&gt;&gt; tform = SimilarityTransform(translation=(0, -10))
&gt;&gt;&gt; warped = warp(image, tform)
</pre> <p>Use a callable (slow):</p> <pre data-language="python">&gt;&gt;&gt; def shift_down(xy):
...     xy[:, 1] -= 10
...     return xy
&gt;&gt;&gt; warped = warp(image, shift_down)
</pre> <p>Use a transformation matrix to warp an image (fast):</p> <pre data-language="python">&gt;&gt;&gt; matrix = np.array([[1, 0, 0], [0, 1, -10], [0, 0, 1]])
&gt;&gt;&gt; warped = warp(image, matrix)
&gt;&gt;&gt; from skimage.transform import ProjectiveTransform
&gt;&gt;&gt; warped = warp(image, ProjectiveTransform(matrix=matrix))
</pre> <p>You can also use the inverse of a geometric transformation (fast):</p> <pre data-language="python">&gt;&gt;&gt; warped = warp(image, tform.inverse)
</pre> <p>For N-D images you can pass a coordinate array, that specifies the coordinates in the input image for every element in the output image. E.g. if you want to rescale a 3-D cube, you can do:</p> <pre data-language="python">&gt;&gt;&gt; cube_shape = np.array([30, 30, 30])
&gt;&gt;&gt; cube = np.random.rand(*cube_shape)
</pre> <p>Setup the coordinate array, that defines the scaling:</p> <pre data-language="python">&gt;&gt;&gt; scale = 0.1
&gt;&gt;&gt; output_shape = (scale * cube_shape).astype(int)
&gt;&gt;&gt; coords0, coords1, coords2 = np.mgrid[:output_shape[0],
...                    :output_shape[1], :output_shape[2]]
&gt;&gt;&gt; coords = np.array([coords0, coords1, coords2])
</pre> <p>Assume that the cube contains spatial data, where the first array element center is at coordinate (0.5, 0.5, 0.5) in real space, i.e. we have to account for this extra offset when scaling the image:</p> <pre data-language="python">&gt;&gt;&gt; coords = (coords + 0.5) / scale - 0.5
&gt;&gt;&gt; warped = warp(cube, coords)
</pre> </dd>
</dl>   <h2 id="warp-coords">warp_coords</h2> <dl class="function"> <dt id="skimage.transform.warp_coords">
<code>skimage.transform.warp_coords(coord_map, shape, dtype=&lt;class 'numpy.float64'&gt;)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L539"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Build the source coordinates for the output of a 2-D image warp.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coord_map : callable like GeometricTransform.inverse</code> </dt> <dd>
<p class="first last">Return input coordinates for given output coordinates. Coordinates are in the shape (P, 2), where P is the number of coordinates and each element is a <code>(row, col)</code> pair.</p> </dd> <dt>
<code>shape : tuple</code> </dt> <dd>
<p class="first last">Shape of output image <code>(rows, cols[, bands])</code>.</p> </dd> <dt>
<code>dtype : np.dtype or string</code> </dt> <dd>
<p class="first last">dtype for return value (sane choices: float32 or float64).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (ndim, rows, cols[, bands]) array of dtype dtype</code> </dt> <dd>
<p class="first last">Coordinates for <code>scipy.ndimage.map_coordinates</code>, that will yield an image of shape (orows, ocols, bands) by drawing from source points according to the <code>coord_transform_fn</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>This is a lower-level routine that produces the source coordinates for 2-D images used by <code>warp()</code>.</p> <p>It is provided separately from <code>warp</code> to give additional flexibility to users who would like, for example, to re-use a particular coordinate mapping, to use specific dtypes at various points along the the image-warping process, or to implement different post-processing logic than <code>warp</code> performs after the call to <code>ndi.map_coordinates</code>.</p> <h4 class="rubric">Examples</h4> <p>Produce a coordinate map that shifts an image up and to the right:</p> <pre data-language="python">&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; from scipy.ndimage import map_coordinates
&gt;&gt;&gt;
&gt;&gt;&gt; def shift_up10_left20(xy):
...     return xy - np.array([-20, 10])[None, :]
&gt;&gt;&gt;
&gt;&gt;&gt; image = data.astronaut().astype(np.float32)
&gt;&gt;&gt; coords = warp_coords(shift_up10_left20, image.shape)
&gt;&gt;&gt; warped_image = map_coordinates(image, coords)
</pre> </dd>
</dl>   <h2 id="estimate-transform">estimate_transform</h2> <dl class="function"> <dt id="skimage.transform.estimate_transform">
<code>skimage.transform.estimate_transform(ttype, src, dst, **kwargs)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1307"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate 2D geometric transformation parameters.</p> <p>You can determine the over-, well- and under-determined parameters with the total least-squares method.</p> <p>Number of source and destination coordinates must match.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>ttype : {‘euclidean’, similarity’, ‘affine’, ‘piecewise-affine’, ‘projective’, ‘polynomial’}</code> </dt> <dd>
<p class="first last">Type of transform.</p> </dd> <dt>
<code>kwargs : array or int</code> </dt> <dd>
<p class="first">Function parameters (src, dst, n, angle):</p> <pre data-language="python">NAME / TTYPE        FUNCTION PARAMETERS
'euclidean'         `src, `dst`
'similarity'        `src, `dst`
'affine'            `src, `dst`
'piecewise-affine'  `src, `dst`
'projective'        `src, `dst`
'polynomial'        `src, `dst`, `order` (polynomial order,
                                          default order is 2)
</pre> <p class="last">Also see examples below.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>tform : GeometricTransform</code> </dt> <dd>
<p class="first last">Transform object containing the transformation parameters and providing access to forward and inverse transformation functions.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from skimage import transform as tf
</pre> <pre data-language="python">&gt;&gt;&gt; # estimate transformation parameters
&gt;&gt;&gt; src = np.array([0, 0, 10, 10]).reshape((2, 2))
&gt;&gt;&gt; dst = np.array([12, 14, 1, -20]).reshape((2, 2))
</pre> <pre data-language="python">&gt;&gt;&gt; tform = tf.estimate_transform('similarity', src, dst)
</pre> <pre data-language="python">&gt;&gt;&gt; np.allclose(tform.inverse(tform(src)), src)
True
</pre> <pre data-language="python">&gt;&gt;&gt; # warp image using the estimated transformation
&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; image = data.camera()
</pre> <pre data-language="python">&gt;&gt;&gt; warp(image, inverse_map=tform.inverse) # doctest: +SKIP
</pre> <pre data-language="python">&gt;&gt;&gt; # create transformation with explicit parameters
&gt;&gt;&gt; tform2 = tf.SimilarityTransform(scale=1.1, rotation=1,
...     translation=(10, 20))
</pre> <pre data-language="python">&gt;&gt;&gt; # unite transformations, applied in order from left to right
&gt;&gt;&gt; tform3 = tform + tform2
&gt;&gt;&gt; np.allclose(tform3(src), tform2(tform(src)))
True
</pre> </dd>
</dl>   <h2 id="matrix-transform">matrix_transform</h2> <dl class="function"> <dt id="skimage.transform.matrix_transform">
<code>skimage.transform.matrix_transform(coords, matrix)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1381"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply 2D matrix transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">x, y coordinates to transform</p> </dd> <dt>
<code>matrix : (3, 3) array</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Transformed coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl>   <h2 id="swirl">swirl</h2> <dl class="function"> <dt id="skimage.transform.swirl">
<code>skimage.transform.swirl(image, center=None, strength=1, radius=100, rotation=0, output_shape=None, order=1, mode=None, cval=0, clip=True, preserve_range=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L450"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform a swirl transformation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>center : (column, row) tuple or (2,) ndarray, optional</code> </dt> <dd>
<p class="first last">Center coordinate of transformation.</p> </dd> <dt>
<code>strength : float, optional</code> </dt> <dd>
<p class="first last">The amount of swirling applied.</p> </dd> <dt>
<code>radius : float, optional</code> </dt> <dd>
<p class="first last">The extent of the swirl in pixels. The effect dies out rapidly beyond <code>radius</code>.</p> </dd> <dt>
<code>rotation : float, optional</code> </dt> <dd>
<p class="first last">Additional rotation applied to the image.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>swirled : ndarray</code> </dt> <dd>
<p class="first last">Swirled version of the input.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>output_shape : tuple (rows, cols), optional</code> </dt> <dd>
<p class="first last">Shape of the output image generated. By default the shape of the input image is preserved.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">Points outside the boundaries of the input are filled according to the given mode, with ‘constant’ used as the default. Modes match the behaviour of <code>numpy.pad</code>.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>clip : bool, optional</code> </dt> <dd>
<p class="first last">Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.</p> </dd> <dt>
<code>preserve_range : bool, optional</code> </dt> <dd>
<p class="first last">Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of <code>img_as_float</code>.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl>   <h2 id="resize">resize</h2> <dl class="function"> <dt id="skimage.transform.resize">
<code>skimage.transform.resize(image, output_shape, order=1, mode=None, cval=0, clip=True, preserve_range=False, anti_aliasing=None, anti_aliasing_sigma=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L34"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Resize image to match a certain size.</p> <p>Performs interpolation to up-size or down-size images. Note that anti- aliasing should be enabled when down-sizing images to avoid aliasing artifacts. For down-sampling N-dimensional images with an integer factor also see <code>skimage.transform.downscale_local_mean</code>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>output_shape : tuple or ndarray</code> </dt> <dd>
<p class="first last">Size of the generated output image <code>(rows, cols[, …][, dim])</code>. If <code>dim</code> is not provided, the number of channels is preserved. In case the number of input channels does not equal the number of output channels a n-dimensional interpolation is applied.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>resized : ndarray</code> </dt> <dd>
<p class="first last">Resized version of the input.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of <code>numpy.pad</code>. The default mode is ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>clip : bool, optional</code> </dt> <dd>
<p class="first last">Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.</p> </dd> <dt>
<code>preserve_range : bool, optional</code> </dt> <dd>
<p class="first last">Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of <code>img_as_float</code>.</p> </dd> <dt>
<code>anti_aliasing : bool, optional</code> </dt> <dd>
<p class="first last">Whether to apply a Gaussian filter to smooth the image prior to down-scaling. It is crucial to filter when down-sampling the image to avoid aliasing artifacts.</p> </dd> <dt>
<code>anti_aliasing_sigma : {float, tuple of floats}, optional</code> </dt> <dd>
<p class="first last">Standard deviation for Gaussian filtering to avoid aliasing artifacts. By default, this value is chosen as (1 - s) / 2 where s is the down-scaling factor.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Modes ‘reflect’ and ‘symmetric’ are similar, but differ in whether the edge pixels are duplicated during the reflection. As an example, if an array has values [0, 1, 2] and was padded to the right by four values using symmetric, the result would be [0, 1, 2, 2, 1, 0, 0], while for reflect it would be [0, 1, 2, 1, 0, 1, 2].</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; from skimage.transform import resize
&gt;&gt;&gt; image = data.camera()
&gt;&gt;&gt; resize(image, (100, 100), mode='reflect').shape
(100, 100)
</pre> </dd>
</dl>   <h2 id="rotate">rotate</h2> <dl class="function"> <dt id="skimage.transform.rotate">
<code>skimage.transform.rotate(image, angle, resize=False, center=None, order=1, mode='constant', cval=0, clip=True, preserve_range=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L285"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Rotate image by a certain angle around its center.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>angle : float</code> </dt> <dd>
<p class="first last">Rotation angle in degrees in counter-clockwise direction.</p> </dd> <dt>
<code>resize : bool, optional</code> </dt> <dd>
<p class="first last">Determine whether the shape of the output image will be automatically calculated, so the complete rotated image exactly fits. Default is False.</p> </dd> <dt>
<code>center : iterable of length 2</code> </dt> <dd>
<p class="first last">The rotation center. If <code>center=None</code>, the image is rotated around its center, i.e. <code>center=(cols / 2 - 0.5, rows / 2 - 0.5)</code>. Please note that this parameter is (cols, rows), contrary to normal skimage ordering.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>rotated : ndarray</code> </dt> <dd>
<p class="first last">Rotated version of the input.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of <code>numpy.pad</code>.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>clip : bool, optional</code> </dt> <dd>
<p class="first last">Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.</p> </dd> <dt>
<code>preserve_range : bool, optional</code> </dt> <dd>
<p class="first last">Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of <code>img_as_float</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Modes ‘reflect’ and ‘symmetric’ are similar, but differ in whether the edge pixels are duplicated during the reflection. As an example, if an array has values [0, 1, 2] and was padded to the right by four values using symmetric, the result would be [0, 1, 2, 2, 1, 0, 0], while for reflect it would be [0, 1, 2, 1, 0, 1, 2].</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; from skimage.transform import rotate
&gt;&gt;&gt; image = data.camera()
&gt;&gt;&gt; rotate(image, 2).shape
(512, 512)
&gt;&gt;&gt; rotate(image, 2, resize=True).shape
(530, 530)
&gt;&gt;&gt; rotate(image, 90, resize=True).shape
(512, 512)
</pre> </dd>
</dl>   <h2 id="rescale">rescale</h2> <dl class="function"> <dt id="skimage.transform.rescale">
<code>skimage.transform.rescale(image, scale, order=1, mode=None, cval=0, clip=True, preserve_range=False, multichannel=None, anti_aliasing=None, anti_aliasing_sigma=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L190"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Scale image by a certain factor.</p> <p>Performs interpolation to up-scale or down-scale images. Note that anti- aliasing should be enabled when down-sizing images to avoid aliasing artifacts. For down-sampling N-dimensional images with an integer factor also see <code>skimage.transform.downscale_local_mean</code>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>scale : {float, tuple of floats}</code> </dt> <dd>
<p class="first last">Scale factors. Separate scale factors can be defined as <code>(rows, cols[, …][, dim])</code>.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>scaled : ndarray</code> </dt> <dd>
<p class="first last">Scaled version of the input.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of <code>numpy.pad</code>. The default mode is ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Used in conjunction with mode ‘constant’, the value outside the image boundaries.</p> </dd> <dt>
<code>clip : bool, optional</code> </dt> <dd>
<p class="first last">Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.</p> </dd> <dt>
<code>preserve_range : bool, optional</code> </dt> <dd>
<p class="first last">Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of <code>img_as_float</code>.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">Whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. By default, is set to True for 3D (2D+color) inputs, and False for others. Starting in release 0.16, this will always default to False.</p> </dd> <dt>
<code>anti_aliasing : bool, optional</code> </dt> <dd>
<p class="first last">Whether to apply a Gaussian filter to smooth the image prior to down-scaling. It is crucial to filter when down-sampling the image to avoid aliasing artifacts.</p> </dd> <dt>
<code>anti_aliasing_sigma : {float, tuple of floats}, optional</code> </dt> <dd>
<p class="first last">Standard deviation for Gaussian filtering to avoid aliasing artifacts. By default, this value is chosen as (1 - s) / 2 where s is the down-scaling factor.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>Modes ‘reflect’ and ‘symmetric’ are similar, but differ in whether the edge pixels are duplicated during the reflection. As an example, if an array has values [0, 1, 2] and was padded to the right by four values using symmetric, the result would be [0, 1, 2, 2, 1, 0, 0], while for reflect it would be [0, 1, 2, 1, 0, 1, 2].</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; from skimage.transform import rescale
&gt;&gt;&gt; image = data.camera()
&gt;&gt;&gt; rescale(image, 0.1, mode='reflect').shape
(51, 51)
&gt;&gt;&gt; rescale(image, 0.5, mode='reflect').shape
(256, 256)
</pre> </dd>
</dl>   <h2 id="downscale-local-mean">downscale_local_mean</h2> <dl class="function"> <dt id="skimage.transform.downscale_local_mean">
<code>skimage.transform.downscale_local_mean(image, factors, cval=0, clip=True)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_warps.py#L390"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Down-sample N-dimensional image by local averaging.</p> <p>The image is padded with <code>cval</code> if it is not perfectly divisible by the integer factors.</p> <p>In contrast to the 2-D interpolation in <code>skimage.transform.resize</code> and <code>skimage.transform.rescale</code> this function may be applied to N-dimensional images and calculates the local mean of elements in each block of size <code>factors</code> in the input image.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">N-dimensional input image.</p> </dd> <dt>
<code>factors : array_like</code> </dt> <dd>
<p class="first last">Array containing down-sampling integer factor along each axis.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Constant padding value if image is not perfectly divisible by the integer factors.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Down-sampled image with same number of dimensions as input image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; a = np.arange(15).reshape(3, 5)
&gt;&gt;&gt; a
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14]])
&gt;&gt;&gt; downscale_local_mean(a, (2, 3))
array([[ 3.5,  4. ],
       [ 5.5,  4.5]])
</pre> </dd>
</dl>   <h2 id="pyramid-reduce">pyramid_reduce</h2> <dl class="function"> <dt id="skimage.transform.pyramid_reduce">
<code>skimage.transform.pyramid_reduce(image, downscale=2, sigma=None, order=1, mode='reflect', cval=0, multichannel=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/pyramids.py#L27"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Smooth and then downsample image.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>downscale : float, optional</code> </dt> <dd>
<p class="first last">Downscale factor.</p> </dd> <dt>
<code>sigma : float, optional</code> </dt> <dd>
<p class="first last">Sigma for Gaussian filter. Default is <code>2 * downscale / 6.0</code> which corresponds to a filter mask twice the size of the scale factor that covers more than 99% of the Gaussian distribution.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Order of splines used in interpolation of downsampling. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘reflect’, ‘constant’, ‘edge’, ‘symmetric’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Value to fill past edges of input if mode is ‘constant’.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">Whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. By default, is set to True for 3D (2D+color) inputs, and False for others. Starting in release 0.16, this will always default to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>out : array</code> </dt> <dd>
<p class="first last">Smoothed and downsampled float image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r4f51c9e42c4a-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id18">[1]</a></td>
<td><a class="reference external" href="http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf">http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="pyramid-expand">pyramid_expand</h2> <dl class="function"> <dt id="skimage.transform.pyramid_expand">
<code>skimage.transform.pyramid_expand(image, upscale=2, sigma=None, order=1, mode='reflect', cval=0, multichannel=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/pyramids.py#L85"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Upsample and then smooth image.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>upscale : float, optional</code> </dt> <dd>
<p class="first last">Upscale factor.</p> </dd> <dt>
<code>sigma : float, optional</code> </dt> <dd>
<p class="first last">Sigma for Gaussian filter. Default is <code>2 * upscale / 6.0</code> which corresponds to a filter mask twice the size of the scale factor that covers more than 99% of the Gaussian distribution.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Order of splines used in interpolation of upsampling. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘reflect’, ‘constant’, ‘edge’, ‘symmetric’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Value to fill past edges of input if mode is ‘constant’.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">Whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. By default, is set to True for 3D (2D+color) inputs, and False for others. Starting in release 0.16, this will always default to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>out : array</code> </dt> <dd>
<p class="first last">Upsampled and smoothed float image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r53df52222c6d-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id19">[1]</a></td>
<td><a class="reference external" href="http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf">http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="pyramid-gaussian">pyramid_gaussian</h2> <dl class="function"> <dt id="skimage.transform.pyramid_gaussian">
<code>skimage.transform.pyramid_gaussian(image, max_layer=-1, downscale=2, sigma=None, order=1, mode='reflect', cval=0, multichannel=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/pyramids.py#L144"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Yield images of the Gaussian pyramid formed by the input image.</p> <p>Recursively applies the <code>pyramid_reduce</code> function to the image, and yields the downscaled images.</p> <p>Note that the first image of the pyramid will be the original, unscaled image. The total number of images is <code>max_layer + 1</code>. In case all layers are computed, the last image is either a one-pixel image or the image where the reduction does not change its shape.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>max_layer : int</code> </dt> <dd>
<p class="first last">Number of layers for the pyramid. 0th layer is the original image. Default is -1 which builds all possible layers.</p> </dd> <dt>
<code>downscale : float, optional</code> </dt> <dd>
<p class="first last">Downscale factor.</p> </dd> <dt>
<code>sigma : float, optional</code> </dt> <dd>
<p class="first last">Sigma for Gaussian filter. Default is <code>2 * downscale / 6.0</code> which corresponds to a filter mask twice the size of the scale factor that covers more than 99% of the Gaussian distribution.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Order of splines used in interpolation of downsampling. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘reflect’, ‘constant’, ‘edge’, ‘symmetric’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Value to fill past edges of input if mode is ‘constant’.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">Whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. By default, is set to True for 3D (2D+color) inputs, and False for others. Starting in release 0.16, this will always default to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>pyramid : generator</code> </dt> <dd>
<p class="first last">Generator yielding pyramid layers as float images.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r4f1da659b730-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id20">[1]</a></td>
<td><a class="reference external" href="http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf">http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="pyramid-laplacian">pyramid_laplacian</h2> <dl class="function"> <dt id="skimage.transform.pyramid_laplacian">
<code>skimage.transform.pyramid_laplacian(image, max_layer=-1, downscale=2, sigma=None, order=1, mode='reflect', cval=0, multichannel=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/pyramids.py#L224"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Yield images of the laplacian pyramid formed by the input image.</p> <p>Each layer contains the difference between the downsampled and the downsampled, smoothed image:</p> <pre data-language="python">layer = resize(prev_layer) - smooth(resize(prev_layer))
</pre> <p>Note that the first image of the pyramid will be the difference between the original, unscaled image and its smoothed version. The total number of images is <code>max_layer + 1</code>. In case all layers are computed, the last image is either a one-pixel image or the image where the reduction does not change its shape.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Input image.</p> </dd> <dt>
<code>max_layer : int</code> </dt> <dd>
<p class="first last">Number of layers for the pyramid. 0th layer is the original image. Default is -1 which builds all possible layers.</p> </dd> <dt>
<code>downscale : float, optional</code> </dt> <dd>
<p class="first last">Downscale factor.</p> </dd> <dt>
<code>sigma : float, optional</code> </dt> <dd>
<p class="first last">Sigma for Gaussian filter. Default is <code>2 * downscale / 6.0</code> which corresponds to a filter mask twice the size of the scale factor that covers more than 99% of the Gaussian distribution.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Order of splines used in interpolation of downsampling. See <code>skimage.transform.warp</code> for detail.</p> </dd> <dt>
<code>mode : {‘reflect’, ‘constant’, ‘edge’, ‘symmetric’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">Value to fill past edges of input if mode is ‘constant’.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">Whether the last axis of the image is to be interpreted as multiple channels or another spatial dimension. By default, is set to True for 3D (2D+color) inputs, and False for others. Starting in release 0.16, this will always default to False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>pyramid : generator</code> </dt> <dd>
<p class="first last">Generator yielding pyramid layers as float images.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r64565393f7ed-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id21">[1]</a></td>
<td><a class="reference external" href="http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf">http://web.mit.edu/persci/people/adelson/pub_pdfs/pyramid83.pdf</a></td>
</tr>  </table> <table class="docutils citation" frame="void" id="r64565393f7ed-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id22">[2]</a></td>
<td><a class="reference external" href="http://sepwww.stanford.edu/data/media/public/sep/morgan/texturematch/paper_html/node3.html">http://sepwww.stanford.edu/data/media/public/sep/morgan/texturematch/paper_html/node3.html</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="seam-carve">seam_carve</h2> <dl class="function"> <dt id="skimage.transform.seam_carve">
<code>skimage.transform.seam_carve(image, energy_map, mode, num, border=1, force_copy=True)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/seam_carving.py#L7"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Carve vertical or horizontal seams off an image.</p> <p>Carves out vertical/horizontal seams from an image while using the given energy map to decide the importance of each pixel.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (M, N) or (M, N, 3) ndarray</code> </dt> <dd>
<p class="first last">Input image whose seams are to be removed.</p> </dd> <dt>
<code>energy_map : (M, N) ndarray</code> </dt> <dd>
<p class="first last">The array to decide the importance of each pixel. The higher the value corresponding to a pixel, the more the algorithm will try to keep it in the image.</p> </dd> <dt>
<code>mode : str {‘horizontal’, ‘vertical’}</code> </dt> <dd>
<p class="first last">Indicates whether seams are to be removed vertically or horizontally. Removing seams horizontally will decrease the height whereas removing vertically will decrease the width.</p> </dd> <dt>
<code>num : int</code> </dt> <dd>
<p class="first last">Number of seams are to be removed.</p> </dd> <dt>
<code>border : int, optional</code> </dt> <dd>
<p class="first last">The number of pixels in the right, left and bottom end of the image to be excluded from being considered for a seam. This is important as certain filters just ignore image boundaries and set them to <code>0</code>. By default border is set to <code>1</code>.</p> </dd> <dt>
<code>force_copy : bool, optional</code> </dt> <dd>
<p class="first last">If set, the <code>image</code> and <code>energy_map</code> are copied before being used by the method which modifies it in place. Set this to <code>False</code> if the original image and the energy map are no longer needed after this operation.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>out : ndarray</code> </dt> <dd>
<p class="first last">The cropped image with the seams removed.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="racd373b9ddae-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id23">[1]</a></td>
<td>Shai Avidan and Ariel Shamir “Seam Carving for Content-Aware Image Resizing” <a class="reference external" href="http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Avidan07.pdf">http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Avidan07.pdf</a>
</td>
</tr>  </table> </dd>
</dl>   <h2 id="euclideantransform">EuclideanTransform</h2> <dl class="class"> <dt id="skimage.transform.EuclideanTransform">
<code>class skimage.transform.EuclideanTransform(matrix=None, rotation=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L942"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.ProjectiveTransform</code></p> <p>2D Euclidean transformation.</p> <p>Has the following form:</p> <pre data-language="python">X = a0 * x - b0 * y + a1 =
  = x * cos(rotation) - y * sin(rotation) + a1

Y = b0 * x + a0 * y + b1 =
  = x * sin(rotation) + y * cos(rotation) + b1
</pre> <p>where the homogeneous transformation matrix is:</p> <pre data-language="python">[[a0  b0  a1]
 [b0  a0  b1]
 [0   0    1]]
</pre> <p>The Euclidean transformation is a rigid transformation with rotation and translation parameters. The similarity transformation extends the Euclidean transformation with a single scaling factor.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> <dt>
<code>rotation : float, optional</code> </dt> <dd>
<p class="first last">Rotation angle in counter-clockwise direction as radians.</p> </dd> <dt>
<code>translation : (tx, ty) as array, list or tuple, optional</code> </dt> <dd>
<p class="first last">x, y translation parameters.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.EuclideanTransform.__init__">
<code>__init__(matrix=None, rotation=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L979"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.EuclideanTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1006"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the transformation from a set of corresponding points.</p> <p>You can determine the over-, well- and under-determined parameters with the total least-squares method.</p> <p>Number of source and destination coordinates must match.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="skimage.transform.EuclideanTransform.rotation">
<code>rotation</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.transform.EuclideanTransform.translation">
<code>translation</code> </dt> 
</dl> </dd>
</dl>   <h2 id="similaritytransform">SimilarityTransform</h2> <dl class="class"> <dt id="skimage.transform.SimilarityTransform">
<code>class skimage.transform.SimilarityTransform(matrix=None, scale=None, rotation=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1041"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.EuclideanTransform</code></p> <p>2D similarity transformation.</p> <p>Has the following form:</p> <pre data-language="python">X = a0 * x - b0 * y + a1 =
  = s * x * cos(rotation) - s * y * sin(rotation) + a1

Y = b0 * x + a0 * y + b1 =
  = s * x * sin(rotation) + s * y * cos(rotation) + b1
</pre> <p>where <code>s</code> is a scale factor and the homogeneous transformation matrix is:</p> <pre data-language="python">[[a0  b0  a1]
 [b0  a0  b1]
 [0   0    1]]
</pre> <p>The similarity transformation extends the Euclidean transformation with a single scaling factor in addition to the rotation and translation parameters.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> <dt>
<code>scale : float, optional</code> </dt> <dd>
<p class="first last">Scale factor.</p> </dd> <dt>
<code>rotation : float, optional</code> </dt> <dd>
<p class="first last">Rotation angle in counter-clockwise direction as radians.</p> </dd> <dt>
<code>translation : (tx, ty) as array, list or tuple, optional</code> </dt> <dd>
<p class="first last">x, y translation parameters.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.SimilarityTransform.__init__">
<code>__init__(matrix=None, scale=None, rotation=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1080"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.SimilarityTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1111"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the transformation from a set of corresponding points.</p> <p>You can determine the over-, well- and under-determined parameters with the total least-squares method.</p> <p>Number of source and destination coordinates must match.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="skimage.transform.SimilarityTransform.scale">
<code>scale</code> </dt> 
</dl> </dd>
</dl>   <h2 id="affinetransform">AffineTransform</h2> <dl class="class"> <dt id="skimage.transform.AffineTransform">
<code>class skimage.transform.AffineTransform(matrix=None, scale=None, rotation=None, shear=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L715"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.ProjectiveTransform</code></p> <p>2D affine transformation.</p> <p>Has the following form:</p> <pre data-language="python">X = a0*x + a1*y + a2 =
  = sx*x*cos(rotation) - sy*y*sin(rotation + shear) + a2

Y = b0*x + b1*y + b2 =
  = sx*x*sin(rotation) + sy*y*cos(rotation + shear) + b2
</pre> <p>where <code>sx</code> and <code>sy</code> are scale factors in the x and y directions, and the homogeneous transformation matrix is:</p> <pre data-language="python">[[a0  a1  a2]
 [b0  b1  b2]
 [0   0    1]]
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> <dt>
<code>scale : (sx, sy) as array, list or tuple, optional</code> </dt> <dd>
<p class="first last">Scale factors.</p> </dd> <dt>
<code>rotation : float, optional</code> </dt> <dd>
<p class="first last">Rotation angle in counter-clockwise direction as radians.</p> </dd> <dt>
<code>shear : float, optional</code> </dt> <dd>
<p class="first last">Shear angle in counter-clockwise direction as radians.</p> </dd> <dt>
<code>translation : (tx, ty) as array, list or tuple, optional</code> </dt> <dd>
<p class="first last">Translation parameters.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.AffineTransform.__init__">
<code>__init__(matrix=None, scale=None, rotation=None, shear=None, translation=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L755"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="attribute"> <dt id="skimage.transform.AffineTransform.rotation">
<code>rotation</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.transform.AffineTransform.scale">
<code>scale</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.transform.AffineTransform.shear">
<code>shear</code> </dt> 
</dl> <dl class="attribute"> <dt id="skimage.transform.AffineTransform.translation">
<code>translation</code> </dt> 
</dl> </dd>
</dl>   <h2 id="projectivetransform">ProjectiveTransform</h2> <dl class="class"> <dt id="skimage.transform.ProjectiveTransform">
<code>class skimage.transform.ProjectiveTransform(matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L495"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.GeometricTransform</code></p> <p>Projective transformation.</p> <p>Apply a projective transformation (homography) on coordinates.</p> <p>For each homogeneous coordinate <span class="math notranslate nohighlight">\(\mathbf{x} = [x, y, 1]^T\)</span>, its target position is calculated by multiplying with the given matrix, <span class="math notranslate nohighlight">\(H\)</span>, to give <span class="math notranslate nohighlight">\(H \mathbf{x}\)</span>:</p> <pre data-language="python">[[a0 a1 a2]
 [b0 b1 b2]
 [c0 c1 1 ]].
</pre> <p>E.g., to rotate by theta degrees clockwise, the matrix should be:</p> <pre data-language="python">[[cos(theta) -sin(theta) 0]
 [sin(theta)  cos(theta) 0]
 [0            0         1]]
</pre> <p>or, to translate x by 10 and y by 20:</p> <pre data-language="python">[[1 0 10]
 [0 1 20]
 [0 0 1 ]].
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Homogeneous transformation matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.ProjectiveTransform.__init__">
<code>__init__(matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L534"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.ProjectiveTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L591"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the transformation from a set of corresponding points.</p> <p>You can determine the over-, well- and under-determined parameters with the total least-squares method.</p> <p>Number of source and destination coordinates must match.</p> <p>The transformation is defined as:</p> <pre data-language="python">X = (a0*x + a1*y + a2) / (c0*x + c1*y + 1)
Y = (b0*x + b1*y + b2) / (c0*x + c1*y + 1)
</pre> <p>These equations can be transformed to the following form:</p> <pre data-language="python">0 = a0*x + a1*y + a2 - c0*x*X - c1*y*X - X
0 = b0*x + b1*y + b2 - c0*x*Y - c1*y*Y - Y
</pre> <p>which exist for each set of corresponding points, so we have a set of N * 2 equations. The coefficients appear linearly so we can write A x = 0, where:</p> <pre data-language="python">A   = [[x y 1 0 0 0 -x*X -y*X -X]
       [0 0 0 x y 1 -x*Y -y*Y -Y]
        ...
        ...
      ]
x.T = [a0 a1 a2 b0 b1 b2 c0 c1 c3]
</pre> <p>In case of total least-squares the solution of this homogeneous system of equations is the right singular vector of A which corresponds to the smallest singular value normed by the coefficient c3.</p> <p>In case of the affine transformation the coefficients c0 and c1 are 0. Thus the system of equations is:</p> <pre data-language="python">A   = [[x y 1 0 0 0 -X]
       [0 0 0 x y 1 -Y]
        ...
        ...
      ]
x.T = [a0 a1 a2 b0 b1 b2 c3]
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.ProjectiveTransform.inverse">
<code>inverse(coords)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L575"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply inverse transformation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="essentialmatrixtransform">EssentialMatrixTransform</h2> <dl class="class"> <dt id="skimage.transform.EssentialMatrixTransform">
<code>class skimage.transform.EssentialMatrixTransform(rotation=None, translation=None, matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L397"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.FundamentalMatrixTransform</code></p> <p>Essential matrix transformation.</p> <p>The essential matrix relates corresponding points between a pair of calibrated images. The matrix transforms normalized, homogeneous image points in one image to epipolar lines in the other image.</p> <p>The essential matrix is only defined for a pair of moving images capturing a non-planar scene. In the case of pure rotation or planar scenes, the homography describes the geometric relation between two images (<code>ProjectiveTransform</code>). If the intrinsic calibration of the images is unknown, the fundamental matrix describes the projective relation between the two images (<code>FundamentalMatrixTransform</code>).</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>rotation : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Rotation matrix of the relative camera motion.</p> </dd> <dt>
<code>translation : (3, 1) array, optional</code> </dt> <dd>
<p class="first last">Translation vector of the relative camera motion. The vector must have unit length.</p> </dd> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Essential matrix.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r2fbde33858f1-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id24">[1]</a></td>
<td>Hartley, Richard, and Andrew Zisserman. Multiple view geometry in computer vision. Cambridge university press, 2003.</td>
</tr>  </table> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Essential matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.EssentialMatrixTransform.__init__">
<code>__init__(rotation=None, translation=None, matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L433"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.EssentialMatrixTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L458"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate essential matrix using 8-point algorithm.</p> <p>The 8-point algorithm requires at least 8 corresponding point pairs for a well-conditioned solution, otherwise the over-determined solution is estimated.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="fundamentalmatrixtransform">FundamentalMatrixTransform</h2> <dl class="class"> <dt id="skimage.transform.FundamentalMatrixTransform">
<code>class skimage.transform.FundamentalMatrixTransform(matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L211"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.GeometricTransform</code></p> <p>Fundamental matrix transformation.</p> <p>The fundamental matrix relates corresponding points between a pair of uncalibrated images. The matrix transforms homogeneous image points in one image to epipolar lines in the other image.</p> <p>The fundamental matrix is only defined for a pair of moving images. In the case of pure rotation or planar scenes, the homography describes the geometric relation between two images (<code>ProjectiveTransform</code>). If the intrinsic calibration of the images is known, the essential matrix describes the metric relation between the two images (<code>EssentialMatrixTransform</code>).</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>matrix : (3, 3) array, optional</code> </dt> <dd>
<p class="first last">Fundamental matrix.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r725e3a484348-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id25">[1]</a></td>
<td>Hartley, Richard, and Andrew Zisserman. Multiple view geometry in computer vision. Cambridge university press, 2003.</td>
</tr>  </table> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (3, 3) array</code> </dt> <dd>
<p class="first last">Fundamental matrix.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.FundamentalMatrixTransform.__init__">
<code>__init__(matrix=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L241"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.FundamentalMatrixTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L333"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate fundamental matrix using 8-point algorithm.</p> <p>The 8-point algorithm requires at least 8 corresponding point pairs for a well-conditioned solution, otherwise the over-determined solution is estimated.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.FundamentalMatrixTransform.inverse">
<code>inverse(coords)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L266"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply inverse transformation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (N, 3) array</code> </dt> <dd>
<p class="first last">Epipolar lines in the source image.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.FundamentalMatrixTransform.residuals">
<code>residuals(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L367"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the Sampson distance.</p> <p>The Sampson distance is the first approximation to the geometric error.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>residuals : (N, ) array</code> </dt> <dd>
<p class="first last">Sampson distance.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="polynomialtransform">PolynomialTransform</h2> <dl class="class"> <dt id="skimage.transform.PolynomialTransform">
<code>class skimage.transform.PolynomialTransform(params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1147"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.GeometricTransform</code></p> <p>2D polynomial transformation.</p> <p>Has the following form:</p> <pre data-language="python">X = sum[j=0:order]( sum[i=0:j]( a_ji * x**(j - i) * y**i ))
Y = sum[j=0:order]( sum[i=0:j]( b_ji * x**(j - i) * y**i ))
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>params : (2, N) array, optional</code> </dt> <dd>
<p class="first last">Polynomial coefficients where <code>N * 2 = (order + 1) * (order + 2)</code>. So, a_ji is defined in <code>params[0, :]</code> and b_ji in <code>params[1, :]</code>.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : (2, N) array</code> </dt> <dd>
<p class="first last">Polynomial coefficients where <code>N * 2 = (order + 1) * (order + 2)</code>. So, a_ji is defined in <code>params[0, :]</code> and b_ji in <code>params[1, :]</code>.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.PolynomialTransform.__init__">
<code>__init__(params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1169"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.PolynomialTransform.estimate">
<code>estimate(src, dst, order=2)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1177"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the transformation from a set of corresponding points.</p> <p>You can determine the over-, well- and under-determined parameters with the total least-squares method.</p> <p>Number of source and destination coordinates must match.</p> <p>The transformation is defined as:</p> <pre data-language="python">X = sum[j=0:order]( sum[i=0:j]( a_ji * x**(j - i) * y**i ))
Y = sum[j=0:order]( sum[i=0:j]( b_ji * x**(j - i) * y**i ))
</pre> <p>These equations can be transformed to the following form:</p> <pre data-language="python">0 = sum[j=0:order]( sum[i=0:j]( a_ji * x**(j - i) * y**i )) - X
0 = sum[j=0:order]( sum[i=0:j]( b_ji * x**(j - i) * y**i )) - Y
</pre> <p>which exist for each set of corresponding points, so we have a set of N * 2 equations. The coefficients appear linearly so we can write A x = 0, where:</p> <pre data-language="python">A   = [[1 x y x**2 x*y y**2 ... 0 ...             0 -X]
       [0 ...                 0 1 x y x**2 x*y y**2 -Y]
        ...
        ...
      ]
x.T = [a00 a10 a11 a20 a21 a22 ... ann
       b00 b10 b11 b20 b21 b22 ... bnn c3]
</pre> <p>In case of total least-squares the solution of this homogeneous system of equations is the right singular vector of A which corresponds to the smallest singular value normed by the coefficient c3.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Polynomial order (number of coefficients is order + 1).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.PolynomialTransform.inverse">
<code>inverse(coords)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L1287"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply inverse transformation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="piecewiseaffinetransform">PiecewiseAffineTransform</h2> <dl class="class"> <dt id="skimage.transform.PiecewiseAffineTransform">
<code>class skimage.transform.PiecewiseAffineTransform</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L808"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.transform._geometric.GeometricTransform</code></p> <p>2D piecewise affine transformation.</p> <p>Control points are used to define the mapping. The transform is based on a Delaunay triangulation of the points to form a mesh. Each triangle is used to find a local affine transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>affines : list of AffineTransform objects</code> </dt> <dd>
<p class="first last">Affine transformations for each triangle in the mesh.</p> </dd> <dt>
<code>inverse_affines : list of AffineTransform objects</code> </dt> <dd>
<p class="first last">Inverse affine transformations for each triangle in the mesh.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.transform.PiecewiseAffineTransform.__init__">
<code>__init__()</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L824"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.PiecewiseAffineTransform.estimate">
<code>estimate(src, dst)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L830"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the transformation from a set of corresponding points.</p> <p>Number of source and destination coordinates must match.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>src : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> <dt>
<code>dst : (N, 2) array</code> </dt> <dd>
<p class="first last">Destination coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.transform.PiecewiseAffineTransform.inverse">
<code>inverse(coords)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/transform/_geometric.py#L906"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply inverse transformation.</p> <p>Coordinates outside of the mesh will be set to <code>- 1</code>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Source coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Transformed coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>
<div class="_attribution">
  <p class="_attribution-p">
    © 2011 the scikit-image team<br>Licensed under the BSD 3-clause License.<br>
    <a href="http://scikit-image.org/docs/0.14.x/api/skimage.transform.html" class="_attribution-link">http://scikit-image.org/docs/0.14.x/api/skimage.transform.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
