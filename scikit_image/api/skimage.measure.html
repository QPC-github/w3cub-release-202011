
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Measure - Scikit-image - W3cubDocs</title>
  
  <meta name="description" content=" Find iso-valued contours in a 2D array for a given level value. ">
  <meta name="keywords" content="module, measure, scikit-image, scikit_image">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_image/api/skimage.measure.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/scikit_image.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_image/" class="_nav-link" title="" style="margin-left:0;">scikit-image</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="module-measure">Module: measure</h1> <table class="longtable docutils" id="module-skimage.measure">   <tr>
<td>
<a class="reference internal" href="#skimage.measure.find_contours" title="skimage.measure.find_contours"><code>skimage.measure.find_contours</code></a>(array, level)</td> <td>Find iso-valued contours in a 2D array for a given level value.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.regionprops" title="skimage.measure.regionprops"><code>skimage.measure.regionprops</code></a>(label_image[, …])</td> <td>Measure properties of labeled image regions.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.perimeter" title="skimage.measure.perimeter"><code>skimage.measure.perimeter</code></a>(image[, neighbourhood])</td> <td>Calculate total perimeter of all objects in binary image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.approximate_polygon" title="skimage.measure.approximate_polygon"><code>skimage.measure.approximate_polygon</code></a>(coords, …)</td> <td>Approximate a polygonal chain with the specified tolerance.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.subdivide_polygon" title="skimage.measure.subdivide_polygon"><code>skimage.measure.subdivide_polygon</code></a>(coords[, …])</td> <td>Subdivision of polygonal curves using B-Splines.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.ransac" title="skimage.measure.ransac"><code>skimage.measure.ransac</code></a>(data, model_class, …)</td> <td>Fit a model to data with the RANSAC (random sample consensus) algorithm.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.block_reduce" title="skimage.measure.block_reduce"><code>skimage.measure.block_reduce</code></a>(image, block_size)</td> <td>Down-sample image by applying function to local blocks.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments" title="skimage.measure.moments"><code>skimage.measure.moments</code></a>(image[, order])</td> <td>Calculate all raw image moments up to a certain order.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments_central" title="skimage.measure.moments_central"><code>skimage.measure.moments_central</code></a>(image[, …])</td> <td>Calculate all central image moments up to a certain order.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments_coords" title="skimage.measure.moments_coords"><code>skimage.measure.moments_coords</code></a>(coords[, order])</td> <td>Calculate all raw image moments up to a certain order.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments_coords_central" title="skimage.measure.moments_coords_central"><code>skimage.measure.moments_coords_central</code></a>(coords)</td> <td>Calculate all central image moments up to a certain order.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments_normalized" title="skimage.measure.moments_normalized"><code>skimage.measure.moments_normalized</code></a>(mu[, order])</td> <td>Calculate all normalized central image moments up to a certain order.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.moments_hu" title="skimage.measure.moments_hu"><code>skimage.measure.moments_hu</code></a>(nu)</td> <td>Calculate Hu’s set of image moments (2D-only).</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.marching_cubes_lewiner" title="skimage.measure.marching_cubes_lewiner"><code>skimage.measure.marching_cubes_lewiner</code></a>(volume)</td> <td>Lewiner marching cubes algorithm to find surfaces in 3d volumetric data.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.marching_cubes_classic" title="skimage.measure.marching_cubes_classic"><code>skimage.measure.marching_cubes_classic</code></a>(volume)</td> <td>Classic marching cubes algorithm to find surfaces in 3d volumetric data.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.mesh_surface_area" title="skimage.measure.mesh_surface_area"><code>skimage.measure.mesh_surface_area</code></a>(verts, faces)</td> <td>Compute surface area, given vertices &amp; triangular faces</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.correct_mesh_orientation" title="skimage.measure.correct_mesh_orientation"><code>skimage.measure.correct_mesh_orientation</code></a>(…)</td> <td>Correct orientations of mesh faces.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.profile_line" title="skimage.measure.profile_line"><code>skimage.measure.profile_line</code></a>(image, src, dst)</td> <td>Return the intensity profile of an image measured along a scan line.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.label" title="skimage.measure.label"><code>skimage.measure.label</code></a>(input[, neighbors, …])</td> <td>Label connected regions of an integer array.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.points_in_poly" title="skimage.measure.points_in_poly"><code>skimage.measure.points_in_poly</code></a>(points, verts)</td> <td>Test whether points lie inside a polygon.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.grid_points_in_poly" title="skimage.measure.grid_points_in_poly"><code>skimage.measure.grid_points_in_poly</code></a>(shape, verts)</td> <td>Test whether points on a specified grid are inside a polygon.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.compare_ssim" title="skimage.measure.compare_ssim"><code>skimage.measure.compare_ssim</code></a>(X, Y[, …])</td> <td>Compute the mean structural similarity index between two images.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.compare_mse" title="skimage.measure.compare_mse"><code>skimage.measure.compare_mse</code></a>(im1, im2)</td> <td>Compute the mean-squared error between two images.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.compare_nrmse" title="skimage.measure.compare_nrmse"><code>skimage.measure.compare_nrmse</code></a>(im_true, im_test)</td> <td>Compute the normalized root mean-squared error (NRMSE) between two images.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.compare_psnr" title="skimage.measure.compare_psnr"><code>skimage.measure.compare_psnr</code></a>(im_true, im_test)</td> <td>Compute the peak signal to noise ratio (PSNR) for an image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.shannon_entropy" title="skimage.measure.shannon_entropy"><code>skimage.measure.shannon_entropy</code></a>(image[, base])</td> <td>Calculate the Shannon entropy of an image.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.LineModelND" title="skimage.measure.LineModelND"><code>skimage.measure.LineModelND</code></a>()</td> <td>Total least squares estimator for N-dimensional lines.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.CircleModel" title="skimage.measure.CircleModel"><code>skimage.measure.CircleModel</code></a>()</td> <td>Total least squares estimator for 2D circles.</td> </tr> <tr>
<td>
<a class="reference internal" href="#skimage.measure.EllipseModel" title="skimage.measure.EllipseModel"><code>skimage.measure.EllipseModel</code></a>()</td> <td>Total least squares estimator for 2D ellipses.</td> </tr>  </table>  <h2 id="find-contours">find_contours</h2> <dl class="function"> <dt id="skimage.measure.find_contours">
<code>skimage.measure.find_contours(array, level, fully_connected='low', positive_orientation='low')</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_find_contours.py#L9"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Find iso-valued contours in a 2D array for a given level value.</p> <p>Uses the “marching squares” method to compute a the iso-valued contours of the input 2D array for a particular level value. Array values are linearly interpolated to provide better precision for the output contours.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>array : 2D ndarray of double</code> </dt> <dd>
<p class="first last">Input data in which to find contours.</p> </dd> <dt>
<code>level : float</code> </dt> <dd>
<p class="first last">Value along which to find contours in the array.</p> </dd> <dt>
<code>fully_connected : str, {‘low’, ‘high’}</code> </dt> <dd>
<p class="first last">Indicates whether array elements below the given level value are to be considered fully-connected (and hence elements above the value will only be face connected), or vice-versa. (See notes below for details.)</p> </dd> <dt>
<code>positive_orientation : either ‘low’ or ‘high’</code> </dt> <dd>
<p class="first last">Indicates whether the output contours will produce positively-oriented polygons around islands of low- or high-valued elements. If ‘low’ then contours will wind counter- clockwise around elements below the iso-value. Alternately, this means that low-valued elements are always on the left of the contour. (See below for details.)</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>contours : list of (n,2)-ndarrays</code> </dt> <dd>
<p class="first last">Each contour is an ndarray of shape <code>(n, 2)</code>, consisting of n <code>(row, column)</code> coordinates along the contour.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The marching squares algorithm is a special case of the marching cubes algorithm <a class="reference internal" href="#r8ed60f468bf9-1" id="id1">[1]</a>. A simple explanation is available here:</p> <pre data-language="python">http://www.essi.fr/~lingrand/MarchingCubes/algo.html
</pre> <p>There is a single ambiguous case in the marching squares algorithm: when a given <code>2 x 2</code>-element square has two high-valued and two low-valued elements, each pair diagonally adjacent. (Where high- and low-valued is with respect to the contour value sought.) In this case, either the high-valued elements can be ‘connected together’ via a thin isthmus that separates the low-valued elements, or vice-versa. When elements are connected together across a diagonal, they are considered ‘fully connected’ (also known as ‘face+vertex-connected’ or ‘8-connected’). Only high-valued or low-valued elements can be fully-connected, the other set will be considered as ‘face-connected’ or ‘4-connected’. By default, low-valued elements are considered fully-connected; this can be altered with the ‘fully_connected’ parameter.</p> <p>Output contours are not guaranteed to be closed: contours which intersect the array edge will be left open. All other contours will be closed. (The closed-ness of a contours can be tested by checking whether the beginning point is the same as the end point.)</p> <p>Contours are oriented. By default, array values lower than the contour value are to the left of the contour and values greater than the contour value are to the right. This means that contours will wind counter-clockwise (i.e. in ‘positive orientation’) around islands of low-valued pixels. This behavior can be altered with the ‘positive_orientation’ parameter.</p> <p>The order of the contours in the output list is determined by the position of the smallest <code>x,y</code> (in lexicographical order) coordinate in the contour. This is a side-effect of how the input array is traversed, but can be relied upon.</p> <div class="admonition warning"> <p class="first admonition-title">Warning</p> <p class="last">Array coordinates/values are assumed to refer to the <em>center</em> of the array element. Take a simple example input: <code>[0, 1]</code>. The interpolated position of 0.5 in this array is midway between the 0-element (at <code>x=0</code>) and the 1-element (at <code>x=1</code>), and thus would fall at <code>x=0.5</code>.</p> </div> <p>This means that to find reasonable contours, it is best to find contours midway between the expected “light” and “dark” values. In particular, given a binarized array, <em>do not</em> choose to find contours at the low or high value of the array. This will often yield degenerate contours, especially around structures that are a single array element wide. Instead choose a middle value, as above.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r8ed60f468bf9-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id2">2</a>)</em> Lorensen, William and Harvey E. Cline. Marching Cubes: A High Resolution 3D Surface Construction Algorithm. Computer Graphics (SIGGRAPH 87 Proceedings) 21(4) July 1987, p. 163-170).</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; a = np.zeros((3, 3))
&gt;&gt;&gt; a[0, 0] = 1
&gt;&gt;&gt; a
array([[ 1.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])
&gt;&gt;&gt; find_contours(a, 0.5)
[array([[ 0. ,  0.5],
       [ 0.5,  0. ]])]
</pre> </dd>
</dl>   <h2 id="regionprops">regionprops</h2> <dl class="function"> <dt id="skimage.measure.regionprops">
<code>skimage.measure.regionprops(label_image, intensity_image=None, cache=True, coordinates=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_regionprops.py#L361"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Measure properties of labeled image regions.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>label_image : (N, M) ndarray</code> </dt> <dd>
<p class="first last">Labeled input image. Labels with value 0 are ignored.</p> </dd> <dt>
<code>intensity_image : (N, M) ndarray, optional</code> </dt> <dd>
<p class="first last">Intensity (i.e., input) image with same size as labeled image. Default is None.</p> </dd> <dt>
<code>cache : bool, optional</code> </dt> <dd>
<p class="first last">Determine whether to cache calculated properties. The computation is much faster for cached properties, whereas the memory consumption increases.</p> </dd> <dt>
<code>coordinates : ‘rc’ or ‘xy’, optional</code> </dt> <dd>
<p class="first last">Coordinate conventions for 2D images. (Only ‘rc’ coordinates are supported for 3D images.)</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>properties : list of RegionProperties</code> </dt> <dd>
<p class="first last">Each item describes one labeled region, and can be accessed using the attributes listed below.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.label" title="skimage.measure.label"><code>label</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>The following properties can be accessed as attributes or keys:</p> <dl class="docutils"> <dt>
<code>area : int</code> </dt> <dd>Number of pixels of region.</dd> <dt>
<code>bbox : tuple</code> </dt> <dd>Bounding box <code>(min_row, min_col, max_row, max_col)</code>. Pixels belonging to the bounding box are in the half-open interval <code>[min_row; max_row)</code> and <code>[min_col; max_col)</code>.</dd> <dt>
<code>bbox_area : int</code> </dt> <dd>Number of pixels of bounding box.</dd> <dt>
<code>centroid : array</code> </dt> <dd>Centroid coordinate tuple <code>(row, col)</code>.</dd> <dt>
<code>convex_area : int</code> </dt> <dd>Number of pixels of convex hull image.</dd> <dt>
<code>convex_image : (H, J) ndarray</code> </dt> <dd>Binary convex hull image which has the same size as bounding box.</dd> <dt>
<code>coords : (N, 2) ndarray</code> </dt> <dd>Coordinate list <code>(row, col)</code> of the region.</dd> <dt>
<code>eccentricity : float</code> </dt> <dd>Eccentricity of the ellipse that has the same second-moments as the region. The eccentricity is the ratio of the focal distance (distance between focal points) over the major axis length. The value is in the interval [0, 1). When it is 0, the ellipse becomes a circle.</dd> <dt>
<code>equivalent_diameter : float</code> </dt> <dd>The diameter of a circle with the same area as the region.</dd> <dt>
<code>euler_number : int</code> </dt> <dd>Euler characteristic of region. Computed as number of objects (= 1) subtracted by number of holes (8-connectivity).</dd> <dt>
<code>extent : float</code> </dt> <dd>Ratio of pixels in the region to pixels in the total bounding box. Computed as <code>area / (rows * cols)</code>
</dd> <dt>
<code>filled_area : int</code> </dt> <dd>Number of pixels of filled region.</dd> <dt>
<code>filled_image : (H, J) ndarray</code> </dt> <dd>Binary region image with filled holes which has the same size as bounding box.</dd> <dt>
<code>image : (H, J) ndarray</code> </dt> <dd>Sliced binary region image which has the same size as bounding box.</dd> <dt>
<code>inertia_tensor : (2, 2) ndarray</code> </dt> <dd>Inertia tensor of the region for the rotation around its mass.</dd> <dt>
<code>inertia_tensor_eigvals : tuple</code> </dt> <dd>The two eigen values of the inertia tensor in decreasing order.</dd> <dt>
<code>intensity_image : ndarray</code> </dt> <dd>Image inside region bounding box.</dd> <dt>
<code>label : int</code> </dt> <dd>The label in the labeled input image.</dd> <dt>
<code>local_centroid : array</code> </dt> <dd>Centroid coordinate tuple <code>(row, col)</code>, relative to region bounding box.</dd> <dt>
<code>major_axis_length : float</code> </dt> <dd>The length of the major axis of the ellipse that has the same normalized second central moments as the region.</dd> <dt>
<code>max_intensity : float</code> </dt> <dd>Value with the greatest intensity in the region.</dd> <dt>
<code>mean_intensity : float</code> </dt> <dd>Value with the mean intensity in the region.</dd> <dt>
<code>min_intensity : float</code> </dt> <dd>Value with the least intensity in the region.</dd> <dt>
<code>minor_axis_length : float</code> </dt> <dd>The length of the minor axis of the ellipse that has the same normalized second central moments as the region.</dd> <dt>
<code>moments : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Spatial moments up to 3rd order:</p> <pre data-language="python">m_ji = sum{ array(x, y) * x^j * y^i }
</pre> <p class="last">where the sum is over the <code>x</code>, <code>y</code> coordinates of the region.</p> </dd> <dt>
<code>moments_central : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Central moments (translation invariant) up to 3rd order:</p> <pre data-language="python">mu_ji = sum{ array(x, y) * (x - x_c)^j * (y - y_c)^i }
</pre> <p class="last">where the sum is over the <code>x</code>, <code>y</code> coordinates of the region, and <code>x_c</code> and <code>y_c</code> are the coordinates of the region’s centroid.</p> </dd> <dt>
<code>moments_hu : tuple</code> </dt> <dd>Hu moments (translation, scale and rotation invariant).</dd> <dt>
<code>moments_normalized : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Normalized moments (translation and scale invariant) up to 3rd order:</p> <pre data-language="python">nu_ji = mu_ji / m_00^[(i+j)/2 + 1]
</pre> <p class="last">where <code>m_00</code> is the zeroth spatial moment.</p> </dd> <dt>
<code>orientation : float</code> </dt> <dd>
<p class="first">In ‘rc’ coordinates, angle between the 0th axis (rows) and the major axis of the ellipse that has the same second moments as the region, ranging from <code>-pi/2</code> to <code>pi/2</code> counter-clockwise.</p> <p class="last">In <code>xy</code> coordinates, as above but the angle is now measured from the “x” or horizontal axis.</p> </dd> <dt>
<code>perimeter : float</code> </dt> <dd>Perimeter of object which approximates the contour as a line through the centers of border pixels using a 4-connectivity.</dd> <dt>
<code>solidity : float</code> </dt> <dd>Ratio of pixels in the region to pixels of the convex hull image.</dd> <dt>
<code>weighted_centroid : array</code> </dt> <dd>Centroid coordinate tuple <code>(row, col)</code> weighted with intensity image.</dd> <dt>
<code>weighted_local_centroid : array</code> </dt> <dd>Centroid coordinate tuple <code>(row, col)</code>, relative to region bounding box, weighted with intensity image.</dd> <dt>
<code>weighted_moments : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Spatial moments of intensity image up to 3rd order:</p> <pre data-language="python">wm_ji = sum{ array(x, y) * x^j * y^i }
</pre> <p class="last">where the sum is over the <code>x</code>, <code>y</code> coordinates of the region.</p> </dd> <dt>
<code>weighted_moments_central : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Central moments (translation invariant) of intensity image up to 3rd order:</p> <pre data-language="python">wmu_ji = sum{ array(x, y) * (x - x_c)^j * (y - y_c)^i }
</pre> <p class="last">where the sum is over the <code>x</code>, <code>y</code> coordinates of the region, and <code>x_c</code> and <code>y_c</code> are the coordinates of the region’s weighted centroid.</p> </dd> <dt>
<code>weighted_moments_hu : tuple</code> </dt> <dd>Hu moments (translation, scale and rotation invariant) of intensity image.</dd> <dt>
<code>weighted_moments_normalized : (3, 3) ndarray</code> </dt> <dd>
<p class="first">Normalized moments (translation and scale invariant) of intensity image up to 3rd order:</p> <pre data-language="python">wnu_ji = wmu_ji / wm_00^[(i+j)/2 + 1]
</pre> <p class="last">where <code>wm_00</code> is the zeroth spatial moment (intensity-weighted area).</p> </dd> </dl> <p>Each region also supports iteration, so that you can do:</p> <pre data-language="python">for prop in region:
    print(prop, region[prop])
</pre> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r4a29d8446b4f-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id3">[1]</a></td>
<td>Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r4a29d8446b4f-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id4">[2]</a></td>
<td>B. Jähne. Digital Image Processing. Springer-Verlag, Berlin-Heidelberg, 6. edition, 2005.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r4a29d8446b4f-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id5">[3]</a></td>
<td>T. H. Reiss. Recognizing Planar Objects Using Invariant Image Features, from Lecture notes in computer science, p. 676. Springer, Berlin, 1993.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r4a29d8446b4f-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id6">[4]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Image_moment">http://en.wikipedia.org/wiki/Image_moment</a></td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data, util
&gt;&gt;&gt; from skimage.measure import label
&gt;&gt;&gt; img = util.img_as_ubyte(data.coins()) &gt; 110
&gt;&gt;&gt; label_img = label(img, connectivity=img.ndim)
&gt;&gt;&gt; props = regionprops(label_img)
&gt;&gt;&gt; # centroid of first labeled object
&gt;&gt;&gt; props[0].centroid
(22.729879860483141, 81.912285234465827)
&gt;&gt;&gt; # centroid of first labeled object
&gt;&gt;&gt; props[0]['centroid']
(22.729879860483141, 81.912285234465827)
</pre> </dd>
</dl>   <h2 id="perimeter">perimeter</h2> <dl class="function"> <dt id="skimage.measure.perimeter">
<code>skimage.measure.perimeter(image, neighbourhood=4)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_regionprops.py#L575"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate total perimeter of all objects in binary image.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : array</code> </dt> <dd>
<p class="first last">Binary image.</p> </dd> <dt>
<code>neighbourhood : 4 or 8, optional</code> </dt> <dd>
<p class="first last">Neighborhood connectivity for border pixel determination.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>perimeter : float</code> </dt> <dd>
<p class="first last">Total perimeter of all objects in binary image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r5745cfa18943-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id7">[1]</a></td>
<td>K. Benkrid, D. Crookes. Design and FPGA Implementation of a Perimeter Estimator. The Queen’s University of Belfast. <a class="reference external" href="http://www.cs.qub.ac.uk/~d.crookes/webpubs/papers/perimeter.doc">http://www.cs.qub.ac.uk/~d.crookes/webpubs/papers/perimeter.doc</a>
</td>
</tr>  </table> </dd>
</dl>   <h2 id="approximate-polygon">approximate_polygon</h2> <dl class="function"> <dt id="skimage.measure.approximate_polygon">
<code>skimage.measure.approximate_polygon(coords, tolerance)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_polygon.py#L5"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Approximate a polygonal chain with the specified tolerance.</p> <p>It is based on the Douglas-Peucker algorithm.</p> <p>Note that the approximated polygon is always within the convex hull of the original polygon.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Coordinate array.</p> </dd> <dt>
<code>tolerance : float</code> </dt> <dd>
<p class="first last">Maximum distance from original points of polygon to approximated polygonal chain. If tolerance is 0, the original coordinate array is returned.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (M, 2) array</code> </dt> <dd>
<p class="first last">Approximated polygonal chain where M &lt;= N.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rb46d085928c9-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id8">[1]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm">http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="subdivide-polygon">subdivide_polygon</h2> <dl class="function"> <dt id="skimage.measure.subdivide_polygon">
<code>skimage.measure.subdivide_polygon(coords, degree=2, preserve_ends=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_polygon.py#L109"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Subdivision of polygonal curves using B-Splines.</p> <p>Note that the resulting curve is always within the convex hull of the original polygon. Circular polygons stay closed after subdivision.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, 2) array</code> </dt> <dd>
<p class="first last">Coordinate array.</p> </dd> <dt>
<code>degree : {1, 2, 3, 4, 5, 6, 7}, optional</code> </dt> <dd>
<p class="first last">Degree of B-Spline. Default is 2.</p> </dd> <dt>
<code>preserve_ends : bool, optional</code> </dt> <dd>
<p class="first last">Preserve first and last coordinate of non-circular polygon. Default is False.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coords : (M, 2) array</code> </dt> <dd>
<p class="first last">Subdivided coordinate array.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r13f3ce062a97-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id9">[1]</a></td>
<td><a class="reference external" href="http://mrl.nyu.edu/publications/subdiv-course2000/coursenotes00.pdf">http://mrl.nyu.edu/publications/subdiv-course2000/coursenotes00.pdf</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="ransac">ransac</h2> <dl class="function"> <dt id="skimage.measure.ransac">
<code>skimage.measure.ransac(data, model_class, min_samples, residual_threshold, is_data_valid=None, is_model_valid=None, max_trials=100, stop_sample_num=inf, stop_residuals_sum=0, stop_probability=1, random_state=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L619"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit a model to data with the RANSAC (random sample consensus) algorithm.</p> <p>RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set. Each iteration performs the following tasks:</p> <ol class="arabic simple"> <li>Select <code>min_samples</code> random samples from the original data and check whether the set of data is valid (see <code>is_data_valid</code>).</li> <li>Estimate a model to the random subset (<code>model_cls.estimate(*data[random_subset]</code>) and check whether the estimated model is valid (see <code>is_model_valid</code>).</li> <li>Classify all data as inliers or outliers by calculating the residuals to the estimated model (<code>model_cls.residuals(*data)</code>) - all data samples with residuals smaller than the <code>residual_threshold</code> are considered as inliers.</li> <li>Save estimated model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has less sum of residuals.</li> </ol> <p>These steps are performed either a maximum number of times or until one of the special stop criteria are met. The final model is estimated using all inlier samples of the previously determined best model.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : [list, tuple of] (N, D) array</code> </dt> <dd>
<p class="first last">Data set to which the model is fitted, where N is the number of data points and D the dimensionality of the data. If the model class requires multiple input data arrays (e.g. source and destination coordinates of <code>skimage.transform.AffineTransform</code>), they can be optionally passed as tuple or list. Note, that in this case the functions <code>estimate(*data)</code>, <code>residuals(*data)</code>, <code>is_model_valid(model, *random_data)</code> and <code>is_data_valid(*random_data)</code> must all take each data array as separate arguments.</p> </dd> <dt>
<code>model_class : object</code> </dt> <dd>
<p class="first">Object with the following object methods:</p>  <ul class="simple"> <li><code>success = estimate(*data)</code></li> <li><code>residuals(*data)</code></li> </ul>  <p class="last">where <code>success</code> indicates whether the model estimation succeeded (<code>True</code> or <code>None</code> for success, <code>False</code> for failure).</p> </dd> <dt>
<code>min_samples : int</code> </dt> <dd>
<p class="first last">The minimum number of data points to fit a model to.</p> </dd> <dt>
<code>residual_threshold : float</code> </dt> <dd>
<p class="first last">Maximum distance for a data point to be classified as an inlier.</p> </dd> <dt>
<code>is_data_valid : function, optional</code> </dt> <dd>
<p class="first last">This function is called with the randomly selected data before the model is fitted to it: <code>is_data_valid(*random_data)</code>.</p> </dd> <dt>
<code>is_model_valid : function, optional</code> </dt> <dd>
<p class="first last">This function is called with the estimated model and the randomly selected data: <code>is_model_valid(model, *random_data)</code>, .</p> </dd> <dt>
<code>max_trials : int, optional</code> </dt> <dd>
<p class="first last">Maximum number of iterations for random sample selection.</p> </dd> <dt>
<code>stop_sample_num : int, optional</code> </dt> <dd>
<p class="first last">Stop iteration if at least this number of inliers are found.</p> </dd> <dt>
<code>stop_residuals_sum : float, optional</code> </dt> <dd>
<p class="first last">Stop iteration if sum of residuals is less than or equal to this threshold.</p> </dd> <dt>
<code>stop_probability : float in range [0, 1], optional</code> </dt> <dd>
<p class="first">RANSAC iteration stops if at least one outlier-free set of the training data is sampled with <code>probability &gt;= stop_probability</code>, depending on the current best model’s inlier ratio and the number of trials. This requires to generate at least N samples (trials):</p>  <p>N &gt;= log(1 - probability) / log(1 - e**m)</p>  <p class="last">where the probability (confidence) is typically set to a high value such as 0.99, and e is the current fraction of inliers w.r.t. the total number of samples.</p> </dd> <dt>
<code>random_state : int, RandomState instance or None, optional</code> </dt> <dd>
<p class="first last">If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>model : object</code> </dt> <dd>
<p class="first last">Best model with largest consensus set.</p> </dd> <dt>
<code>inliers : (N, ) array</code> </dt> <dd>
<p class="first last">Boolean mask of inliers classified as <code>True</code>.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="radbaf2717b1f-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id10">[1]</a></td>
<td>“RANSAC”, Wikipedia, <a class="reference external" href="http://en.wikipedia.org/wiki/RANSAC">http://en.wikipedia.org/wiki/RANSAC</a>
</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <p>Generate ellipse data without tilt and add noise:</p> <pre data-language="python">&gt;&gt;&gt; t = np.linspace(0, 2 * np.pi, 50)
&gt;&gt;&gt; xc, yc = 20, 30
&gt;&gt;&gt; a, b = 5, 10
&gt;&gt;&gt; x = xc + a * np.cos(t)
&gt;&gt;&gt; y = yc + b * np.sin(t)
&gt;&gt;&gt; data = np.column_stack([x, y])
&gt;&gt;&gt; np.random.seed(seed=1234)
&gt;&gt;&gt; data += np.random.normal(size=data.shape)
</pre> <p>Add some faulty data:</p> <pre data-language="python">&gt;&gt;&gt; data[0] = (100, 100)
&gt;&gt;&gt; data[1] = (110, 120)
&gt;&gt;&gt; data[2] = (120, 130)
&gt;&gt;&gt; data[3] = (140, 130)
</pre> <p>Estimate ellipse model using all available data:</p> <pre data-language="python">&gt;&gt;&gt; model = EllipseModel()
&gt;&gt;&gt; model.estimate(data)
True
&gt;&gt;&gt; np.round(model.params)  # doctest: +SKIP
array([ 72.,  75.,  77.,  14.,   1.])
</pre> <p>Estimate ellipse model using RANSAC:</p> <pre data-language="python">&gt;&gt;&gt; ransac_model, inliers = ransac(data, EllipseModel, 20, 3, max_trials=50)
&gt;&gt;&gt; abs(np.round(ransac_model.params))
array([ 20.,  30.,   5.,  10.,   0.])
&gt;&gt;&gt; inliers # doctest: +SKIP
array([False, False, False, False,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True], dtype=bool)
&gt;&gt;&gt; sum(inliers) &gt; 40
True
</pre> <p>Robustly estimate geometric transformation:</p> <pre data-language="python">&gt;&gt;&gt; from skimage.transform import SimilarityTransform
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; src = 100 * np.random.rand(50, 2)
&gt;&gt;&gt; model0 = SimilarityTransform(scale=0.5, rotation=1,
...                              translation=(10, 20))
&gt;&gt;&gt; dst = model0(src)
&gt;&gt;&gt; dst[0] = (10000, 10000)
&gt;&gt;&gt; dst[1] = (-100, 100)
&gt;&gt;&gt; dst[2] = (50, 50)
&gt;&gt;&gt; model, inliers = ransac((src, dst), SimilarityTransform, 2, 10)
&gt;&gt;&gt; inliers
array([False, False, False,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True], dtype=bool)
</pre> </dd>
</dl>   <h2 id="block-reduce">block_reduce</h2> <dl class="function"> <dt id="skimage.measure.block_reduce">
<code>skimage.measure.block_reduce(image, block_size, func=&lt;function sum&gt;, cval=0)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/block.py#L5"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Down-sample image by applying function to local blocks.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">N-dimensional input image.</p> </dd> <dt>
<code>block_size : array_like</code> </dt> <dd>
<p class="first last">Array containing down-sampling integer factor along each axis.</p> </dd> <dt>
<code>func : callable</code> </dt> <dd>
<p class="first last">Function object which is used to calculate the return value for each local block. This function must implement an <code>axis</code> parameter such as <code>numpy.sum</code> or <code>numpy.min</code>.</p> </dd> <dt>
<code>cval : float</code> </dt> <dd>
<p class="first last">Constant padding value if image is not perfectly divisible by the block size.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>image : ndarray</code> </dt> <dd>
<p class="first last">Down-sampled image with same number of dimensions as input image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage.measure import block_reduce
&gt;&gt;&gt; image = np.arange(3*3*4).reshape(3, 3, 4)
&gt;&gt;&gt; image # doctest: +NORMALIZE_WHITESPACE
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]],
       [[12, 13, 14, 15],
        [16, 17, 18, 19],
        [20, 21, 22, 23]],
       [[24, 25, 26, 27],
        [28, 29, 30, 31],
        [32, 33, 34, 35]]])
&gt;&gt;&gt; block_reduce(image, block_size=(3, 3, 1), func=np.mean)
array([[[ 16.,  17.,  18.,  19.]]])
&gt;&gt;&gt; image_max1 = block_reduce(image, block_size=(1, 3, 4), func=np.max)
&gt;&gt;&gt; image_max1 # doctest: +NORMALIZE_WHITESPACE
array([[[11]],
       [[23]],
       [[35]]])
&gt;&gt;&gt; image_max2 = block_reduce(image, block_size=(3, 1, 4), func=np.max)
&gt;&gt;&gt; image_max2 # doctest: +NORMALIZE_WHITESPACE
array([[[27],
        [31],
        [35]]])
</pre> </dd>
</dl>   <h2 id="moments">moments</h2> <dl class="function"> <dt id="skimage.measure.moments">
<code>skimage.measure.moments(image, order=3)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L152"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate all raw image moments up to a certain order.</p> <dl class="docutils"> <dt>The following properties can be calculated from raw image moments:</dt> <dd>
<ul class="first last simple"> <li>Area as: <code>M[0, 0]</code>.</li> <li>Centroid as: {<code>M[1, 0] / M[0, 0]</code>, <code>M[0, 1] / M[0, 0]</code>}.</li> </ul> </dd> </dl> <p>Note that raw moments are neither translation, scale nor rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : nD double or uint8 array</code> </dt> <dd>
<p class="first last">Rasterized shape as image.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Maximum order of moments. Default is 3.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>m : (order + 1, order + 1) array</code> </dt> <dd>
<p class="first last">Raw image moments.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r3012f4679c28-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id11">[1]</a></td>
<td>Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r3012f4679c28-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id12">[2]</a></td>
<td>B. Jähne. Digital Image Processing. Springer-Verlag, Berlin-Heidelberg, 6. edition, 2005.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r3012f4679c28-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id13">[3]</a></td>
<td>T. H. Reiss. Recognizing Planar Objects Using Invariant Image Features, from Lecture notes in computer science, p. 676. Springer, Berlin, 1993.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r3012f4679c28-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id14">[4]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Image_moment">http://en.wikipedia.org/wiki/Image_moment</a></td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; image = np.zeros((20, 20), dtype=np.double)
&gt;&gt;&gt; image[13:17, 13:17] = 1
&gt;&gt;&gt; M = moments(image)
&gt;&gt;&gt; cr = M[1, 0] / M[0, 0]
&gt;&gt;&gt; cc = M[0, 1] / M[0, 0]
&gt;&gt;&gt; cr, cc
(14.5, 14.5)
</pre> </dd>
</dl>   <h2 id="moments-central">moments_central</h2> <dl class="function"> <dt id="skimage.measure.moments_central">
<code>skimage.measure.moments_central(image, center=None, cc=None, order=3, **kwargs)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L198"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate all central image moments up to a certain order.</p> <p>The center coordinates (cr, cc) can be calculated from the raw moments as: {<code>M[1, 0] / M[0, 0]</code>, <code>M[0, 1] / M[0, 0]</code>}.</p> <p>Note that central moments are translation invariant but not scale and rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : nD double or uint8 array</code> </dt> <dd>
<p class="first last">Rasterized shape as image.</p> </dd> <dt>
<code>center : tuple of float, optional</code> </dt> <dd>
<p class="first last">Coordinates of the image centroid. This will be computed if it is not provided.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">The maximum order of moments computed.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>mu : (order + 1, order + 1) array</code> </dt> <dd>
<p class="first last">Central image moments.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>cr : double</code> </dt> <dd>
<p class="first last">DEPRECATED: Center row coordinate for 2D image.</p> </dd> <dt>
<code>cc : double</code> </dt> <dd>
<p class="first last">DEPRECATED: Center column coordinate for 2D image.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="re30db7550969-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id15">[1]</a></td>
<td>Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="re30db7550969-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id16">[2]</a></td>
<td>B. Jähne. Digital Image Processing. Springer-Verlag, Berlin-Heidelberg, 6. edition, 2005.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="re30db7550969-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id17">[3]</a></td>
<td>T. H. Reiss. Recognizing Planar Objects Using Invariant Image Features, from Lecture notes in computer science, p. 676. Springer, Berlin, 1993.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="re30db7550969-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id18">[4]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Image_moment">http://en.wikipedia.org/wiki/Image_moment</a></td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; image = np.zeros((20, 20), dtype=np.double)
&gt;&gt;&gt; image[13:17, 13:17] = 1
&gt;&gt;&gt; M = moments(image)
&gt;&gt;&gt; cr = M[1, 0] / M[0, 0]
&gt;&gt;&gt; cc = M[0, 1] / M[0, 0]
&gt;&gt;&gt; moments_central(image, (cr, cc))
array([[ 16.,   0.,  20.,   0.],
       [  0.,   0.,   0.,   0.],
       [ 20.,   0.,  25.,   0.],
       [  0.,   0.,   0.,   0.]])
</pre> </dd>
</dl>   <h2 id="moments-coords">moments_coords</h2> <dl class="function"> <dt id="skimage.measure.moments_coords">
<code>skimage.measure.moments_coords(coords, order=3)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L10"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate all raw image moments up to a certain order.</p> <dl class="docutils"> <dt>The following properties can be calculated from raw image moments:</dt> <dd>
<ul class="first last simple"> <li>Area as: <code>M[0, 0]</code>.</li> <li>Centroid as: {<code>M[1, 0] / M[0, 0]</code>, <code>M[0, 1] / M[0, 0]</code>}.</li> </ul> </dd> </dl> <p>Note that raw moments are neither translation, scale nor rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, D) double or uint8 array</code> </dt> <dd>
<p class="first last">Array of N points that describe an image of D dimensionality in Cartesian space.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Maximum order of moments. Default is 3.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>M : (order + 1, order + 1, …) array</code> </dt> <dd>
<p class="first last">Raw image moments. (D dimensions)</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r1906bd878ddc-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id19">[1]</a></td>
<td>Johannes Kilian. Simple Image Analysis By Moments. Durham University, version 0.2, Durham, 2001.</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; coords = np.array([[row, col]
...                    for row in range(13, 17)
...                    for col in range(14, 18)], dtype=np.double)
&gt;&gt;&gt; M = moments_coords(coords)
&gt;&gt;&gt; centroid_row = M[1, 0] / M[0, 0]
&gt;&gt;&gt; centroid_col = M[0, 1] / M[0, 0]
&gt;&gt;&gt; centroid_row, centroid_col
(14.5, 15.5)
</pre> </dd>
</dl>   <h2 id="moments-coords-central">moments_coords_central</h2> <dl class="function"> <dt id="skimage.measure.moments_coords_central">
<code>skimage.measure.moments_coords_central(coords, center=None, order=3)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L52"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate all central image moments up to a certain order.</p> <dl class="docutils"> <dt>The following properties can be calculated from raw image moments:</dt> <dd>
<ul class="first last simple"> <li>Area as: <code>M[0, 0]</code>.</li> <li>Centroid as: {<code>M[1, 0] / M[0, 0]</code>, <code>M[0, 1] / M[0, 0]</code>}.</li> </ul> </dd> </dl> <p>Note that raw moments are neither translation, scale nor rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>coords : (N, D) double or uint8 array</code> </dt> <dd>
<p class="first last">Array of N points that describe an image of D dimensionality in Cartesian space. A tuple of coordinates as returned by <code>np.nonzero</code> is also accepted as input.</p> </dd> <dt>
<code>center : tuple of float, optional</code> </dt> <dd>
<p class="first last">Coordinates of the image centroid. This will be computed if it is not provided.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Maximum order of moments. Default is 3.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>Mc : (order + 1, order + 1, …) array</code> </dt> <dd>
<p class="first last">Central image moments. (D dimensions)</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rdba8c2d58a27-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id20">[1]</a></td>
<td>Johannes Kilian. Simple Image Analysis By Moments. Durham University, version 0.2, Durham, 2001.</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; coords = np.array([[row, col]
...                    for row in range(13, 17)
...                    for col in range(14, 18)])
&gt;&gt;&gt; moments_coords_central(coords)
array([[ 16.,   0.,  20.,   0.],
       [  0.,   0.,   0.,   0.],
       [ 20.,   0.,  25.,   0.],
       [  0.,   0.,   0.,   0.]])
</pre> <p>As seen above, for symmetric objects, odd-order moments (columns 1 and 3, rows 1 and 3) are zero when centered on the centroid, or center of mass, of the object (the default). If we break the symmetry by adding a new point, this no longer holds:</p> <pre data-language="python">&gt;&gt;&gt; coords2 = np.concatenate((coords, [[17, 17]]), axis=0)
&gt;&gt;&gt; np.round(moments_coords_central(coords2), 2)
array([[ 17.  ,   0.  ,  22.12,  -2.49],
       [  0.  ,   3.53,   1.73,   7.4 ],
       [ 25.88,   6.02,  36.63,   8.83],
       [  4.15,  19.17,  14.8 ,  39.6 ]])
</pre> <p>Image moments and central image moments are equivalent (by definition) when the center is (0, 0):</p> <pre data-language="python">&gt;&gt;&gt; np.allclose(moments_coords(coords),
...             moments_coords_central(coords, (0, 0)))
True
</pre> </dd>
</dl>   <h2 id="moments-normalized">moments_normalized</h2> <dl class="function"> <dt id="skimage.measure.moments_normalized">
<code>skimage.measure.moments_normalized(mu, order=3)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L276"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate all normalized central image moments up to a certain order.</p> <p>Note that normalized central moments are translation and scale invariant but not rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>mu : (M,[ …,] M) array</code> </dt> <dd>
<p class="first last">Central image moments, where M must be greater than or equal to <code>order</code>.</p> </dd> <dt>
<code>order : int, optional</code> </dt> <dd>
<p class="first last">Maximum order of moments. Default is 3.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>nu : (order + 1,[ …,] order + 1) array</code> </dt> <dd>
<p class="first last">Normalized central image moments.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rc5867b15e1bf-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id21">[1]</a></td>
<td>Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rc5867b15e1bf-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id22">[2]</a></td>
<td>B. Jähne. Digital Image Processing. Springer-Verlag, Berlin-Heidelberg, 6. edition, 2005.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rc5867b15e1bf-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id23">[3]</a></td>
<td>T. H. Reiss. Recognizing Planar Objects Using Invariant Image Features, from Lecture notes in computer science, p. 676. Springer, Berlin, 1993.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rc5867b15e1bf-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id24">[4]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Image_moment">http://en.wikipedia.org/wiki/Image_moment</a></td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; image = np.zeros((20, 20), dtype=np.double)
&gt;&gt;&gt; image[13:17, 13:17] = 1
&gt;&gt;&gt; m = moments(image)
&gt;&gt;&gt; cr = m[0, 1] / m[0, 0]
&gt;&gt;&gt; cc = m[1, 0] / m[0, 0]
&gt;&gt;&gt; mu = moments_central(image, cr, cc)
&gt;&gt;&gt; moments_normalized(mu)
array([[        nan,         nan,  0.078125  ,  0.        ],
       [        nan,  0.        ,  0.        ,  0.        ],
       [ 0.078125  ,  0.        ,  0.00610352,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ]])
</pre> </dd>
</dl>   <h2 id="moments-hu">moments_hu</h2> <dl class="function"> <dt id="skimage.measure.moments_hu">
<code>skimage.measure.moments_hu(nu)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_moments.py#L333"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate Hu’s set of image moments (2D-only).</p> <p>Note that this set of moments is proofed to be translation, scale and rotation invariant.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>nu : (M, M) array</code> </dt> <dd>
<p class="first last">Normalized central image moments, where M must be &gt; 4.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>nu : (7,) array</code> </dt> <dd>
<p class="first last">Hu’s set of image moments.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r8f5f4137a534-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id25">[1]</a></td>
<td>M. K. Hu, “Visual Pattern Recognition by Moment Invariants”, IRE Trans. Info. Theory, vol. IT-8, pp. 179-187, 1962</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r8f5f4137a534-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id26">[2]</a></td>
<td>Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r8f5f4137a534-3" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id27">[3]</a></td>
<td>B. Jähne. Digital Image Processing. Springer-Verlag, Berlin-Heidelberg, 6. edition, 2005.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r8f5f4137a534-4" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id28">[4]</a></td>
<td>T. H. Reiss. Recognizing Planar Objects Using Invariant Image Features, from Lecture notes in computer science, p. 676. Springer, Berlin, 1993.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r8f5f4137a534-5" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id29">[5]</a></td>
<td><a class="reference external" href="http://en.wikipedia.org/wiki/Image_moment">http://en.wikipedia.org/wiki/Image_moment</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="marching-cubes-lewiner">marching_cubes_lewiner</h2> <dl class="function"> <dt id="skimage.measure.marching_cubes_lewiner">
<code>skimage.measure.marching_cubes_lewiner(volume, level=None, spacing=(1.0, 1.0, 1.0), gradient_direction='descent', step_size=1, allow_degenerate=True, use_classic=False)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_marching_cubes_lewiner.py#L16"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Lewiner marching cubes algorithm to find surfaces in 3d volumetric data.</p> <p>In contrast to <code>marching_cubes_classic()</code>, this algorithm is faster, resolves ambiguities, and guarantees topologically correct results. Therefore, this algorithm generally a better choice, unless there is a specific need for the classic algorithm.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>volume : (M, N, P) array</code> </dt> <dd>
<p class="first last">Input data volume to find isosurfaces. Will internally be converted to float32 if necessary.</p> </dd> <dt>
<code>level : float</code> </dt> <dd>
<p class="first last">Contour value to search for isosurfaces in <code>volume</code>. If not given or None, the average of the min and max of vol is used.</p> </dd> <dt>
<code>spacing : length-3 tuple of floats</code> </dt> <dd>
<p class="first last">Voxel spacing in spatial dimensions corresponding to numpy array indexing dimensions (M, N, P) as in <code>volume</code>.</p> </dd> <dt>
<code>gradient_direction : string</code> </dt> <dd>
<p class="first last">Controls if the mesh was generated from an isosurface with gradient descent toward objects of interest (the default), or the opposite, considering the <em>left-hand</em> rule. The two options are: * descent : Object was greater than exterior * ascent : Exterior was greater than object</p> </dd> <dt>
<code>step_size : int</code> </dt> <dd>
<p class="first last">Step size in voxels. Default 1. Larger steps yield faster but coarser results. The result will always be topologically correct though.</p> </dd> <dt>
<code>allow_degenerate : bool</code> </dt> <dd>
<p class="first last">Whether to allow degenerate (i.e. zero-area) triangles in the end-result. Default True. If False, degenerate triangles are removed, at the cost of making the algorithm slower.</p> </dd> <dt>
<code>use_classic : bool</code> </dt> <dd>
<p class="first last">If given and True, the classic marching cubes by Lorensen (1987) is used. This option is included for reference purposes. Note that this algorithm has ambiguities and is not guaranteed to produce a topologically correct result. The results with using this option are <em>not</em> generally the same as the <code>marching_cubes_classic()</code> function.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>verts : (V, 3) array</code> </dt> <dd>
<p class="first last">Spatial coordinates for V unique mesh vertices. Coordinate order matches input <code>volume</code> (M, N, P).</p> </dd> <dt>
<code>faces : (F, 3) array</code> </dt> <dd>
<p class="first last">Define triangular faces via referencing vertex indices from <code>verts</code>. This algorithm specifically outputs triangles, so each face has exactly three indices.</p> </dd> <dt>
<code>normals : (V, 3) array</code> </dt> <dd>
<p class="first last">The normal direction at each vertex, as calculated from the data.</p> </dd> <dt>
<code>values : (V, ) array</code> </dt> <dd>
<p class="first last">Gives a measure for the maximum value of the data in the local region near each vertex. This can be used by visualization tools to apply a colormap to the mesh.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.marching_cubes_classic" title="skimage.measure.marching_cubes_classic"><code>skimage.measure.marching_cubes_classic</code></a>, <a class="reference internal" href="#skimage.measure.mesh_surface_area" title="skimage.measure.mesh_surface_area"><code>skimage.measure.mesh_surface_area</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>The algorithm [1] is an improved version of Chernyaev’s Marching Cubes 33 algorithm. It is an efficient algorithm that relies on heavy use of lookup tables to handle the many different cases, keeping the algorithm relatively easy. This implementation is written in Cython, ported from Lewiner’s C++ implementation.</p> <p>To quantify the area of an isosurface generated by this algorithm, pass verts and faces to <code>skimage.measure.mesh_surface_area</code>.</p> <p>Regarding visualization of algorithm output, to contour a volume named <code>myvolume</code> about the level 0.0, using the <code>mayavi</code> package:</p> <pre data-language="python">&gt;&gt;&gt; from mayavi import mlab 
&gt;&gt;&gt; verts, faces, normals, values = marching_cubes_lewiner(myvolume, 0.0) 
&gt;&gt;&gt; mlab.triangular_mesh([vert[0] for vert in verts],
...                      [vert[1] for vert in verts],
...                      [vert[2] for vert in verts],
...                      faces) 
&gt;&gt;&gt; mlab.show() 
</pre> <p>Similarly using the <code>visvis</code> package:</p> <pre data-language="python">&gt;&gt;&gt; import visvis as vv 
&gt;&gt;&gt; verts, faces, normals, values = marching_cubes_lewiner(myvolume, 0.0) 
&gt;&gt;&gt; vv.mesh(np.fliplr(verts), faces, normals, values) 
&gt;&gt;&gt; vv.use().Run() 
</pre> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rda8f856612d5-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id30">[1]</a></td>
<td>Thomas Lewiner, Helio Lopes, Antonio Wilson Vieira and Geovan Tavares. Efficient implementation of Marching Cubes’ cases with topological guarantees. Journal of Graphics Tools 8(2) pp. 1-15 (december 2003). DOI: 10.1080/10867651.2003.10487582</td>
</tr>  </table> </dd>
</dl>   <h2 id="marching-cubes-classic">marching_cubes_classic</h2> <dl class="function"> <dt id="skimage.measure.marching_cubes_classic">
<code>skimage.measure.marching_cubes_classic(volume, level=None, spacing=(1.0, 1.0, 1.0), gradient_direction='descent')</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_marching_cubes_classic.py#L7"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Classic marching cubes algorithm to find surfaces in 3d volumetric data.</p> <p>Note that the <code>marching_cubes()</code> algorithm is recommended over this algorithm, because it’s faster and produces better results.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>volume : (M, N, P) array of doubles</code> </dt> <dd>
<p class="first last">Input data volume to find isosurfaces. Will be cast to <code>np.float64</code>.</p> </dd> <dt>
<code>level : float</code> </dt> <dd>
<p class="first last">Contour value to search for isosurfaces in <code>volume</code>. If not given or None, the average of the min and max of vol is used.</p> </dd> <dt>
<code>spacing : length-3 tuple of floats</code> </dt> <dd>
<p class="first last">Voxel spacing in spatial dimensions corresponding to numpy array indexing dimensions (M, N, P) as in <code>volume</code>.</p> </dd> <dt>
<code>gradient_direction : string</code> </dt> <dd>
<p class="first last">Controls if the mesh was generated from an isosurface with gradient descent toward objects of interest (the default), or the opposite. The two options are: * descent : Object was greater than exterior * ascent : Exterior was greater than object</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>verts : (V, 3) array</code> </dt> <dd>
<p class="first last">Spatial coordinates for V unique mesh vertices. Coordinate order matches input <code>volume</code> (M, N, P).</p> </dd> <dt>
<code>faces : (F, 3) array</code> </dt> <dd>
<p class="first last">Define triangular faces via referencing vertex indices from <code>verts</code>. This algorithm specifically outputs triangles, so each face has exactly three indices.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><code>skimage.measure.marching_cubes</code>, <a class="reference internal" href="#skimage.measure.mesh_surface_area" title="skimage.measure.mesh_surface_area"><code>skimage.measure.mesh_surface_area</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>The marching cubes algorithm is implemented as described in <a class="reference internal" href="#r1e43a330a523-1" id="id31">[1]</a>. A simple explanation is available here:</p> <pre data-language="python">http://www.essi.fr/~lingrand/MarchingCubes/algo.html
</pre> <p>There are several known ambiguous cases in the marching cubes algorithm. Using point labeling as in <a class="reference internal" href="#r1e43a330a523-1" id="id32">[1]</a>, Figure 4, as shown:</p> <pre data-language="python">    v8 ------ v7
   / |       / |        y
  /  |      /  |        ^  z
v4 ------ v3   |        | /
 |  v5 ----|- v6        |/          (note: NOT right handed!)
 |  /      |  /          ----&gt; x
 | /       | /
v1 ------ v2
</pre> <p>Most notably, if v4, v8, v2, and v6 are all &gt;= <code>level</code> (or any generalization of this case) two parallel planes are generated by this algorithm, separating v4 and v8 from v2 and v6. An equally valid interpretation would be a single connected thin surface enclosing all four points. This is the best known ambiguity, though there are others.</p> <p>This algorithm does not attempt to resolve such ambiguities; it is a naive implementation of marching cubes as in <a class="reference internal" href="#r1e43a330a523-1" id="id33">[1]</a>, but may be a good beginning for work with more recent techniques (Dual Marching Cubes, Extended Marching Cubes, Cubic Marching Squares, etc.).</p> <p>Because of interactions between neighboring cubes, the isosurface(s) generated by this algorithm are NOT guaranteed to be closed, particularly for complicated contours. Furthermore, this algorithm does not guarantee a single contour will be returned. Indeed, ALL isosurfaces which cross <code>level</code> will be found, regardless of connectivity.</p> <p>The output is a triangular mesh consisting of a set of unique vertices and connecting triangles. The order of these vertices and triangles in the output list is determined by the position of the smallest <code>x,y,z</code> (in lexicographical order) coordinate in the contour. This is a side-effect of how the input array is traversed, but can be relied upon.</p> <p>The generated mesh guarantees coherent orientation as of version 0.12.</p> <p>To quantify the area of an isosurface generated by this algorithm, pass outputs directly into <code>skimage.measure.mesh_surface_area</code>.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r1e43a330a523-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id31">1</a>, <a class="fn-backref" href="#id32">2</a>, <a class="fn-backref" href="#id33">3</a>, <a class="fn-backref" href="#id34">4</a>)</em> Lorensen, William and Harvey E. Cline. Marching Cubes: A High Resolution 3D Surface Construction Algorithm. Computer Graphics (SIGGRAPH 87 Proceedings) 21(4) July 1987, p. 163-170). DOI: 10.1145/37401.37422</td>
</tr>  </table> </dd>
</dl>   <h2 id="mesh-surface-area">mesh_surface_area</h2> <dl class="function"> <dt id="skimage.measure.mesh_surface_area">
<code>skimage.measure.mesh_surface_area(verts, faces)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_marching_cubes_classic.py#L139"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute surface area, given vertices &amp; triangular faces</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>verts : (V, 3) array of floats</code> </dt> <dd>
<p class="first last">Array containing (x, y, z) coordinates for V unique mesh vertices.</p> </dd> <dt>
<code>faces : (F, 3) array of ints</code> </dt> <dd>
<p class="first last">List of length-3 lists of integers, referencing vertex coordinates as provided in <code>verts</code></p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>area : float</code> </dt> <dd>
<p class="first last">Surface area of mesh. Units now [coordinate units] ** 2.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><code>skimage.measure.marching_cubes</code>, <a class="reference internal" href="#skimage.measure.marching_cubes_classic" title="skimage.measure.marching_cubes_classic"><code>skimage.measure.marching_cubes_classic</code></a>, <a class="reference internal" href="#skimage.measure.correct_mesh_orientation" title="skimage.measure.correct_mesh_orientation"><code>skimage.measure.correct_mesh_orientation</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>The arguments expected by this function are the first two outputs from <code>skimage.measure.marching_cubes</code>. For unit correct output, ensure correct <code>spacing</code> was passed to <code>skimage.measure.marching_cubes</code>.</p> <p>This algorithm works properly only if the <code>faces</code> provided are all triangles.</p> </dd>
</dl>   <h2 id="correct-mesh-orientation">correct_mesh_orientation</h2> <dl class="function"> <dt id="skimage.measure.correct_mesh_orientation">
<code>skimage.measure.correct_mesh_orientation(volume, verts, faces, spacing=(1.0, 1.0, 1.0), gradient_direction='descent')</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_marching_cubes_classic.py#L182"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Correct orientations of mesh faces.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>volume : (M, N, P) array of doubles</code> </dt> <dd>
<p class="first last">Input data volume to find isosurfaces. Will be cast to <code>np.float64</code>.</p> </dd> <dt>
<code>verts : (V, 3) array of floats</code> </dt> <dd>
<p class="first last">Array containing (x, y, z) coordinates for V unique mesh vertices.</p> </dd> <dt>
<code>faces : (F, 3) array of ints</code> </dt> <dd>
<p class="first last">List of length-3 lists of integers, referencing vertex coordinates as provided in <code>verts</code>.</p> </dd> <dt>
<code>spacing : length-3 tuple of floats</code> </dt> <dd>
<p class="first last">Voxel spacing in spatial dimensions corresponding to numpy array indexing dimensions (M, N, P) as in <code>volume</code>.</p> </dd> <dt>
<code>gradient_direction : string</code> </dt> <dd>
<p class="first last">Controls if the mesh was generated from an isosurface with gradient descent toward objects of interest (the default), or the opposite. The two options are: * descent : Object was greater than exterior * ascent : Exterior was greater than object</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt><strong>faces_corrected (F, 3) array of ints</strong></dt> <dd>
<p class="first last">Corrected list of faces referencing vertex coordinates in <code>verts</code>.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.marching_cubes_classic" title="skimage.measure.marching_cubes_classic"><code>skimage.measure.marching_cubes_classic</code></a>, <a class="reference internal" href="#skimage.measure.mesh_surface_area" title="skimage.measure.mesh_surface_area"><code>skimage.measure.mesh_surface_area</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>Certain applications and mesh processing algorithms require all faces to be oriented in a consistent way. Generally, this means a normal vector points “out” of the meshed shapes. This algorithm corrects the output from <code>skimage.measure.marching_cubes_classic</code> by flipping the orientation of mis-oriented faces.</p> <p>Because marching cubes could be used to find isosurfaces either on gradient descent (where the desired object has greater values than the exterior) or ascent (where the desired object has lower values than the exterior), the <code>gradient_direction</code> kwarg allows the user to inform this algorithm which is correct. If the resulting mesh appears to be oriented completely incorrectly, try changing this option.</p> <p>The arguments expected by this function are the exact outputs from <code>skimage.measure.marching_cubes_classic</code>. Only <code>faces</code> is corrected and returned, as the vertices do not change; only the order in which they are referenced.</p> <p>This algorithm assumes <code>faces</code> provided are all triangles.</p> </dd>
</dl>   <h2 id="profile-line">profile_line</h2> <dl class="function"> <dt id="skimage.measure.profile_line">
<code>skimage.measure.profile_line(image, src, dst, linewidth=1, order=1, mode='constant', cval=0.0)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/profile.py#L5"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the intensity profile of an image measured along a scan line.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : numeric array, shape (M, N[, C])</code> </dt> <dd>
<p class="first last">The image, either grayscale (2D array) or multichannel (3D array, where the final axis contains the channel information).</p> </dd> <dt>
<code>src : 2-tuple of numeric scalar (float or int)</code> </dt> <dd>
<p class="first last">The start point of the scan line.</p> </dd> <dt>
<code>dst : 2-tuple of numeric scalar (float or int)</code> </dt> <dd>
<p class="first last">The end point of the scan line. The destination point is <em>included</em> in the profile, in constrast to standard numpy indexing.</p> </dd> <dt>
<code>linewidth : int, optional</code> </dt> <dd>
<p class="first last">Width of the scan, perpendicular to the line</p> </dd> <dt>
<code>order : int in {0, 1, 2, 3, 4, 5}, optional</code> </dt> <dd>
<p class="first last">The order of the spline interpolation to compute image values at non-integer coordinates. 0 means nearest-neighbor interpolation.</p> </dd> <dt>
<code>mode : {‘constant’, ‘nearest’, ‘reflect’, ‘mirror’, ‘wrap’}, optional</code> </dt> <dd>
<p class="first last">How to compute any values falling outside of the image.</p> </dd> <dt>
<code>cval : float, optional</code> </dt> <dd>
<p class="first last">If <code>mode</code> is ‘constant’, what constant value to use outside the image.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>return_value : array</code> </dt> <dd>
<p class="first last">The intensity profile along the scan line. The length of the profile is the ceil of the computed length of the scan line.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; x = np.array([[1, 1, 1, 2, 2, 2]])
&gt;&gt;&gt; img = np.vstack([np.zeros_like(x), x, x, x, np.zeros_like(x)])
&gt;&gt;&gt; img
array([[0, 0, 0, 0, 0, 0],
       [1, 1, 1, 2, 2, 2],
       [1, 1, 1, 2, 2, 2],
       [1, 1, 1, 2, 2, 2],
       [0, 0, 0, 0, 0, 0]])
&gt;&gt;&gt; profile_line(img, (2, 1), (2, 4))
array([ 1.,  1.,  2.,  2.])
&gt;&gt;&gt; profile_line(img, (1, 0), (1, 6), cval=4)
array([ 1.,  1.,  1.,  2.,  2.,  2.,  4.])
</pre> <p>The destination point is included in the profile, in contrast to standard numpy indexing. For example:</p> <pre data-language="python">&gt;&gt;&gt; profile_line(img, (1, 0), (1, 6))  # The final point is out of bounds
array([ 1.,  1.,  1.,  2.,  2.,  2.,  0.])
&gt;&gt;&gt; profile_line(img, (1, 0), (1, 5))  # This accesses the full first row
array([ 1.,  1.,  1.,  2.,  2.,  2.])
</pre> </dd>
</dl>   <h2 id="label">label</h2> <dl class="function"> <dt id="skimage.measure.label">
<code>skimage.measure.label(input, neighbors=None, background=None, return_num=False, connectivity=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_label.py#L4"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Label connected regions of an integer array.</p> <p>Two pixels are connected when they are neighbors and have the same value. In 2D, they can be neighbors either in a 1- or 2-connected sense. The value refers to the maximum number of orthogonal hops to consider a pixel/voxel a neighbor:</p> <pre data-language="python">1-connectivity      2-connectivity     diagonal connection close-up

     [ ]           [ ]  [ ]  [ ]         [ ]
      |               \  |  /             |  &lt;- hop 2
[ ]--[x]--[ ]      [ ]--[x]--[ ]    [x]--[ ]
      |               /  |  \         hop 1
     [ ]           [ ]  [ ]  [ ]
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>input : ndarray of dtype int</code> </dt> <dd>
<p class="first last">Image to label.</p> </dd> <dt>
<code>neighbors : {4, 8}, int, optional</code> </dt> <dd>
<p class="first last">Whether to use 4- or 8-“connectivity”. In 3D, 4-“connectivity” means connected pixels have to share face, whereas with 8-“connectivity”, they have to share only edge or vertex. <strong>Deprecated, use ``connectivity`` instead.</strong></p> </dd> <dt>
<code>background : int, optional</code> </dt> <dd>
<p class="first last">Consider all pixels with this value as background pixels, and label them as 0. By default, 0-valued pixels are considered as background pixels.</p> </dd> <dt>
<code>return_num : bool, optional</code> </dt> <dd>
<p class="first last">Whether to return the number of assigned labels.</p> </dd> <dt>
<code>connectivity : int, optional</code> </dt> <dd>
<p class="first last">Maximum number of orthogonal hops to consider a pixel/voxel as a neighbor. Accepted values are ranging from 1 to input.ndim. If <code>None</code>, a full connectivity of <code>input.ndim</code> is used.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>labels : ndarray of dtype int</code> </dt> <dd>
<p class="first last">Labeled array, where all connected regions are assigned the same integer value.</p> </dd> <dt>
<code>num : int, optional</code> </dt> <dd>
<p class="first last">Number of labels, which equals the maximum label index and is only returned if return_num is <code>True</code>.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.regionprops" title="skimage.measure.regionprops"><code>regionprops</code></a></p> </div> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r4c017a27ed0c-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id35">[1]</a></td>
<td>Christophe Fiorio and Jens Gustedt, “Two linear time Union-Find strategies for image processing”, Theoretical Computer Science 154 (1996), pp. 165-181.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r4c017a27ed0c-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id36">[2]</a></td>
<td>Kensheng Wu, Ekow Otoo and Arie Shoshani, “Optimizing connected component labeling algorithms”, Paper LBNL-56864, 2005, Lawrence Berkeley National Laboratory (University of California), <a class="reference external" href="http://repositories.cdlib.org/lbnl/LBNL-56864">http://repositories.cdlib.org/lbnl/LBNL-56864</a>
</td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; x = np.eye(3).astype(int)
&gt;&gt;&gt; print(x)
[[1 0 0]
 [0 1 0]
 [0 0 1]]
&gt;&gt;&gt; print(label(x, connectivity=1))
[[1 0 0]
 [0 2 0]
 [0 0 3]]
&gt;&gt;&gt; print(label(x, connectivity=2))
[[1 0 0]
 [0 1 0]
 [0 0 1]]
&gt;&gt;&gt; print(label(x, background=-1))
[[1 2 2]
 [2 1 2]
 [2 2 1]]
&gt;&gt;&gt; x = np.array([[1, 0, 0],
...               [1, 1, 5],
...               [0, 0, 0]])
&gt;&gt;&gt; print(label(x))
[[1 0 0]
 [1 1 2]
 [0 0 0]]
</pre> </dd>
</dl>   <h2 id="points-in-poly">points_in_poly</h2> <dl class="function"> <dt id="skimage.measure.points_in_poly">
<code>skimage.measure.points_in_poly(points, verts)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/pnpoly.py#L32"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Test whether points lie inside a polygon.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>points : (N, 2) array</code> </dt> <dd>
<p class="first last">Input points, <code>(x, y)</code>.</p> </dd> <dt>
<code>verts : (M, 2) array</code> </dt> <dd>
<p class="first last">Vertices of the polygon, sorted either clockwise or anti-clockwise. The first point may (but does not need to be) duplicated.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>mask : (N,) array of bool</code> </dt> <dd>
<p class="first last">True if corresponding point is inside the polygon.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.grid_points_in_poly" title="skimage.measure.grid_points_in_poly"><code>grid_points_in_poly</code></a></p> </div> </dd>
</dl>   <h2 id="grid-points-in-poly">grid_points_in_poly</h2> <dl class="function"> <dt id="skimage.measure.grid_points_in_poly">
<code>skimage.measure.grid_points_in_poly(shape, verts)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/pnpoly.py#L4"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Test whether points on a specified grid are inside a polygon.</p> <p>For each <code>(r, c)</code> coordinate on a grid, i.e. <code>(0, 0)</code>, <code>(0, 1)</code> etc., test whether that point lies inside a polygon.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>shape : tuple (M, N)</code> </dt> <dd>
<p class="first last">Shape of the grid.</p> </dd> <dt>
<code>verts : (V, 2) array</code> </dt> <dd>
<p class="first last">Specify the V vertices of the polygon, sorted either clockwise or anti-clockwise. The first point may (but does not need to be) duplicated.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>mask : (M, N) ndarray of bool</code> </dt> <dd>
<p class="first last">True where the grid falls inside the polygon.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="#skimage.measure.points_in_poly" title="skimage.measure.points_in_poly"><code>points_in_poly</code></a></p> </div> </dd>
</dl>   <h2 id="compare-ssim">compare_ssim</h2> <dl class="function"> <dt id="skimage.measure.compare_ssim">
<code>skimage.measure.compare_ssim(X, Y, win_size=None, gradient=False, data_range=None, multichannel=False, gaussian_weights=False, full=False, **kwargs)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/_structural_similarity.py#L13"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the mean structural similarity index between two images.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X, Y : ndarray</code> </dt> <dd>
<p class="first last">Image. Any dimensionality.</p> </dd> <dt>
<code>win_size : int or None</code> </dt> <dd>
<p class="first last">The side-length of the sliding window used in comparison. Must be an odd value. If <code>gaussian_weights</code> is True, this is ignored and the window size will depend on <code>sigma</code>.</p> </dd> <dt>
<code>gradient : bool, optional</code> </dt> <dd>
<p class="first last">If True, also return the gradient with respect to Y.</p> </dd> <dt>
<code>data_range : float, optional</code> </dt> <dd>
<p class="first last">The data range of the input image (distance between minimum and maximum possible values). By default, this is estimated from the image data-type.</p> </dd> <dt>
<code>multichannel : bool, optional</code> </dt> <dd>
<p class="first last">If True, treat the last dimension of the array as channels. Similarity calculations are done independently for each channel then averaged.</p> </dd> <dt>
<code>gaussian_weights : bool, optional</code> </dt> <dd>
<p class="first last">If True, each patch has its mean and variance spatially weighted by a normalized Gaussian kernel of width sigma=1.5.</p> </dd> <dt>
<code>full : bool, optional</code> </dt> <dd>
<p class="first last">If True, return the full structural similarity image instead of the mean value.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>mssim : float</code> </dt> <dd>
<p class="first last">The mean structural similarity over the image.</p> </dd> <dt>
<code>grad : ndarray</code> </dt> <dd>
<p class="first last">The gradient of the structural similarity index between X and Y <a class="reference internal" href="#rccea9a164d3e-2" id="id37">[2]</a>. This is only returned if <code>gradient</code> is set to True.</p> </dd> <dt>
<code>S : ndarray</code> </dt> <dd>
<p class="first last">The full SSIM image. This is only returned if <code>full</code> is set to True.</p> </dd> </dl> </td> </tr> <tr><th class="field-name" colspan="2">Other Parameters:</th></tr> <tr>
<td> </td>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>use_sample_covariance : bool</code> </dt> <dd>
<p class="first last">if True, normalize covariances by N-1 rather than, N where N is the number of pixels within the sliding window.</p> </dd> <dt>
<code>K1 : float</code> </dt> <dd>
<p class="first last">algorithm parameter, K1 (small constant, see <a class="reference internal" href="#rccea9a164d3e-1" id="id38">[1]</a>)</p> </dd> <dt>
<code>K2 : float</code> </dt> <dd>
<p class="first last">algorithm parameter, K2 (small constant, see <a class="reference internal" href="#rccea9a164d3e-1" id="id39">[1]</a>)</p> </dd> <dt>
<code>sigma : float</code> </dt> <dd>
<p class="first last">sigma for the Gaussian when <code>gaussian_weights</code> is True.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>To match the implementation of Wang et. al. <a class="reference internal" href="#rccea9a164d3e-1" id="id40">[1]</a>, set <code>gaussian_weights</code> to True, <code>sigma</code> to 1.5, and <code>use_sample_covariance</code> to False.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rccea9a164d3e-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id38">1</a>, <a class="fn-backref" href="#id39">2</a>, <a class="fn-backref" href="#id40">3</a>, <a class="fn-backref" href="#id41">4</a>)</em> Wang, Z., Bovik, A. C., Sheikh, H. R., &amp; Simoncelli, E. P. (2004). Image quality assessment: From error visibility to structural similarity. IEEE Transactions on Image Processing, 13, 600-612. <a class="reference external" href="https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf">https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf</a>, DOI:10.1109/TIP.2003.819861</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rccea9a164d3e-2" rules="none">   <tr>
<td class="label">[2]</td>
<td>
<em>(<a class="fn-backref" href="#id37">1</a>, <a class="fn-backref" href="#id42">2</a>)</em> Avanaki, A. N. (2009). Exact global histogram specification optimized for structural similarity. Optical Review, 16, 613-621. <a class="reference external" href="http://arxiv.org/abs/0901.0065">http://arxiv.org/abs/0901.0065</a>, DOI:10.1007/s10043-009-0119-z</td>
</tr>  </table> </dd>
</dl>   <h2 id="compare-mse">compare_mse</h2> <dl class="function"> <dt id="skimage.measure.compare_mse">
<code>skimage.measure.compare_mse(im1, im2)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/simple_metrics.py#L28"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the mean-squared error between two images.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>im1, im2 : ndarray</code> </dt> <dd>
<p class="first last">Image. Any dimensionality.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>mse : float</code> </dt> <dd>
<p class="first last">The mean-squared error (MSE) metric.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl>   <h2 id="compare-nrmse">compare_nrmse</h2> <dl class="function"> <dt id="skimage.measure.compare_nrmse">
<code>skimage.measure.compare_nrmse(im_true, im_test, norm_type='Euclidean')</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/simple_metrics.py#L47"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the normalized root mean-squared error (NRMSE) between two images.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>im_true : ndarray</code> </dt> <dd>
<p class="first last">Ground-truth image.</p> </dd> <dt>
<code>im_test : ndarray</code> </dt> <dd>
<p class="first last">Test image.</p> </dd> <dt>
<code>norm_type : {‘Euclidean’, ‘min-max’, ‘mean’}</code> </dt> <dd>
<p class="first">Controls the normalization method to use in the denominator of the NRMSE. There is no standard method of normalization across the literature <a class="reference internal" href="#rb7f5201e5e31-1" id="id43">[1]</a>. The methods available here are as follows:</p> <ul class="last"> <li>
<p class="first">‘Euclidean’ : normalize by the averaged Euclidean norm of <code>im_true</code>:</p> <pre data-language="python">NRMSE = RMSE * sqrt(N) / || im_true ||
</pre> <p>where || . || denotes the Frobenius norm and <code>N = im_true.size</code>. This result is equivalent to:</p> <pre data-language="python">NRMSE = || im_true - im_test || / || im_true ||.
</pre> </li> <li>‘min-max’ : normalize by the intensity range of <code>im_true</code>. </li> <li>‘mean’ : normalize by the mean of <code>im_true</code> </li> </ul> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>nrmse : float</code> </dt> <dd>
<p class="first last">The NRMSE metric.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rb7f5201e5e31-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id43">1</a>, <a class="fn-backref" href="#id44">2</a>)</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">https://en.wikipedia.org/wiki/Root-mean-square_deviation</a>
</td>
</tr>  </table> </dd>
</dl>   <h2 id="compare-psnr">compare_psnr</h2> <dl class="function"> <dt id="skimage.measure.compare_psnr">
<code>skimage.measure.compare_psnr(im_true, im_test, data_range=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/simple_metrics.py#L100"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the peak signal to noise ratio (PSNR) for an image.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>im_true : ndarray</code> </dt> <dd>
<p class="first last">Ground-truth image.</p> </dd> <dt>
<code>im_test : ndarray</code> </dt> <dd>
<p class="first last">Test image.</p> </dd> <dt>
<code>data_range : int</code> </dt> <dd>
<p class="first last">The data range of the input image (distance between minimum and maximum possible values). By default, this is estimated from the image data-type.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>psnr : float</code> </dt> <dd>
<p class="first last">The PSNR metric.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rc30fc0f79907-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id45">[1]</a></td>
<td><a class="reference external" href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio">https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio</a></td>
</tr>  </table> </dd>
</dl>   <h2 id="shannon-entropy">shannon_entropy</h2> <dl class="function"> <dt id="skimage.measure.shannon_entropy">
<code>skimage.measure.shannon_entropy(image, base=2)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/entropy.py#L5"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Calculate the Shannon entropy of an image.</p> <p>The Shannon entropy is defined as S = -sum(pk * log(pk)), where pk are frequency/probability of pixels of value k.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>image : (N, M) ndarray</code> </dt> <dd>
<p class="first last">Grayscale input image.</p> </dd> <dt>
<code>base : float, optional</code> </dt> <dd>
<p class="first last">The logarithmic base to use.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>entropy : float</code> </dt>  </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The returned value is measured in bits or shannon (Sh) for base=2, natural unit (nat) for base=np.e and hartley (Hart) for base=10.</p> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rd3de3b6e4b40-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id46">[1]</a></td>
<td>
<a class="reference external" href="https://en.wikipedia.org/wiki/Entropy_(information_theory">https://en.wikipedia.org/wiki/Entropy_(information_theory</a>)</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rd3de3b6e4b40-2" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id47">[2]</a></td>
<td><a class="reference external" href="https://en.wiktionary.org/wiki/Shannon_entropy">https://en.wiktionary.org/wiki/Shannon_entropy</a></td>
</tr>  </table> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from skimage import data
&gt;&gt;&gt; shannon_entropy(data.camera())
7.0479552324230861
</pre> </dd>
</dl>   <h2 id="linemodelnd">LineModelND</h2> <dl class="class"> <dt id="skimage.measure.LineModelND">
<code>class skimage.measure.LineModelND</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L28"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.measure.fit.BaseModel</code></p> <p>Total least squares estimator for N-dimensional lines.</p> <p>In contrast to ordinary least squares line estimation, this estimator minimizes the orthogonal distances of points to the estimated line.</p> <p>Lines are defined by a point (origin) and a unit vector (direction) according to the following vector equation:</p> <pre data-language="python">X = origin + lambda * direction
</pre> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; x = np.linspace(1, 2, 25)
&gt;&gt;&gt; y = 1.5 * x + 3
&gt;&gt;&gt; lm = LineModelND()
&gt;&gt;&gt; lm.estimate(np.array([x, y]).T)
True
&gt;&gt;&gt; tuple(np.round(lm.params, 5))
(array([ 1.5 ,  5.25]), array([ 0.5547 ,  0.83205]))
&gt;&gt;&gt; res = lm.residuals(np.array([x, y]).T)
&gt;&gt;&gt; np.abs(np.round(res, 9))
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
&gt;&gt;&gt; np.round(lm.predict_y(x[:5]), 3)
array([ 4.5  ,  4.562,  4.625,  4.688,  4.75 ])
&gt;&gt;&gt; np.round(lm.predict_x(y[:5]), 3)
array([ 1.   ,  1.042,  1.083,  1.125,  1.167])
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : tuple</code> </dt> <dd>
<p class="first last">Line model parameters in the following order <code>origin</code>, <code>direction</code>.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.measure.LineModelND.__init__">
<code>__init__()</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L24"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.LineModelND.estimate">
<code>estimate(data)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L64"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate line model from data.</p> <p>This minimizes the sum of shortest (orthogonal) distances from the given data points to the estimated line.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, dim) array</code> </dt> <dd>
<p class="first last">N points in a space of dimensionality dim &gt;= 2.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.LineModelND.predict">
<code>predict(x, axis=0, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L131"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict intersection of the estimated line model with a hyperplane orthogonal to a given axis.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>x : (n, 1) array</code> </dt> <dd>
<p class="first last">Coordinates along an axis.</p> </dd> <dt>
<code>axis : int</code> </dt> <dd>
<p class="first last">Axis orthogonal to the hyperplane intersecting the line.</p> </dd> <dt>
<code>params : (2, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set in the form (<code>origin</code>, <code>direction</code>).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (n, m) array</code> </dt> <dd>
<p class="first last">Predicted coordinates.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Raises:</th>
<td class="field-body">
<dl class="first last docutils"> <dt><strong>ValueError</strong></dt> <dd>
<p class="first last">If the line is parallel to the given axis.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.LineModelND.predict_x">
<code>predict_x(y, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L170"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict x-coordinates for 2D lines using the estimated model.</p> <p>Alias for:</p> <pre data-language="python">predict(y, axis=1)[:, 0]
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>y : array</code> </dt> <dd>
<p class="first last">y-coordinates.</p> </dd> <dt>
<code>params : (2, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set in the form (<code>origin</code>, <code>direction</code>).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>x : array</code> </dt> <dd>
<p class="first last">Predicted x-coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.LineModelND.predict_y">
<code>predict_y(x, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L193"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict y-coordinates for 2D lines using the estimated model.</p> <p>Alias for:</p> <pre data-language="python">predict(x, axis=0)[:, 1]
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>x : array</code> </dt> <dd>
<p class="first last">x-coordinates.</p> </dd> <dt>
<code>params : (2, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set in the form (<code>origin</code>, <code>direction</code>).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>y : array</code> </dt> <dd>
<p class="first last">Predicted y-coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.LineModelND.residuals">
<code>residuals(data, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L101"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Determine residuals of data to model.</p> <p>For each point, the shortest (orthogonal) distance to the line is returned. It is obtained by projecting the data onto the line.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, dim) array</code> </dt> <dd>
<p class="first last">N points in a space of dimension dim.</p> </dd> <dt>
<code>params : (2, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set in the form (<code>origin</code>, <code>direction</code>).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>residuals : (N, ) array</code> </dt> <dd>
<p class="first last">Residual for each data point.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="circlemodel">CircleModel</h2> <dl class="class"> <dt id="skimage.measure.CircleModel">
<code>class skimage.measure.CircleModel</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L217"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.measure.fit.BaseModel</code></p> <p>Total least squares estimator for 2D circles.</p> <p>The functional model of the circle is:</p> <pre data-language="python">r**2 = (x - xc)**2 + (y - yc)**2
</pre> <p>This estimator minimizes the squared distances from all points to the circle:</p> <pre data-language="python">min{ sum((r - sqrt((x_i - xc)**2 + (y_i - yc)**2))**2) }
</pre> <p>A minimum number of 3 points is required to solve for the parameters.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; t = np.linspace(0, 2 * np.pi, 25)
&gt;&gt;&gt; xy = CircleModel().predict_xy(t, params=(2, 3, 4))
&gt;&gt;&gt; model = CircleModel()
&gt;&gt;&gt; model.estimate(xy)
True
&gt;&gt;&gt; tuple(np.round(model.params, 5))
(2.0, 3.0, 4.0)
&gt;&gt;&gt; res = model.residuals(xy)
&gt;&gt;&gt; np.abs(np.round(res, 9))
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : tuple</code> </dt> <dd>
<p class="first last">Circle model parameters in the following order <code>xc</code>, <code>yc</code>, <code>r</code>.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.measure.CircleModel.__init__">
<code>__init__()</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L24"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.CircleModel.estimate">
<code>estimate(data)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L253"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate circle model from data using total least squares.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, 2) array</code> </dt> <dd>
<p class="first last">N points with <code>(x, y)</code> coordinates, respectively.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.CircleModel.predict_xy">
<code>predict_xy(t, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L320"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict x- and y-coordinates using the estimated model.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>t : array</code> </dt> <dd>
<p class="first last">Angles in circle in radians. Angles start to count from positive x-axis to positive y-axis in a right-handed system.</p> </dd> <dt>
<code>params : (3, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>xy : (…, 2) array</code> </dt> <dd>
<p class="first last">Predicted x- and y-coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.CircleModel.residuals">
<code>residuals(data)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L294"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Determine residuals of data to model.</p> <p>For each point the shortest distance to the circle is returned.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, 2) array</code> </dt> <dd>
<p class="first last">N points with <code>(x, y)</code> coordinates, respectively.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>residuals : (N, ) array</code> </dt> <dd>
<p class="first last">Residual for each data point.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>   <h2 id="ellipsemodel">EllipseModel</h2> <dl class="class"> <dt id="skimage.measure.EllipseModel">
<code>class skimage.measure.EllipseModel</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L347"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bases: <code>skimage.measure.fit.BaseModel</code></p> <p>Total least squares estimator for 2D ellipses.</p> <p>The functional model of the ellipse is:</p> <pre data-language="python">xt = xc + a*cos(theta)*cos(t) - b*sin(theta)*sin(t)
yt = yc + a*sin(theta)*cos(t) + b*cos(theta)*sin(t)
d = sqrt((x - xt)**2 + (y - yt)**2)
</pre> <p>where <code>(xt, yt)</code> is the closest point on the ellipse to <code>(x, y)</code>. Thus d is the shortest distance from the point to the ellipse.</p> <p>The estimator is based on a least squares minimization. The optimal solution is computed directly, no iterations are required. This leads to a simple, stable and robust fitting method.</p> <p>The <code>params</code> attribute contains the parameters in the following order:</p> <pre data-language="python">xc, yc, a, b, theta
</pre> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; xy = EllipseModel().predict_xy(np.linspace(0, 2 * np.pi, 25),
...                                params=(10, 15, 4, 8, np.deg2rad(30)))
&gt;&gt;&gt; ellipse = EllipseModel()
&gt;&gt;&gt; ellipse.estimate(xy)
True
&gt;&gt;&gt; np.round(ellipse.params, 2)
array([ 10.  ,  15.  ,   4.  ,   8.  ,   0.52])
&gt;&gt;&gt; np.round(abs(ellipse.residuals(xy)), 5)
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
</pre> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : tuple</code> </dt> <dd>
<p class="first last">Ellipse model parameters in the following order <code>xc</code>, <code>yc</code>, <code>a</code>, <code>b</code>, <code>theta</code>.</p> </dd> </dl> </td> </tr>  </table> <dl class="method"> <dt id="skimage.measure.EllipseModel.__init__">
<code>__init__()</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L24"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.EllipseModel.estimate">
<code>estimate(data)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L388"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate circle model from data using total least squares.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, 2) array</code> </dt> <dd>
<p class="first last">N points with <code>(x, y)</code> coordinates, respectively.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>success : bool</code> </dt> <dd>
<p class="first last">True, if model estimation succeeds.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rb82f40f15f1b-1" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id48">[1]</a></td>
<td>Halir, R.; Flusser, J. “Numerically stable direct least squares fitting of ellipses”. In Proc. 6th International Conference in Central Europe on Computer Graphics and Visualization. WSCG (Vol. 98, pp. 125-132).</td>
</tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.EllipseModel.predict_xy">
<code>predict_xy(t, params=None)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L545"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict x- and y-coordinates using the estimated model.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>t : array</code> </dt> <dd>
<p class="first last">Angles in circle in radians. Angles start to count from positive x-axis to positive y-axis in a right-handed system.</p> </dd> <dt>
<code>params : (5, ) array, optional</code> </dt> <dd>
<p class="first last">Optional custom parameter set.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>xy : (…, 2) array</code> </dt> <dd>
<p class="first last">Predicted x- and y-coordinates.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="skimage.measure.EllipseModel.residuals">
<code>residuals(data)</code> <a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.1/skimage/measure/fit.py#L483"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Determine residuals of data to model.</p> <p>For each point the shortest distance to the ellipse is returned.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>data : (N, 2) array</code> </dt> <dd>
<p class="first last">N points with <code>(x, y)</code> coordinates, respectively.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>residuals : (N, ) array</code> </dt> <dd>
<p class="first last">Residual for each data point.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>
<div class="_attribution">
  <p class="_attribution-p">
    © 2011 the scikit-image team<br>Licensed under the BSD 3-clause License.<br>
    <a href="http://scikit-image.org/docs/0.14.x/api/skimage.measure.html" class="_attribution-link">http://scikit-image.org/docs/0.14.x/api/skimage.measure.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
