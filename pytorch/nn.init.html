
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>torch.nn.init - PyTorch - W3cubDocs</title>
  
  <meta name="description" content=" Return the recommended gain value for the given nonlinearity function. The values are as follows&#58; ">
  <meta name="keywords" content="torch, nn, init, pytorch">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/pytorch/nn.init.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/pytorch.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/pytorch/" class="_nav-link" title="" style="margin-left:0;">PyTorch</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="nn-init-doc">torch.nn.init</h1> <dl class="function" id="torch-nn-init"> <dt id="torch.nn.init.calculate_gain">
<code>torch.nn.init.calculate_gain(nonlinearity, param=None)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#calculate_gain"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the recommended gain value for the given nonlinearity function. The values are as follows:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p>nonlinearity</p></th> <th class="head"><p>gain</p></th> </tr> </thead>  <tr>
<td><p>Linear / Identity</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td><p>Conv{1,2,3}D</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td><p>Sigmoid</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td><p>Tanh</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>5</mn><mn>3</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{5}{3}</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td><p>ReLU</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mn>2</mn></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{2}</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td><p>Leaky Relu</p></td> <td><p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mfrac><mn>2</mn><mrow><mn>1</mn><mo>+</mo><msup><mtext>negative_slope</mtext><mn>2</mn></msup></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}</annotation></semantics></math></span></span> </span></p></td> </tr>  </table> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>nonlinearity</strong> – the non-linear function (<code>nn.functional</code> name)</li> <li>
<strong>param</strong> – optional parameter for the non-linear function</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.uniform_">
<code>torch.nn.init.uniform_(tensor, a=0.0, b=1.0)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#uniform_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input Tensor with values drawn from the uniform distribution <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">U</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}(a, b)</annotation></semantics></math></span></span> </span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>a</strong> – the lower bound of the uniform distribution</li> <li>
<strong>b</strong> – the upper bound of the uniform distribution</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.uniform_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.normal_">
<code>torch.nn.init.normal_(tensor, mean=0.0, std=1.0)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#normal_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input Tensor with values drawn from the normal distribution <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mtext>mean</mtext><mo separator="true">,</mo><msup><mtext>std</mtext><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(\text{mean}, \text{std}^2)</annotation></semantics></math></span></span> </span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>mean</strong> – the mean of the normal distribution</li> <li>
<strong>std</strong> – the standard deviation of the normal distribution</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.normal_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.constant_">
<code>torch.nn.init.constant_(tensor, val)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#constant_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input Tensor with the value <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>val</mtext></mrow><annotation encoding="application/x-tex">\text{val}</annotation></semantics></math></span></span> </span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>val</strong> – the value to fill the tensor with</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.constant_(w, 0.3)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.ones_">
<code>torch.nn.init.ones_(tensor)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#ones_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input Tensor with the scalar value <code>1</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.ones_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.zeros_">
<code>torch.nn.init.zeros_(tensor)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#zeros_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input Tensor with the scalar value <code>0</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.zeros_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.eye_">
<code>torch.nn.init.eye_(tensor)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#eye_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the 2-dimensional input <code>Tensor</code> with the identity matrix. Preserves the identity of the inputs in <code>Linear</code> layers, where as many inputs are preserved as possible.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>tensor</strong> – a 2-dimensional <code>torch.Tensor</code></p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.eye_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.dirac_">
<code>torch.nn.init.dirac_(tensor, groups=1)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#dirac_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the {3, 4, 5}-dimensional input <code>Tensor</code> with the Dirac delta function. Preserves the identity of the inputs in <code>Convolutional</code> layers, where as many input channels are preserved as possible. In case of groups&gt;1, each group of channels preserves identity</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – a {3, 4, 5}-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>groups</strong> (<em>optional</em>) – number of groups in the conv layer (default: 1)</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 16, 5, 5)
&gt;&gt;&gt; nn.init.dirac_(w)
&gt;&gt;&gt; w = torch.empty(3, 24, 5, 5)
&gt;&gt;&gt; nn.init.dirac_(w, 3)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.xavier_uniform_">
<code>torch.nn.init.xavier_uniform_(tensor, gain=1.0)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#xavier_uniform_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input <code>Tensor</code> with values according to the method described in <code>Understanding the difficulty of training deep feedforward neural networks</code> - Glorot, X. &amp; Bengio, Y. (2010), using a uniform distribution. The resulting tensor will have values sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">U</mi><mo stretchy="false">(</mo><mo>−</mo><mi>a</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}(-a, a)</annotation></semantics></math></span></span> </span> where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo>=</mo><mtext>gain</mtext><mo>×</mo><msqrt><mfrac><mn>6</mn><mrow><mtext>fan_in</mtext><mo>+</mo><mtext>fan_out</mtext></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}} </annotation></semantics></math></span></span></span> </div>
<p>Also known as Glorot initialization.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>gain</strong> – an optional scaling factor</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.xavier_normal_">
<code>torch.nn.init.xavier_normal_(tensor, gain=1.0)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#xavier_normal_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input <code>Tensor</code> with values according to the method described in <code>Understanding the difficulty of training deep feedforward neural networks</code> - Glorot, X. &amp; Bengio, Y. (2010), using a normal distribution. The resulting tensor will have values sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><msup><mtext>std</mtext><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, \text{std}^2)</annotation></semantics></math></span></span> </span> where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>std</mtext><mo>=</mo><mtext>gain</mtext><mo>×</mo><msqrt><mfrac><mn>2</mn><mrow><mtext>fan_in</mtext><mo>+</mo><mtext>fan_out</mtext></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">\text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}} </annotation></semantics></math></span></span></span> </div>
<p>Also known as Glorot initialization.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>gain</strong> – an optional scaling factor</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.xavier_normal_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.kaiming_uniform_">
<code>torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#kaiming_uniform_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input <code>Tensor</code> with values according to the method described in <code>Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</code> - He, K. et al. (2015), using a uniform distribution. The resulting tensor will have values sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">U</mi><mo stretchy="false">(</mo><mo>−</mo><mtext>bound</mtext><mo separator="true">,</mo><mtext>bound</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{U}(-\text{bound}, \text{bound})</annotation></semantics></math></span></span> </span> where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>bound</mtext><mo>=</mo><mtext>gain</mtext><mo>×</mo><msqrt><mfrac><mn>3</mn><mtext>fan_mode</mtext></mfrac></msqrt></mrow><annotation encoding="application/x-tex">\text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}} </annotation></semantics></math></span></span></span> </div>
<p>Also known as He initialization.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>a</strong> – the negative slope of the rectifier used after this layer (only used with <code>'leaky_relu'</code>)</li> <li>
<strong>mode</strong> – either <code>'fan_in'</code> (default) or <code>'fan_out'</code>. Choosing <code>'fan_in'</code> preserves the magnitude of the variance of the weights in the forward pass. Choosing <code>'fan_out'</code> preserves the magnitudes in the backwards pass.</li> <li>
<strong>nonlinearity</strong> – the non-linear function (<code>nn.functional</code> name), recommended to use only with <code>'relu'</code> or <code>'leaky_relu'</code> (default).</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.kaiming_normal_">
<code>torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#kaiming_normal_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input <code>Tensor</code> with values according to the method described in <code>Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</code> - He, K. et al. (2015), using a normal distribution. The resulting tensor will have values sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><msup><mtext>std</mtext><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, \text{std}^2)</annotation></semantics></math></span></span> </span> where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>std</mtext><mo>=</mo><mfrac><mtext>gain</mtext><msqrt><mtext>fan_mode</mtext></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}} </annotation></semantics></math></span></span></span> </div>
<p>Also known as He initialization.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>a</strong> – the negative slope of the rectifier used after this layer (only used with <code>'leaky_relu'</code>)</li> <li>
<strong>mode</strong> – either <code>'fan_in'</code> (default) or <code>'fan_out'</code>. Choosing <code>'fan_in'</code> preserves the magnitude of the variance of the weights in the forward pass. Choosing <code>'fan_out'</code> preserves the magnitudes in the backwards pass.</li> <li>
<strong>nonlinearity</strong> – the non-linear function (<code>nn.functional</code> name), recommended to use only with <code>'relu'</code> or <code>'leaky_relu'</code> (default).</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.orthogonal_">
<code>torch.nn.init.orthogonal_(tensor, gain=1)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#orthogonal_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the input <code>Tensor</code> with a (semi) orthogonal matrix, as described in <code>Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</code> - Saxe, A. et al. (2013). The input tensor must have at least 2 dimensions, and for tensors with more than 2 dimensions the trailing dimensions are flattened.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>, where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≥</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n \geq 2</annotation></semantics></math></span></span> </span>
</li> <li>
<strong>gain</strong> – optional scaling factor</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.orthogonal_(w)
</pre> </dd>
</dl> <dl class="function"> <dt id="torch.nn.init.sparse_">
<code>torch.nn.init.sparse_(tensor, sparsity, std=0.01)</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/init.html#sparse_"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fills the 2D input <code>Tensor</code> as a sparse matrix, where the non-zero elements will be drawn from the normal distribution <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>0.01</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, 0.01)</annotation></semantics></math></span></span> </span>, as described in <code>Deep learning via Hessian-free optimization</code> - Martens, J. (2010).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>tensor</strong> – an n-dimensional <code>torch.Tensor</code>
</li> <li>
<strong>sparsity</strong> – The fraction of elements in each column to be set to zero</li> <li>
<strong>std</strong> – the standard deviation of the normal distribution used to generate the non-zero values</li> </ul> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; w = torch.empty(3, 5)
&gt;&gt;&gt; nn.init.sparse_(w, sparsity=0.1)
</pre> </dd>
</dl>
<div class="_attribution">
  <p class="_attribution-p">
    © 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.7.0/nn.init.html" class="_attribution-link">https://pytorch.org/docs/1.7.0/nn.init.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
