
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>TripletMarginWithDistanceLoss - PyTorch - W3cubDocs</title>
  
  <meta name="description" content="Creates a criterion that measures the triplet loss given input tensors aa , pp , and nn (representing anchor, positive, and negative examples, &hellip;">
  <meta name="keywords" content="tripletmarginwithdistanceloss, pytorch">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/pytorch/generated/torch.nn.tripletmarginwithdistanceloss.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/pytorch.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/pytorch/" class="_nav-link" title="" style="margin-left:0;">PyTorch</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="tripletmarginwithdistanceloss">TripletMarginWithDistanceLoss</h1> <dl class="class"> <dt id="torch.nn.TripletMarginWithDistanceLoss">
<code>class torch.nn.TripletMarginWithDistanceLoss(*, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean')</code> <a class="reference internal" href="https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#TripletMarginWithDistanceLoss"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Creates a criterion that measures the triplet loss given input tensors <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> </span>, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span> </span>, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> </span> (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (“distance function”) used to compute the relationship between the anchor and positive example (“positive distance”) and the anchor and negative example (“negative distance”).</p> <p>The unreduced loss (i.e., with <code>reduction</code> set to <code>'none'</code>) can be described as:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mi>L</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>l</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>l</mi><mi>N</mi></msub><msup><mo stretchy="false">}</mo><mi mathvariant="normal">⊤</mi></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi>l</mi><mi>i</mi></msub><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>n</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\ell(a, p, n) = L = \{l_1,\dots,l_N\}^\top, \quad l_i = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\} </annotation></semantics></math></span></span></span> </div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> </span> is the batch size; <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span></span> </span> is a nonnegative, real-valued function quantifying the closeness of two tensors, referred to as the <code>distance_function</code>; and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">margin</annotation></semantics></math></span></span> </span> is a non-negative margin representing the minimum difference between the positive and negative distances that is required for the loss to be 0. The input tensors have <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> </span> elements each and can be of any shape that the distance function can handle.</p> <p>If <code>reduction</code> is not <code>'none'</code> (default <code>'mean'</code>), then:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">mean</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘mean’;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">sum</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘sum’.</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\ell(x, y) = \begin{cases} \operatorname{mean}(L), &amp; \text{if reduction} = \text{`mean';}\\ \operatorname{sum}(L), &amp; \text{if reduction} = \text{`sum'.} \end{cases} </annotation></semantics></math></span></span></span> </div>
<p>See also <a class="reference internal" href="torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss" title="torch.nn.TripletMarginLoss"><code>TripletMarginLoss</code></a>, which computes the triplet loss for input tensors using the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">l_p</annotation></semantics></math></span></span> </span> distance as the distance function.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>distance_function</strong> (<em>callable</em><em>, </em><em>optional</em>) – A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, <code>nn.PairwiseDistance</code> will be used. Default: <code>None</code>
</li> <li>
<strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a><em>, </em><em>optional</em>) – A non-negative margin representing the minimum difference between the positive and negative distances required for the loss to be 0. Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives. Default: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> </span>.</li> <li>
<strong>swap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a><em>, </em><em>optional</em>) – Whether to use the distance swap described in the paper <code>Learning shallow convolutional feature descriptors with triplet losses</code> by V. Balntas, E. Riba et al. If True, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation. Default: <code>False</code>.</li> <li>
<strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the (optional) reduction to apply to the output: <code>'none'</code> | <code>'mean'</code> | <code>'sum'</code>. <code>'none'</code>: no reduction will be applied, <code>'mean'</code>: the sum of the output will be divided by the number of elements in the output, <code>'sum'</code>: the output will be summed. Default: <code>'mean'</code>
</li> </ul> </dd> </dl> <dl class="simple"> <dt>Shape:</dt>
<dd>
<ul class="simple"> <li>Input: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mo>∗</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, *)</annotation></semantics></math></span></span> </span> where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span> </span> represents any number of additional dimensions as supported by the distance function.</li> <li>Output: A Tensor of shape <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N)</annotation></semantics></math></span></span> </span> if <code>reduction</code> is <code>'none'</code>, or a scalar otherwise.</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; # Initialize embeddings
&gt;&gt;&gt; embedding = nn.Embedding(1000, 128)
&gt;&gt;&gt; anchor_ids = torch.randint(0, 1000, (1,), requires_grad=True)
&gt;&gt;&gt; positive_ids = torch.randint(0, 1000, (1,), requires_grad=True)
&gt;&gt;&gt; negative_ids = torch.randint(0, 1000, (1,), requires_grad=True)
&gt;&gt;&gt; anchor = embedding(anchor_ids)
&gt;&gt;&gt; positive = embedding(positive_ids)
&gt;&gt;&gt; negative = embedding(negative_ids)
&gt;&gt;&gt;
&gt;&gt;&gt; # Built-in Distance Function
&gt;&gt;&gt; triplet_loss = \
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
&gt;&gt;&gt;
&gt;&gt;&gt; # Custom Distance Function
&gt;&gt;&gt; def l_infinity(x1, x2):
&gt;&gt;&gt;     return torch.max(torch.abs(x1 - x2), dim=1).values
&gt;&gt;&gt;
&gt;&gt;&gt; triplet_loss = \
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5)
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
&gt;&gt;&gt;
&gt;&gt;&gt; # Custom Distance Function (Lambda)
&gt;&gt;&gt; triplet_loss = \
&gt;&gt;&gt;     nn.TripletMarginWithDistanceLoss(
&gt;&gt;&gt;         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))
&gt;&gt;&gt; output = triplet_loss(anchor, positive, negative)
&gt;&gt;&gt; output.backward()
</pre> <dl class="simple"> <dt>Reference:</dt>
<dd>
<p>V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses: <a class="reference external" href="http://www.bmva.org/bmvc/2016/papers/paper119/index.html">http://www.bmva.org/bmvc/2016/papers/paper119/index.html</a></p> </dd> </dl> </dd>
</dl>
<div class="_attribution">
  <p class="_attribution-p">
    © 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.7.0/generated/torch.nn.TripletMarginWithDistanceLoss.html" class="_attribution-link">https://pytorch.org/docs/1.7.0/generated/torch.nn.TripletMarginWithDistanceLoss.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
