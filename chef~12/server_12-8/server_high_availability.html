
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>High Availability (DEPRECATED) - Chef 12 - W3cubDocs</title>
  
  <meta name="description" content=" Warning ">
  <meta name="keywords" content="high, availability, deprecated, chef, chef~12">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/chef~12/server_12-8/server_high_availability.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/chef~12.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/chef~12/" class="_nav-link" title="" style="margin-left:0;">Chef 12</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx_simple">
				
				
<h1 id="high-availability-deprecated">High Availability (DEPRECATED)</h1> <div class="admonition warning"> <p class="first admonition-title">Warning</p> <p class="last">This topic is deprecated as of the 12.9 release of the Chef servver. For the latest information on high availability and how to set up a highly-available server cluster, see High Availability: Backend Cluster .</p> </div> <p>The Chef server can operate in a high availability configuration that provides automated load balancing and failover for stateful components in the system architecture. This type of configuration typically splits the servers into two segments: front-end and back-end machines:</p> <img src="https://docs-archive.chef.io/release/server_12-8/_images/chef_server_ha.svg" width="600px">  <p>Front-end machines handle requests to the Chef server API and access to the web user interface. Front-end machines should be load balanced and scaled horizontally by increasing the number of servers available to handle requests.</p> <p>Back-end machines handle data storage and retrieval, messaging and routing, analytics processing, and search. Back-end machines should be configured for failover using block level replication.</p> <p>For Chef server 12, the following high availability configurations are supported:</p> <ul class="simple"> <li>DRBD</li> <li>AWS</li> </ul>  <h2 id="drbd">DRBD</h2> <p>DRBD is a supported high availability configuration option for the Chef server.</p> <img src="https://docs-archive.chef.io/release/server_12-8/_images/chef_server_ha_drbd.svg" width="600px">  <p>Front-end machines are scaled horizontally, and then load balanced using a hardware load balancer, SSL off-loading, and round-robin as the load balancing algorithm.</p> <p>Back-end machines are scaled vertically by adding memory, processing power, and faster disks to increase throughput, by adding faster disks and dedicated network interface cards to increase the reliability of DRBD and the responsiveness of the Chef server. Failover is achieved using:</p> <ul class="simple"> <li>Asynchronous block level replication of logical volume managers, positioned between the two back-end machines</li> <li>A primary and backup cluster election using VRRP over unicast TCP/IP and Keepalived</li> <li>A virtual IP address to the primary Chef server that is maintained based on the results of the election done by Keepalived</li> </ul> <p>When the primary Chef server in the cluster fails, the VRRP heartbeat will stop. At this point, the backup server will begin transitioning to the primary state by:</p> <ol class="arabic simple"> <li>Assigning the virtual IP address and sending a <code class="docutils literal">proxy-arp</code>; this step transitions the virtual IP address, which means traffic will flow to the back-end Chef server while it makes the transition to becoming the primary Chef server.</li> <li>Attempting to take over as the primary Chef server for the DRBD device.</li> <li>Starting all of the back-end services.</li> </ol> <p>For more information about DRBD, see <a class="reference external" href="http://www.drbd.org">http://www.drbd.org</a>.</p>  <h3 id="graceful-transitions">Graceful Transitions</h3> <p>The Keepalived service manages the VRRP and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following command on the primary Chef server:</p> <pre class="highlight-bash" data-language="bash">$ chef-server-ctl stop keepalived</pre> <p>This will initiate a failover from the primary to the secondary Chef server and will cause the current primary Chef server to remove the virtual IP address, stop all services, unmount the DRBD device, and then become the secondary Chef server for the DRBD device. Meanwhile, the secondary Chef server will undergo a similar process, but become the primary Chef server.</p> <p>To view the progress of this transition, use the following command:</p> <pre class="highlight-bash" data-language="bash">$ watch -n1 sudo chef-server-ctl ha-status</pre>   <h3 id="split-brains">Split Brains</h3> <p>A <code class="docutils literal">split-brain</code> event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a <code class="docutils literal">split-brain</code> event can be a complex issue and different clustering software packages use different methods.</p> <p>Failures happen, so completely preventing a <code class="docutils literal">split-brain</code> event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any <code class="docutils literal">split-brain</code> event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols.</p> <p>DRBD is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a high availability topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down.</p> <p>At any given time, only one DRBD host has <code class="docutils literal">userland</code> access to data, This host is referred to as the primary node. The other host runs the DRBD daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a <code class="docutils literal">mount</code> command can be sent).</p> <p>The approach that DRBD takes to <code class="docutils literal">split-brain</code> event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a high availability topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario.</p>  <h4 id="custom-handlers">Custom Handlers</h4> <p>DRBD configuration allows for custom handlers when a <code class="docutils literal">split-brain</code> event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated.</p> <p>The <code class="docutils literal">drbd.conf</code> file that is used with the Chef server specifies other built-in actions that may be taken in certain fault scenarios:</p> <pre class="highlight-none" data-language="none">after-sb-0pri discard-younger-primary;
after-sb-1pri discard-secondary;
after-sb-2pri call-pri-lost-after-sb;</pre> <p>What this means:</p> <ul class="simple"> <li>after-sb-0pri: A <code class="docutils literal">split-brain</code> event has been detected and neither node is the primary node. The <code class="docutils literal">discard-younger-primary</code> action will roll back any changes made on the last host that was the primary node.</li> <li>after-sb-1pri: A <code class="docutils literal">split-brain</code> event has been detected and only one node believes that it was the primary node when the event happened. The <code class="docutils literal">discard-secondary</code> action will continue operations on the primary node and will assume that the secondary node was lost.</li> <li>after-sb-2pri: A <code class="docutils literal">split-brain</code> event has been detected and both nodes believed they were primary nodes. The <code class="docutils literal">call-pri-lost-after-sb</code> action will attempt to apply the <code class="docutils literal">discard-younger-primary</code> from the <code class="docutils literal">0pri</code> configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node.</li> </ul>    <h3 id="assumptions">Assumptions</h3> <p>The following assumptions exist when the Chef server is deployed in a high availability topology:</p> <ul class="simple"> <li>The back-end processes run on two hosts: <code class="docutils literal">BE1</code> and <code class="docutils literal">BE2</code>. <code class="docutils literal">BE1</code> is the DRBD primary and the master Chef server; <code class="docutils literal">BE2</code> is the DRBD secondary and the Chef server backup</li> <li>The back-end uses Keepalived and a dedicated network interface for heartbeat</li> <li>The back-end uses DRBD for file redundancy</li> </ul> <p>On each host, its own status is reported first, and then the status of its remote partner.</p> <p>When both the primary and secondary nodes are running and behaving as expected, the contents of <code class="docutils literal">/proc/drbd</code> on the primary node will look similar to the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.0 (api:1/proto:86-100)
  GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by root@localhost.localdomain, 2012-02-06 12:59:36
0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r-----
      ns:4091788 nr:64 dw:112 dr:4092817 al:3 bm:252 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:0</pre> <p>On the secondary node, the status will look similar to the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.1 (api:1/proto:86-100)
  GIT-hash: 91b4c048c1a0e06777b5f65d312b38d47abaea80 build by dag@Build64R6, 2011-12-21 06:08:50
0: cs:Connected ro:Secondary/Primary ds:UpToDate/UpToDate C r-----
      ns:0 nr:48 dw:48 dr:0 al:0 bm:2 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:0</pre> <p>For information about the settings in this file, see the DRBD website: <a class="reference external" href="http://www.drbd.org/users-guide/ch-admin.html">http://www.drbd.org/users-guide/ch-admin.html</a>.</p>   <h3 id="failure-scenarios">Failure Scenarios</h3> <p>The following four common scenarios are discussed:</p> <ol class="arabic simple"> <li>Back-end server #2 fails gracefully (all data is synced)</li> <li>Back-end server #2 hard fails badly (unsynced data)</li> <li>Back-end server #1 fails gracefully (all data is synced)</li> <li>Back-end server #1 hard fails badly (unsynced data)</li> <li>Both hosts are up as secondary, and the Chef server is unhappy</li> </ol>  <h4 id="scenarios-1-and-2">Scenarios 1 and 2</h4> <p>When the active backup server fails, DRBD on the master will continue to function in primary mode, whether the DRBD on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that DRBD is functioning by running <code class="docutils literal">drbdadm role pc0</code> on the primary:</p> <pre class="highlight-bash" data-language="bash">[root@be1 opscode]# drbdadm role pc0
Primary/Unknown
[root@be1 opscode]#</pre> <p>You can see the full status by running cat <code class="docutils literal">/proc/drbd</code>:</p> <pre class="highlight-none" data-language="none">version: 8.4.0 (api:1/proto:86-100)
  GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by    root@localhost.localdomain, 2012-02-06 12:59:36
0: cs:WFConnection ro:Primary/Unknown ds:UpToDate/DUnknown C r-----
      ns:672 nr:0 dw:24 dr:1697 al:2 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:130760</pre> <p>The disk partition is still mounted into the file system and can be used as normal.</p> <p>When the secondary becomes available again, two things may happen:</p> <ul class="simple"> <li>If the status of the secondary reports <code class="docutils literal">Inconsistent</code> or <code class="docutils literal">UpToDate</code> without manual intervention, all is well.</li> <li>If it remains <code class="docutils literal">DUnknown</code>, DRBD on the secondary can be manually restarted and it will start to sync. The <code class="docutils literal">DUnknown</code> status is the report which indicates that DRBD sees no network connection to its partner.</li> </ul> <p>The last field in the <code class="docutils literal">/prod/drbd</code> file (<code class="docutils literal">oos</code>) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:</p> <pre class="highlight-none" data-language="none">version: 8.4.0 (api:1/proto:86-100)
GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by root@localhost.localdomain, 2012-02-06 12:59:36
 0: cs:WFConnection ro:Primary/Unknown ds:UpToDate/DUnknown C r-----
     ns:5205048 nr:64 dw:1466728 dr:4180125 al:354 bm:261 lo:1667 pe:0 ua:0 ap:1665 ep:1 wo:b oos:361540</pre> <p>When the disks return to a synced state, that field will return to <code class="docutils literal">0</code>. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:</p> <pre class="highlight-none" data-language="none">GIT-hash: 91b4c048c1a0e06777b5f65d312b38d47abaea80 build by dag@Build64R6, 2011-12-21 06:08:50
 0: cs:SyncTarget ro:Secondary/Primary ds:Inconsistent/UpToDate C r-----
    ns:0 nr:1263008 dw:1257888 dr:0 al:0 bm:60 lo:6 pe:8 ua:5 ap:0 ep:1 wo:f oos:1670512
        [======&gt;.............] sync'ed: 36.3% (1670512/2613068)K
        finish: 0:00:47 speed: 35,152 (18,124) want: 44,520 K/sec</pre> <p>and for the primary, something like the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.0 (api:1/proto:86-100)
GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by root@localhost.localdomain, 2012-02-06 12:59:36
 0: cs:SyncSource ro:Primary/Secondary ds:UpToDate/Inconsistent C r-----
    ns:7259268 nr:64 dw:4279364 dr:5721317 al:949 bm:360 lo:5 pe:0 ua:5 ap:0 ep:1 wo:b oos:1121600
        [==========&gt;.........] sync'ed: 57.3% (1121600/2613068)K
        finish: 0:00:32 speed: 34,328 (21,304) K/sec</pre> <p>Eventually the hosts will quiesce and report <code class="docutils literal">ds:UpToDate/UpToDate</code>. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. The processes used to manage the Chef server should not require manipulation in any way during this recovery.</p> <p>If the secondary host is lost completely, a new host can be installed in its place, the device built, and then DRBD started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary.</p>   <h4 id="scenario-3">Scenario 3</h4> <p>Trouble starts when the DRBD primary is the host that becomes unavailable. The DRBD process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the <code class="docutils literal">drbd.conf</code> file.</p> <p>Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, <code class="docutils literal">split-brained</code> host, and is the one unconnected and incorrect. It will take no automatic action.</p> <p>The status of the secondary will look something like the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.1 (api:1/proto:86-100)
GIT-hash: 91b4c048c1a0e06777b5f65d312b38d47abaea80 build by dag@Build64R6, 2011-12-21 06:08:50
 0: cs:WFConnection ro:Secondary/Unknown ds:UpToDate/DUnknown C r-----
    ns:0 nr:3505480 dw:4938128 dr:0 al:0 bm:290 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0</pre> <p>The <code class="docutils literal">ds:UpToDate/Unknown</code> is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted.</p> <p>If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:</p> <pre class="highlight-bash" data-language="bash">$ drbdadm primary pc0</pre> <p>at that point the status will change to something like the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.1 (api:1/proto:86-100)
GIT-hash: 91b4c048c1a0e06777b5f65d312b38d47abaea80 build by dag@Build64R6, 2011-12-21 06:08:50
 0: cs:WFConnection ro:Primary/Unknown ds:UpToDate/DUnknown C r-----
    ns:0 nr:3505480 dw:4938128 dr:672 al:0 bm:290 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0</pre> <p>Notice that <code class="docutils literal">ro</code> is now <code class="docutils literal">ro:Primary/Unknown</code>. The Chef server can now be recovered by entering the following command:</p> <pre class="highlight-bash" data-language="bash">$ chef-server-ctl master-recover</pre> <p>This will start up the configured services and the Chef server will be master on this host.</p> <p>If the original primary can be brought back online, the cluster management script run by Keepalived will try to do a DRBD takeover, based on that host’s original primary Chef server master status.</p> <p>The first thing it will do is attempt to promote itself to DRBD primary, which will fail if the disk has been written to at all while this host was down, and Keepalived will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the DRBD primary Chef server master.</p> <p>DRBD on the first back-end server will sync to the second back-end server and will become the clean secondary FQDN.</p>   <h4 id="scenario-4">Scenario 4</h4> <p>So far, the scenarios have not described any data loss. When the hosts in the high availability pair are synced, either can be lost and the data will be safe.</p> <p>If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the DRBD pair was reporting that the secondary node was in an <code class="docutils literal">Inconsistent</code> state, it is very likely that some data will be lost. The DRBD status on the remaining host will look something like the following:</p> <pre class="highlight-none" data-language="none">version: 8.4.0 (api:1/proto:86-100)
GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by root@localhost.localdomain, 2012-02-06 12:59:36
0: cs:WFConnection ro:Secondary/Unknown ds:Inconsistent/DUnknown C r-----
   ns:0 nr:210572 dw:210572 dr:0 al:0 bm:13 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:40552</pre> <p>As long as good source code management is practiced with cookbooks and other files in the chef-repo, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as chef-client runs and uploads may fail while the cluster is in an <code class="docutils literal">Inconsistent</code> state, but will be fine after there is a working cluster.</p> <p>When the primary back-end server has been lost while the secondary back-end server is in an <code class="docutils literal">Inconsistent</code> state and it’s not going to be back online quickly, the best thing to do is to provision another host to become the new Chef server cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure.</p> <p>In this situation, the Chef server may be freaking out a bit, so turn off the daemons using the <code class="docutils literal">chef-server-ctl stop</code> command.</p> <p>Once the new host is identified and the DRBD devices on that host are ready, bring up DRBD and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up DRBD on the new host and verify that it is listening on the correct port and that the status in <code class="docutils literal">/proc/drbd</code> is reporting that the host is up, but in the <code class="docutils literal">WFConnect: waiting for connection</code> state.</p> <p>By the time you get the new node is up, the secondary back-end server may have taken itself into <code class="docutils literal">standalone</code> mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:</p> <pre class="highlight-bash" data-language="bash">$ drbdadm primary --force pc0</pre> <p>and:</p> <pre class="highlight-bash" data-language="bash">$ drbdadm connect pc0</pre> <p>At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing the Chef server back online can begin.</p> <p>Running a fast network between the primary and secondary hosts, and keeping it full throttle for DRBD transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster.</p>   <h4 id="scenario-5">Scenario 5</h4> <p>Sometimes DRBD hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of <code class="docutils literal">/proc/drbd</code> on both hosts and see if either of them is showing out of sync. If they are both <code class="docutils literal">oos:0</code>, just pick one and promote it to primary using the <code class="docutils literal">drbdadm primary pc0</code> command. If one or both of the hosts is out of sync, choose the one with the lower amount of <code class="docutils literal">oos</code> and promote it to primary.</p> <p>If the chosen node won’t promote, run the following commands on the other host to reset its disk state:</p> <pre class="highlight-bash" data-language="bash">$ drbdadm wipe-md pc0</pre> <p>and:</p> <pre class="highlight-bash" data-language="bash">$ drbdadm create-md pc0</pre> <p>That will tell DRBD to abandon what is on the node and start over, and should allow it to sync with the primary.</p>     <h2 id="aws">AWS</h2> <p>Amazon Web Services (AWS) is a supported high availability configuration option for the Chef server.</p> <img src="https://docs-archive.chef.io/release/server_12-8/_images/chef_server_ha_aws.svg" width="600px">  <p>Backend servers make use of a single Amazon Elastic Block Store (EBS) volume.</p> <p>For more information about Amazon Elastic Block Store (EBS), see <a class="reference external" href="http://aws.amazon.com/ebs/">http://aws.amazon.com/ebs/</a>.</p> <p>View the topic <a class="reference internal" href="install_server_ha_aws">High Availability: AWS</a> for more information about how to set up the Chef server for high availability in Amazon Web Services (AWS).</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">This feature is included as part of the Chef Automate license agreement and is <a class="reference external" href="https://www.chef.io/pricing/">available via subscription</a>.</p> </div>   <h2 id="check-ha-status">Check HA Status</h2> <p>The <code class="docutils literal">/_status</code> endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at <code class="docutils literal">/_status</code> on the front end servers.</p> <p><strong>Request</strong></p> <pre class="highlight-none" data-language="none">api.get("https://chef_server.front_end.url/_status")</pre> <p>This method has no request body.</p> <p><strong>Response</strong></p> <p>The response will return something like the following:</p> <pre class="highlight-javascript" data-language="javascript">{
  "status": "pong",
  "upstreams":
    {
      "service_name": "pong",
      "service_name": "pong",
      ...
    }
 }</pre> <p><strong>Response Codes</strong></p> <table class="docutils"> <colgroup> <col width="40%"> <col width="60%"> </colgroup> <thead valign="bottom"> <tr class="row-odd">
<th class="head">Response Code</th> <th class="head">Description</th> </tr> </thead> <tbody valign="top"> <tr class="row-even">
<td><code class="docutils literal">200</code></td> <td>All communications are OK.</td> </tr> <tr class="row-odd">
<td><code class="docutils literal">500</code></td> <td>
<p class="first">One (or more) services are down. For example:</p> <pre class="last highlight-javascript" data-language="javascript">{
  "status":"fail",
  "upstreams":
    {
      "service_name": "fail",
      "service_name": "pong",
      ...
    }
}</pre> </td> </tr> </tbody> </table>
<div class="_attribution">
  <p class="_attribution-p">
    © Chef Software, Inc.<br>Licensed under the Creative Commons Attribution 3.0 Unported License.<br>The Chef™ Mark and Chef Logo are either registered trademarks/service marks or trademarks/servicemarks of Chef, in the United States and other countries and are used with Chef Inc's permission.<br>We are not affiliated with, endorsed or sponsored by Chef Inc.<br>
    <a href="https://docs-archive.chef.io/release/server_12-8/server_high_availability.html" class="_attribution-link">https://docs-archive.chef.io/release/server_12-8/server_high_availability.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
