
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.compat.v1.losses.softmax_cross_entropy - TensorFlow 2.9 - W3cubDocs</title>
  
  <meta name="description" content=" Creates a cross-entropy loss using tf.nn.softmax_cross_entropy_with_logits_v2. ">
  <meta name="keywords" content="tf, compat, losses, softmax, cross, entropy, tensorflow, tensorflow~2.9">
  <meta name="HandheldFriendly" content="True">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.9/compat/v1/losses/softmax_cross_entropy.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-f16eecbe420d8b2925d31ffbb21d05646497ecbd9515f08ffe69e9bba7332f5657accc7003c7f6c72cb4a132171acf171b359ae3bae4ae5660ddfb1718f88c67.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.9.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.9/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.9</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.compat.v1.losses.softmax_cross_entropy</h1> <devsite-bookmark></devsite-bookmark>       <p>Creates a cross-entropy loss using tf.nn.softmax_cross_entropy_with_logits_v2.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.losses.softmax_cross_entropy(
    onehot_labels,
    logits,
    weights=1.0,
    label_smoothing=0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
</pre> <p><section><devsite-expandable expanded> <h2 class="showalways" id="migrate-to-tf2" data-text="Migrate to TF2">Migrate to TF2</h2></devsite-expandable></section></p> <aside class="caution"><strong>Caution:</strong><span> This API was designed for TensorFlow v1. Continue reading for details on how to migrate from this API to a native TensorFlow v2 equivalent. See the <a href="https://www.tensorflow.org/guide/migrate">TensorFlow v1 to TensorFlow v2 migration guide</a> for instructions on how to migrate the rest of your code.</span></aside> <p><a href="softmax_cross_entropy"><code translate="no" dir="ltr">tf.compat.v1.losses.softmax_cross_entropy</code></a> is mostly compatible with eager execution and <a href="../../../function"><code translate="no" dir="ltr">tf.function</code></a>. But, the <code translate="no" dir="ltr">loss_collection</code> argument is ignored when executing eagerly and no loss will be written to the loss collections. You will need to either hold on to the return value manually or rely on <a href="../../../keras/model"><code translate="no" dir="ltr">tf.keras.Model</code></a> loss tracking.</p> <p>To switch to native TF2 style, instantiate the <a href="../../../keras/losses/categoricalcrossentropy"><code translate="no" dir="ltr">tf.keras.losses.CategoricalCrossentropy</code></a> class with <code translate="no" dir="ltr">from_logits</code> set as <code translate="no" dir="ltr">True</code> and call the object instead.</p> <h4 id="structural_mapping_to_native_tf2" data-text="Structural Mapping to Native TF2">Structural Mapping to Native TF2</h4> <p>Before:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">loss = tf.compat.v1.losses.softmax_cross_entropy(
  onehot_labels=onehot_labels,
  logits=logits,
  weights=weights,
  label_smoothing=smoothing)
</pre> <p>After:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">loss_fn = tf.keras.losses.CategoricalCrossentropy(
  from_logits=True,
  label_smoothing=smoothing)
loss = loss_fn(
  y_true=onehot_labels,
  y_pred=logits,
  sample_weight=weights)
</pre> <h4 id="how_to_map_arguments" data-text="How to Map Arguments">How to Map Arguments</h4> <table> <thead> <tr> <th style="text-align: left">TF1 Arg Name</th> <th style="text-align: left">TF2 Arg Name</th> <th style="text-align: left">Note</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">- </td> <td style="text-align: left">
<code translate="no" dir="ltr">from_logits</code> </td> <td style="text-align: left">Set <code translate="no" dir="ltr">from_logits</code> as True to have identical behavior</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">onehot_labels</code></td> <td style="text-align: left"><code translate="no" dir="ltr">y_true</code></td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">logits</code></td> <td style="text-align: left"><code translate="no" dir="ltr">y_pred</code></td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">weights</code></td> <td style="text-align: left"><code translate="no" dir="ltr">sample_weight</code></td> <td style="text-align: left">In <code translate="no" dir="ltr">__call__()</code> method</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">label_smoothing</code></td> <td style="text-align: left"><code translate="no" dir="ltr">label_smoothing</code></td> <td style="text-align: left">In constructor</td> </tr> <tr> <td style="text-align: left"><code translate="no" dir="ltr">scope</code></td> <td style="text-align: left">Not supported</td> <td style="text-align: left">-</td> </tr> <tr> <td style="text-align: left">
<code translate="no" dir="ltr">loss_collection</code> </td> <td style="text-align: left">Not supported </td> <td style="text-align: left">Losses should be tracked explicitly or with Keras APIs, for example, <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#add_loss">add_loss</a>, instead of via collections</td> </tr> <tr> <td style="text-align: left">
<code translate="no" dir="ltr">reduction</code> </td> <td style="text-align: left">
<code translate="no" dir="ltr">reduction</code> </td> <td style="text-align: left">In constructor. Value of <a href="reduction#SUM_OVER_BATCH_SIZE"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE</code></a>, <a href="reduction#SUM"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM</code></a>, <a href="reduction#NONE"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.NONE</code></a> in <a href="softmax_cross_entropy"><code translate="no" dir="ltr">tf.compat.v1.losses.softmax_cross_entropy</code></a> correspond to <a href="../../../keras/losses/reduction#SUM_OVER_BATCH_SIZE"><code translate="no" dir="ltr">tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE</code></a>, <a href="../../../keras/losses/reduction#SUM"><code translate="no" dir="ltr">tf.keras.losses.Reduction.SUM</code></a>, <a href="../../../keras/losses/reduction#NONE"><code translate="no" dir="ltr">tf.keras.losses.Reduction.NONE</code></a>, respectively. If you used other value for <code translate="no" dir="ltr">reduction</code>, including the default value <a href="reduction#SUM_BY_NONZERO_WEIGHTS"><code translate="no" dir="ltr">tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS</code></a>, there is no directly corresponding value. Please modify the loss implementation manually.</td> </tr> </tbody> </table> <h4 id="before_after_usage_example" data-text="Before &amp; After Usage Example">Before &amp; After Usage Example</h4> <p>Before:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
weights = [0.3, 0.7]
smoothing = 0.2
tf.compat.v1.losses.softmax_cross_entropy(y_true, y_pred, weights=weights,
  label_smoothing=smoothing).numpy()
0.57618
</pre> <p>After:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True,
  label_smoothing=smoothing)
cce(y_true, y_pred, sample_weight=weights).numpy()
0.57618
</pre>  <h2 id="description" data-text="Description">Description</h2>  <p><code translate="no" dir="ltr">weights</code> acts as a coefficient for the loss. If a scalar is provided, then the loss is simply scaled by the given value. If <code translate="no" dir="ltr">weights</code> is a tensor of shape <code translate="no" dir="ltr">[batch_size]</code>, then the loss weights apply to each corresponding sample.</p> <p>If <code translate="no" dir="ltr">label_smoothing</code> is nonzero, smooth the labels towards 1/num_classes: new_onehot_labels = onehot_labels * (1 - label_smoothing)</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">+ label_smoothing / num_classes
</pre> <p>Note that <code translate="no" dir="ltr">onehot_labels</code> and <code translate="no" dir="ltr">logits</code> must have the same shape, e.g. <code translate="no" dir="ltr">[batch_size, num_classes]</code>. The shape of <code translate="no" dir="ltr">weights</code> must be broadcastable to loss, whose shape is decided by the shape of <code translate="no" dir="ltr">logits</code>. In case the shape of <code translate="no" dir="ltr">logits</code> is <code translate="no" dir="ltr">[batch_size, num_classes]</code>, loss is a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[batch_size]</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">onehot_labels</code> </td> <td> One-hot-encoded labels. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logits</code> </td> <td> Logits outputs of the network. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">weights</code> </td> <td> Optional <code translate="no" dir="ltr">Tensor</code> that is broadcastable to loss. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">label_smoothing</code> </td> <td> If greater than 0 then smooth the labels. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">scope</code> </td> <td> the scope for the operations performed in computing the loss. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_collection</code> </td> <td> collection to which the loss will be added. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reduction</code> </td> <td> Type of reduction to apply to loss. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Weighted loss <code translate="no" dir="ltr">Tensor</code> of the same type as <code translate="no" dir="ltr">logits</code>. If <code translate="no" dir="ltr">reduction</code> is <code translate="no" dir="ltr">NONE</code>, this has shape <code translate="no" dir="ltr">[batch_size]</code>; otherwise, it is scalar. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the shape of <code translate="no" dir="ltr">logits</code> doesn't match that of <code translate="no" dir="ltr">onehot_labels</code> or if the shape of <code translate="no" dir="ltr">weights</code> is invalid or if <code translate="no" dir="ltr">weights</code> is None. Also if <code translate="no" dir="ltr">onehot_labels</code> or <code translate="no" dir="ltr">logits</code> is None. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/losses/softmax_cross_entropy" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/compat/v1/losses/softmax_cross_entropy</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
