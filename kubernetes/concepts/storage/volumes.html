
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Volumes - Kubernetes - W3cubDocs</title>
  
  <meta name="description" content="On-disk files in a container are ephemeral, which presents some problems for non-trivial applications when running in containers. One problem is the &hellip;">
  <meta name="keywords" content="volumes, kubernetes">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/kubernetes/concepts/storage/volumes.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-60a6449bb52e9968d95c133a29f066ffcb8dbe4f077d4022e51c991ce30bf256c8e19c508207a4193c414ffd0414826564317669b0f27f9f85c1cb21b84e097e.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/kubernetes.js"></script>
  
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/kubernetes/" class="_nav-link" title="" style="margin-left:0;">Kubernetes</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _kubernetes">
				
				
<h1>Volumes</h1>  <p>On-disk files in a container are ephemeral, which presents some problems for non-trivial applications when running in containers. One problem is the loss of files when a container crashes. The kubelet restarts the container but with a clean state. A second problem occurs when sharing files between containers running together in a <code>Pod</code>. The Kubernetes <a class="glossary-tooltip" title="A directory containing data, accessible to the containers in a pod." data-toggle="tooltip" data-placement="top" href="volumes/index" target="_blank" aria-label="volume">volume</a> abstraction solves both of these problems. Familiarity with <a href="../workloads/pods/index">Pods</a> is suggested.</p>  <h2 id="background">Background</h2> <p>Docker has a concept of <a href="https://docs.docker.com/storage/">volumes</a>, though it is somewhat looser and less managed. A Docker volume is a directory on disk or in another container. Docker provides volume drivers, but the functionality is somewhat limited.</p> <p>Kubernetes supports many types of volumes. A <a class="glossary-tooltip" title="A Pod represents a set of running containers in your cluster." data-toggle="tooltip" data-placement="top" href="../workloads/pods/index" target="_blank" aria-label="Pod">Pod</a> can use any number of volume types simultaneously. Ephemeral volume types have a lifetime of a pod, but persistent volumes exist beyond the lifetime of a pod. When a pod ceases to exist, Kubernetes destroys ephemeral volumes; however, Kubernetes does not destroy persistent volumes. For any kind of volume in a given pod, data is preserved across container restarts.</p> <p>At its core, a volume is a directory, possibly with some data in it, which is accessible to the containers in a pod. How that directory comes to be, the medium that backs it, and the contents of it are determined by the particular volume type used.</p> <p>To use a volume, specify the volumes to provide for the Pod in <code>.spec.volumes</code> and declare where to mount those volumes into containers in <code>.spec.containers[*].volumeMounts</code>. A process in a container sees a filesystem view composed from the initial contents of the <a class="glossary-tooltip" title="Stored instance of a container that holds a set of software needed to run an application." data-toggle="tooltip" data-placement="top" href="https://kubernetes.io/docs/reference/glossary/?all=true#term-image" target="_blank" aria-label="container image">container image</a>, plus volumes (if defined) mounted inside the container. The process sees a root filesystem that initially matches the contents of the container image. Any writes to within that filesystem hierarchy, if allowed, affect what that process views when it performs a subsequent filesystem access. Volumes mount at the <a href="#using-subpath">specified paths</a> within the image. For each container defined within a Pod, you must independently specify where to mount each volume that the container uses.</p> <p>Volumes cannot mount within other volumes (but see <a href="#using-subpath">Using subPath</a> for a related mechanism). Also, a volume cannot contain a hard link to anything in a different volume.</p> <h2 id="volume-types">Types of Volumes</h2> <p>Kubernetes supports several types of volumes.</p> <h3 id="awselasticblockstore">awsElasticBlockStore</h3> <p>An <code>awsElasticBlockStore</code> volume mounts an Amazon Web Services (AWS) <a href="https://aws.amazon.com/ebs/">EBS volume</a> into your pod. Unlike <code>emptyDir</code>, which is erased when a pod is removed, the contents of an EBS volume are persisted and the volume is unmounted. This means that an EBS volume can be pre-populated with data, and that data can be shared between pods.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must create an EBS volume by using <code>aws ec2 create-volume</code> or the AWS API before you can use it. </div> <p>There are some restrictions when using an <code>awsElasticBlockStore</code> volume:</p> <ul> <li>the nodes on which pods are running must be AWS EC2 instances</li> <li>those instances need to be in the same region and availability zone as the EBS volume</li> <li>EBS only supports a single EC2 instance mounting a volume</li> </ul> <h4 id="creating-an-aws-ebs-volume">Creating an AWS EBS volume</h4> <p>Before you can use an EBS volume with a pod, you need to create it.</p> <pre class="highlight" data-language="shell">aws ec2 create-volume --availability-zone=eu-west-1a --size=10 --volume-type=gp2
</pre>
<p>Make sure the zone matches the zone you brought up your cluster in. Check that the size and EBS volume type are suitable for your use.</p> <h4 id="aws-ebs-configuration-example">AWS EBS configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-ebs
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /test-ebs
      name: test-volume
  volumes:
  - name: test-volume
    # This AWS EBS volume must already exist.
    awsElasticBlockStore:
      volumeID: "&lt;volume id&gt;"
      fsType: ext4
</pre>
<p>If the EBS volume is partitioned, you can supply the optional field <code>partition: "&lt;partition number&gt;"</code> to specify which parition to mount on.</p> <h4 id="aws-ebs-csi-migration">AWS EBS CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for <code>awsElasticBlockStore</code>, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>ebs.csi.aws.com</code> Container Storage Interface (CSI) driver. In order to use this feature, the <a href="https://github.com/kubernetes-sigs/aws-ebs-csi-driver">AWS EBS CSI driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationAWS</code> beta features must be enabled.</p> <h4 id="aws-ebs-csi-migration-complete">AWS EBS CSI migration complete</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code> </div> <p>To disable the <code>awsElasticBlockStore</code> storage plugin from being loaded by the controller manager and the kubelet, set the <code>InTreePluginAWSUnregister</code> flag to <code>true</code>.</p> <h3 id="azuredisk">azureDisk</h3> <p>The <code>azureDisk</code> volume type mounts a Microsoft Azure <a href="https://docs.microsoft.com/en-us/azure/aks/csi-storage-drivers">Data Disk</a> into a pod.</p> <p>For more details, see the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_disk/README.md"><code>azureDisk</code> volume plugin</a>.</p> <h4 id="azuredisk-csi-migration">azureDisk CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for <code>azureDisk</code>, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>disk.csi.azure.com</code> Container Storage Interface (CSI) Driver. In order to use this feature, the <a href="https://github.com/kubernetes-sigs/azuredisk-csi-driver">Azure Disk CSI Driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationAzureDisk</code> features must be enabled.</p> <h3 id="azurefile">azureFile</h3> <p>The <code>azureFile</code> volume type mounts a Microsoft Azure File volume (SMB 2.1 and 3.0) into a pod.</p> <p>For more details, see the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_file/README.md"><code>azureFile</code> volume plugin</a>.</p> <h4 id="azurefile-csi-migration">azureFile CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.21 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for <code>azureFile</code>, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>file.csi.azure.com</code> Container Storage Interface (CSI) Driver. In order to use this feature, the <a href="https://github.com/kubernetes-sigs/azurefile-csi-driver">Azure File CSI Driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationAzureFile</code> <a href="../../reference/command-line-tools-reference/feature-gates/index">feature gates</a> must be enabled.</p> <p>Azure File CSI driver does not support using same volume with different fsgroups, if Azurefile CSI migration is enabled, using same volume with different fsgroups won't be supported at all.</p> <h3 id="cephfs">cephfs</h3> <p>A <code>cephfs</code> volume allows an existing CephFS volume to be mounted into your Pod. Unlike <code>emptyDir</code>, which is erased when a pod is removed, the contents of a <code>cephfs</code> volume are preserved and the volume is merely unmounted. This means that a <code>cephfs</code> volume can be pre-populated with data, and that data can be shared between pods. The <code>cephfs</code> volume can be mounted by multiple writers simultaneously.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own Ceph server running with the share exported before you can use it. </div> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/volumes/cephfs/">CephFS example</a> for more details.</p> <h3 id="cinder">cinder</h3> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> Kubernetes must be configured with the OpenStack cloud provider. </div> <p>The <code>cinder</code> volume type is used to mount the OpenStack Cinder volume into your pod.</p> <h4 id="cinder-volume-configuration-example">Cinder volume configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-cinder
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-cinder-container
    volumeMounts:
    - mountPath: /test-cinder
      name: test-volume
  volumes:
  - name: test-volume
    # This OpenStack volume must already exist.
    cinder:
      volumeID: "&lt;volume id&gt;"
      fsType: ext4
</pre>
<h4 id="openstack-csi-migration">OpenStack CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.21 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for Cinder is enabled by default in Kubernetes 1.21. It redirects all plugin operations from the existing in-tree plugin to the <code>cinder.csi.openstack.org</code> Container Storage Interface (CSI) Driver. <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/using-cinder-csi-plugin.md">OpenStack Cinder CSI Driver</a> must be installed on the cluster. You can disable Cinder CSI migration for your cluster by setting the <code>CSIMigrationOpenStack</code> <a href="../../reference/command-line-tools-reference/feature-gates/index">feature gate</a> to <code>false</code>. If you disable the <code>CSIMigrationOpenStack</code> feature, the in-tree Cinder volume plugin takes responsibility for all aspects of Cinder volume storage management.</p> <h3 id="configmap">configMap</h3> <p>A <a href="../../tasks/configure-pod-container/configure-pod-configmap/index">ConfigMap</a> provides a way to inject configuration data into pods. The data stored in a ConfigMap can be referenced in a volume of type <code>configMap</code> and then consumed by containerized applications running in a pod.</p> <p>When referencing a ConfigMap, you provide the name of the ConfigMap in the volume. You can customize the path to use for a specific entry in the ConfigMap. The following configuration shows how to mount the <code>log-config</code> ConfigMap onto a Pod called <code>configmap-pod</code>:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: configmap-pod
spec:
  containers:
    - name: test
      image: busybox
      volumeMounts:
        - name: config-vol
          mountPath: /etc/config
  volumes:
    - name: config-vol
      configMap:
        name: log-config
        items:
          - key: log_level
            path: log_level
</pre>
<p>The <code>log-config</code> ConfigMap is mounted as a volume, and all contents stored in its <code>log_level</code> entry are mounted into the Pod at path <code>/etc/config/log_level</code>. Note that this path is derived from the volume's <code>mountPath</code> and the <code>path</code> keyed with <code>log_level</code>.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> <ul> <li> <p>You must create a <a href="../../tasks/configure-pod-container/configure-pod-configmap/index">ConfigMap</a> before you can use it.</p> </li> <li> <p>A container using a ConfigMap as a <a href="#using-subpath"><code>subPath</code></a> volume mount will not receive ConfigMap updates.</p> </li> <li> <p>Text data is exposed as files using the UTF-8 character encoding. For other character encodings, use <code>binaryData</code>.</p> </li> </ul> </div> <h3 id="downwardapi">downwardAPI</h3> <p>A <code>downwardAPI</code> volume makes downward API data available to applications. It mounts a directory and writes the requested data in plain text files.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> A container using the downward API as a <a href="#using-subpath"><code>subPath</code></a> volume mount will not receive downward API updates. </div> <p>See the <a href="../../tasks/inject-data-application/downward-api-volume-expose-pod-information/index">downward API example</a> for more details.</p> <h3 id="emptydir">emptyDir</h3> <p>An <code>emptyDir</code> volume is first created when a Pod is assigned to a node, and exists as long as that Pod is running on that node. As the name says, the <code>emptyDir</code> volume is initially empty. All containers in the Pod can read and write the same files in the <code>emptyDir</code> volume, though that volume can be mounted at the same or different paths in each container. When a Pod is removed from a node for any reason, the data in the <code>emptyDir</code> is deleted permanently.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> A container crashing does <em>not</em> remove a Pod from a node. The data in an <code>emptyDir</code> volume is safe across container crashes. </div> <p>Some uses for an <code>emptyDir</code> are:</p> <ul> <li>scratch space, such as for a disk-based merge sort</li> <li>checkpointing a long computation for recovery from crashes</li> <li>holding files that a content-manager container fetches while a webserver container serves the data</li> </ul> <p>Depending on your environment, <code>emptyDir</code> volumes are stored on whatever medium that backs the node such as disk or SSD, or network storage. However, if you set the <code>emptyDir.medium</code> field to <code>"Memory"</code>, Kubernetes mounts a tmpfs (RAM-backed filesystem) for you instead. While tmpfs is very fast, be aware that unlike disks, tmpfs is cleared on node reboot and any files you write count against your container's memory limit.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> If the <code>SizeMemoryBackedVolumes</code> <a href="../../reference/command-line-tools-reference/feature-gates/index">feature gate</a> is enabled, you can specify a size for memory backed volumes. If no size is specified, memory backed volumes are sized to 50% of the memory on a Linux host. </div> <h4 id="emptydir-configuration-example">emptyDir configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
</pre>
<h3 id="fc">fc (fibre channel)</h3> <p>An <code>fc</code> volume type allows an existing fibre channel block storage volume to mount in a Pod. You can specify single or multiple target world wide names (WWNs) using the parameter <code>targetWWNs</code> in your Volume configuration. If multiple WWNs are specified, targetWWNs expect that those WWNs are from multi-path connections.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must configure FC SAN Zoning to allocate and mask those LUNs (volumes) to the target WWNs beforehand so that Kubernetes hosts can access them. </div> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/fibre_channel">fibre channel example</a> for more details.</p> <h3 id="flocker">flocker (deprecated)</h3> <p><a href="https://github.com/ClusterHQ/flocker">Flocker</a> is an open-source, clustered container data volume manager. Flocker provides management and orchestration of data volumes backed by a variety of storage backends.</p> <p>A <code>flocker</code> volume allows a Flocker dataset to be mounted into a Pod. If the dataset does not already exist in Flocker, it needs to be first created with the Flocker CLI or by using the Flocker API. If the dataset already exists it will be reattached by Flocker to the node that the pod is scheduled. This means data can be shared between pods as required.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own Flocker installation running before you can use it. </div> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/flocker">Flocker example</a> for more details.</p> <h3 id="gcepersistentdisk">gcePersistentDisk</h3> <p>A <code>gcePersistentDisk</code> volume mounts a Google Compute Engine (GCE) <a href="https://cloud.google.com/compute/docs/disks">persistent disk</a> (PD) into your Pod. Unlike <code>emptyDir</code>, which is erased when a pod is removed, the contents of a PD are preserved and the volume is merely unmounted. This means that a PD can be pre-populated with data, and that data can be shared between pods.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must create a PD using <code>gcloud</code> or the GCE API or UI before you can use it. </div> <p>There are some restrictions when using a <code>gcePersistentDisk</code>:</p> <ul> <li>the nodes on which Pods are running must be GCE VMs</li> <li>those VMs need to be in the same GCE project and zone as the persistent disk</li> </ul> <p>One feature of GCE persistent disk is concurrent read-only access to a persistent disk. A <code>gcePersistentDisk</code> volume permits multiple consumers to simultaneously mount a persistent disk as read-only. This means that you can pre-populate a PD with your dataset and then serve it in parallel from as many Pods as you need. Unfortunately, PDs can only be mounted by a single consumer in read-write mode. Simultaneous writers are not allowed.</p> <p>Using a GCE persistent disk with a Pod controlled by a ReplicaSet will fail unless the PD is read-only or the replica count is 0 or 1.</p> <h4 id="gce-create-persistent-disk">Creating a GCE persistent disk</h4> <p>Before you can use a GCE persistent disk with a Pod, you need to create it.</p> <pre class="highlight" data-language="shell">gcloud compute disks create --size=500GB --zone=us-central1-a my-data-disk
</pre>
<h4 id="gce-persistent-disk-configuration-example">GCE persistent disk configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: test-volume
    # This GCE PD must already exist.
    gcePersistentDisk:
      pdName: my-data-disk
      fsType: ext4
</pre>
<h4 id="regional-persistent-disks">Regional persistent disks</h4> <p>The <a href="https://cloud.google.com/compute/docs/disks/#repds">Regional persistent disks</a> feature allows the creation of persistent disks that are available in two zones within the same region. In order to use this feature, the volume must be provisioned as a PersistentVolume; referencing the volume directly from a pod is not supported.</p> <h4 id="manually-provisioning-a-regional-pd-persistentvolume">Manually provisioning a Regional PD PersistentVolume</h4> <p>Dynamic provisioning is possible using a <a href="storage-classes/index#gce">StorageClass for GCE PD</a>. Before creating a PersistentVolume, you must create the persistent disk:</p> <pre class="highlight" data-language="shell">gcloud compute disks create --size=500GB my-data-disk
  --region us-central1
  --replica-zones us-central1-a,us-central1-b
</pre>
<h4 id="regional-persistent-disk-configuration-example">Regional persistent disk configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: test-volume
spec:
  capacity:
    storage: 400Gi
  accessModes:
  - ReadWriteOnce
  gcePersistentDisk:
    pdName: my-data-disk
    fsType: ext4
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        # failure-domain.beta.kubernetes.io/zone should be used prior to 1.21
        - key: topology.kubernetes.io/zone
          operator: In
          values:
          - us-central1-a
          - us-central1-b
</pre>
<h4 id="gce-csi-migration">GCE CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for GCE PD, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>pd.csi.storage.gke.io</code> Container Storage Interface (CSI) Driver. In order to use this feature, the <a href="https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver">GCE PD CSI Driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationGCE</code> beta features must be enabled.</p> <h4 id="gce-csi-migration-complete">GCE CSI migration complete</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.21 [alpha]</code> </div> <p>To disable the <code>gcePersistentDisk</code> storage plugin from being loaded by the controller manager and the kubelet, set the <code>InTreePluginGCEUnregister</code> flag to <code>true</code>.</p> <h3 id="gitrepo">gitRepo (deprecated)</h3> <div class="alert alert-danger warning callout" role="alert"> <strong>Warning:</strong> The <code>gitRepo</code> volume type is deprecated. To provision a container with a git repo, mount an <a href="#emptydir">EmptyDir</a> into an InitContainer that clones the repo using git, then mount the <a href="#emptydir">EmptyDir</a> into the Pod's container. </div> <p>A <code>gitRepo</code> volume is an example of a volume plugin. This plugin mounts an empty directory and clones a git repository into this directory for your Pod to use.</p> <p>Here is an example of a <code>gitRepo</code> volume:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: server
spec:
  containers:
  - image: nginx
    name: nginx
    volumeMounts:
    - mountPath: /mypath
      name: git-volume
  volumes:
  - name: git-volume
    gitRepo:
      repository: "git@somewhere:me/my-git-repository.git"
      revision: "22f1d8406d464b0c0874075539c1f2e96c253775"
</pre>
<h3 id="glusterfs">glusterfs</h3> <p>A <code>glusterfs</code> volume allows a <a href="https://www.gluster.org">Glusterfs</a> (an open source networked filesystem) volume to be mounted into your Pod. Unlike <code>emptyDir</code>, which is erased when a Pod is removed, the contents of a <code>glusterfs</code> volume are preserved and the volume is merely unmounted. This means that a glusterfs volume can be pre-populated with data, and that data can be shared between pods. GlusterFS can be mounted by multiple writers simultaneously.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own GlusterFS installation running before you can use it. </div> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/volumes/glusterfs">GlusterFS example</a> for more details.</p> <h3 id="hostpath">hostPath</h3> <div class="alert alert-danger warning callout" role="alert"> <strong>Warning:</strong> <p>HostPath volumes present many security risks, and it is a best practice to avoid the use of HostPaths when possible. When a HostPath volume must be used, it should be scoped to only the required file or directory, and mounted as ReadOnly.</p> <p>If restricting HostPath access to specific directories through AdmissionPolicy, <code>volumeMounts</code> MUST be required to use <code>readOnly</code> mounts for the policy to be effective.</p> </div> <p>A <code>hostPath</code> volume mounts a file or directory from the host node's filesystem into your Pod. This is not something that most Pods will need, but it offers a powerful escape hatch for some applications.</p> <p>For example, some uses for a <code>hostPath</code> are:</p> <ul> <li>running a container that needs access to Docker internals; use a <code>hostPath</code> of <code>/var/lib/docker</code>
</li> <li>running cAdvisor in a container; use a <code>hostPath</code> of <code>/sys</code>
</li> <li>allowing a Pod to specify whether a given <code>hostPath</code> should exist prior to the Pod running, whether it should be created, and what it should exist as</li> </ul> <p>In addition to the required <code>path</code> property, you can optionally specify a <code>type</code> for a <code>hostPath</code> volume.</p> <p>The supported values for field <code>type</code> are:</p> <table> <thead> <tr> <th style="text-align:left">Value</th> <th style="text-align:left">Behavior</th> </tr> </thead> <tbody> <tr> <td style="text-align:left"></td> <td style="text-align:left">Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume.</td> </tr> <tr> <td style="text-align:left"><code>DirectoryOrCreate</code></td> <td style="text-align:left">If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet.</td> </tr> <tr> <td style="text-align:left"><code>Directory</code></td> <td style="text-align:left">A directory must exist at the given path</td> </tr> <tr> <td style="text-align:left"><code>FileOrCreate</code></td> <td style="text-align:left">If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet.</td> </tr> <tr> <td style="text-align:left"><code>File</code></td> <td style="text-align:left">A file must exist at the given path</td> </tr> <tr> <td style="text-align:left"><code>Socket</code></td> <td style="text-align:left">A UNIX socket must exist at the given path</td> </tr> <tr> <td style="text-align:left"><code>CharDevice</code></td> <td style="text-align:left">A character device must exist at the given path</td> </tr> <tr> <td style="text-align:left"><code>BlockDevice</code></td> <td style="text-align:left">A block device must exist at the given path</td> </tr> </tbody> </table> <p>Watch out when using this type of volume, because:</p> <ul> <li>HostPaths can expose privileged system credentials (such as for the Kubelet) or privileged APIs (such as container runtime socket), which can be used for container escape or to attack other parts of the cluster.</li> <li>Pods with identical configuration (such as created from a PodTemplate) may behave differently on different nodes due to different files on the nodes</li> <li>The files or directories created on the underlying hosts are only writable by root. You either need to run your process as root in a <a href="../../tasks/configure-pod-container/security-context/index">privileged Container</a> or modify the file permissions on the host to be able to write to a <code>hostPath</code> volume</li> </ul> <h4 id="hostpath-configuration-example">hostPath configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: test-volume
    hostPath:
      # directory location on host
      path: /data
      # this field is optional
      type: Directory
</pre>
<div class="alert alert-warning caution callout" role="alert"> <strong>Caution:</strong> The <code>FileOrCreate</code> mode does not create the parent directory of the file. If the parent directory of the mounted file does not exist, the pod fails to start. To ensure that this mode works, you can try to mount directories and files separately, as shown in the <a href="#hostpath-fileorcreate-example"><code>FileOrCreate</code>configuration</a>. </div> <h4 id="hostpath-fileorcreate-example">hostPath FileOrCreate configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-webserver
spec:
  containers:
  - name: test-webserver
    image: k8s.gcr.io/test-webserver:latest
    volumeMounts:
    - mountPath: /var/local/aaa
      name: mydir
    - mountPath: /var/local/aaa/1.txt
      name: myfile
  volumes:
  - name: mydir
    hostPath:
      # Ensure the file directory is created.
      path: /var/local/aaa
      type: DirectoryOrCreate
  - name: myfile
    hostPath:
      path: /var/local/aaa/1.txt
      type: FileOrCreate
</pre>
<h3 id="iscsi">iscsi</h3> <p>An <code>iscsi</code> volume allows an existing iSCSI (SCSI over IP) volume to be mounted into your Pod. Unlike <code>emptyDir</code>, which is erased when a Pod is removed, the contents of an <code>iscsi</code> volume are preserved and the volume is merely unmounted. This means that an iscsi volume can be pre-populated with data, and that data can be shared between pods.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own iSCSI server running with the volume created before you can use it. </div> <p>A feature of iSCSI is that it can be mounted as read-only by multiple consumers simultaneously. This means that you can pre-populate a volume with your dataset and then serve it in parallel from as many Pods as you need. Unfortunately, iSCSI volumes can only be mounted by a single consumer in read-write mode. Simultaneous writers are not allowed.</p> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/volumes/iscsi">iSCSI example</a> for more details.</p> <h3 id="local">local</h3> <p>A <code>local</code> volume represents a mounted local storage device such as a disk, partition or directory.</p> <p>Local volumes can only be used as a statically created PersistentVolume. Dynamic provisioning is not supported.</p> <p>Compared to <code>hostPath</code> volumes, <code>local</code> volumes are used in a durable and portable manner without manually scheduling pods to nodes. The system is aware of the volume's node constraints by looking at the node affinity on the PersistentVolume.</p> <p>However, <code>local</code> volumes are subject to the availability of the underlying node and are not suitable for all applications. If a node becomes unhealthy, then the <code>local</code> volume becomes inaccessible by the pod. The pod using this volume is unable to run. Applications using <code>local</code> volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.</p> <p>The following example shows a PersistentVolume using a <code>local</code> volume and <code>nodeAffinity</code>:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-pv
spec:
  capacity:
    storage: 100Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /mnt/disks/ssd1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - example-node
</pre>
<p>You must set a PersistentVolume <code>nodeAffinity</code> when using <code>local</code> volumes. The Kubernetes scheduler uses the PersistentVolume <code>nodeAffinity</code> to schedule these Pods to the correct node.</p> <p>PersistentVolume <code>volumeMode</code> can be set to "Block" (instead of the default value "Filesystem") to expose the local volume as a raw block device.</p> <p>When using local volumes, it is recommended to create a StorageClass with <code>volumeBindingMode</code> set to <code>WaitForFirstConsumer</code>. For more details, see the local <a href="storage-classes/index#local">StorageClass</a> example. Delaying volume binding ensures that the PersistentVolumeClaim binding decision will also be evaluated with any other node constraints the Pod may have, such as node resource requirements, node selectors, Pod affinity, and Pod anti-affinity.</p> <p>An external static provisioner can be run separately for improved management of the local volume lifecycle. Note that this provisioner does not support dynamic provisioning yet. For an example on how to run an external local provisioner, see the <a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">local volume provisioner user guide</a>.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> The local PersistentVolume requires manual cleanup and deletion by the user if the external static provisioner is not used to manage the volume lifecycle. </div> <h3 id="nfs">nfs</h3> <p>An <code>nfs</code> volume allows an existing NFS (Network File System) share to be mounted into a Pod. Unlike <code>emptyDir</code>, which is erased when a Pod is removed, the contents of an <code>nfs</code> volume are preserved and the volume is merely unmounted. This means that an NFS volume can be pre-populated with data, and that data can be shared between pods. NFS can be mounted by multiple writers simultaneously.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own NFS server running with the share exported before you can use it. </div> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs">NFS example</a> for more details.</p> <h3 id="persistentvolumeclaim">persistentVolumeClaim</h3> <p>A <code>persistentVolumeClaim</code> volume is used to mount a <a href="persistent-volumes/index">PersistentVolume</a> into a Pod. PersistentVolumeClaims are a way for users to "claim" durable storage (such as a GCE PersistentDisk or an iSCSI volume) without knowing the details of the particular cloud environment.</p> <p>See the information about <a href="persistent-volumes/index">PersistentVolumes</a> for more details.</p> <h3 id="portworxvolume">portworxVolume</h3> <p>A <code>portworxVolume</code> is an elastic block storage layer that runs hyperconverged with Kubernetes. <a href="https://portworx.com/use-case/kubernetes-storage/">Portworx</a> fingerprints storage in a server, tiers based on capabilities, and aggregates capacity across multiple servers. Portworx runs in-guest in virtual machines or on bare metal Linux nodes.</p> <p>A <code>portworxVolume</code> can be dynamically created through Kubernetes or it can also be pre-provisioned and referenced inside a Pod. Here is an example Pod referencing a pre-provisioned Portworx volume:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-portworx-volume-pod
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /mnt
      name: pxvol
  volumes:
  - name: pxvol
    # This Portworx volume must already exist.
    portworxVolume:
      volumeID: "pxvol"
      fsType: "&lt;fs-type&gt;"
</pre>
<div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> Make sure you have an existing PortworxVolume with name <code>pxvol</code> before using it in the Pod. </div> <p>For more details, see the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/portworx/README.md">Portworx volume</a> examples.</p> <h3 id="projected">projected</h3> <p>A projected volume maps several existing volume sources into the same directory. For more details, see <a href="projected-volumes/index">projected volumes</a>.</p> <h3 id="quobyte">quobyte (deprecated)</h3> <p>A <code>quobyte</code> volume allows an existing <a href="https://www.quobyte.com">Quobyte</a> volume to be mounted into your Pod.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have your own Quobyte setup and running with the volumes created before you can use it. </div> <p>Quobyte supports the <a class="glossary-tooltip" title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle="tooltip" data-placement="top" href="volumes/index#csi" target="_blank" aria-label="Container Storage Interface">Container Storage Interface</a>. CSI is the recommended plugin to use Quobyte volumes inside Kubernetes. Quobyte's GitHub project has <a href="https://github.com/quobyte/quobyte-csi#quobyte-csi">instructions</a> for deploying Quobyte using CSI, along with examples.</p> <h3 id="rbd">rbd</h3> <p>An <code>rbd</code> volume allows a <a href="https://docs.ceph.com/en/latest/rbd/">Rados Block Device</a> (RBD) volume to mount into your Pod. Unlike <code>emptyDir</code>, which is erased when a pod is removed, the contents of an <code>rbd</code> volume are preserved and the volume is unmounted. This means that a RBD volume can be pre-populated with data, and that data can be shared between pods.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must have a Ceph installation running before you can use RBD. </div> <p>A feature of RBD is that it can be mounted as read-only by multiple consumers simultaneously. This means that you can pre-populate a volume with your dataset and then serve it in parallel from as many pods as you need. Unfortunately, RBD volumes can only be mounted by a single consumer in read-write mode. Simultaneous writers are not allowed.</p> <p>See the <a href="https://github.com/kubernetes/examples/tree/master/volumes/rbd">RBD example</a> for more details.</p> <h4 id="rbd-csi-migration">RBD CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code> </div> <p>The <code>CSIMigration</code> feature for <code>RBD</code>, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>rbd.csi.ceph.com</code> <a class="glossary-tooltip" title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle="tooltip" data-placement="top" href="volumes/index#csi" target="_blank" aria-label="CSI">CSI</a> driver. In order to use this feature, the <a href="https://github.com/ceph/ceph-csi">Ceph CSI driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationRBD</code> <a href="../../reference/command-line-tools-reference/feature-gates/index">feature gates</a> must be enabled.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> <p>As a Kubernetes cluster operator that administers storage, here are the prerequisites that you must complete before you attempt migration to the RBD CSI driver:</p> <ul> <li>You must install the Ceph CSI driver (<code>rbd.csi.ceph.com</code>), v3.5.0 or above, into your Kubernetes cluster.</li> <li>considering the <code>clusterID</code> field is a required parameter for CSI driver for its operations, but in-tree StorageClass has <code>monitors</code> field as a required parameter, a Kubernetes storage admin has to create a clusterID based on the monitors hash ( ex:<code>#echo -n '&lt;monitors_string&gt;' | md5sum</code>) in the CSI config map and keep the monitors under this clusterID configuration.</li> <li>Also, if the value of <code>adminId</code> in the in-tree Storageclass is different from <code>admin</code>, the <code>adminSecretName</code> mentioned in the in-tree Storageclass has to be patched with the base64 value of the <code>adminId</code> parameter value, otherwise this step can be skipped.</li> </ul> </div> <h3 id="secret">secret</h3> <p>A <code>secret</code> volume is used to pass sensitive information, such as passwords, to Pods. You can store secrets in the Kubernetes API and mount them as files for use by pods without coupling to Kubernetes directly. <code>secret</code> volumes are backed by tmpfs (a RAM-backed filesystem) so they are never written to non-volatile storage.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must create a Secret in the Kubernetes API before you can use it. </div> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> A container using a Secret as a <a href="#using-subpath"><code>subPath</code></a> volume mount will not receive Secret updates. </div> <p>For more details, see <a href="../configuration/secret/index">Configuring Secrets</a>.</p> <h3 id="storageos">storageOS (deprecated)</h3> <p>A <code>storageos</code> volume allows an existing <a href="https://www.storageos.com">StorageOS</a> volume to mount into your Pod.</p> <p>StorageOS runs as a container within your Kubernetes environment, making local or attached storage accessible from any node within the Kubernetes cluster. Data can be replicated to protect against node failure. Thin provisioning and compression can improve utilization and reduce cost.</p> <p>At its core, StorageOS provides block storage to containers, accessible from a file system.</p> <p>The StorageOS Container requires 64-bit Linux and has no additional dependencies. A free developer license is available.</p> <div class="alert alert-warning caution callout" role="alert"> <strong>Caution:</strong> You must run the StorageOS container on each node that wants to access StorageOS volumes or that will contribute storage capacity to the pool. For installation instructions, consult the <a href="https://docs.storageos.com">StorageOS documentation</a>. </div> <p>The following example is a Pod configuration with StorageOS:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    name: redis
    role: master
  name: test-storageos-redis
spec:
  containers:
    - name: master
      image: kubernetes/redis:v1
      env:
        - name: MASTER
          value: "true"
      ports:
        - containerPort: 6379
      volumeMounts:
        - mountPath: /redis-master-data
          name: redis-data
  volumes:
    - name: redis-data
      storageos:
        # The `redis-vol01` volume must already exist within StorageOS in the `default` namespace.
        volumeName: redis-vol01
        fsType: ext4
</pre>
<p>For more information about StorageOS, dynamic provisioning, and PersistentVolumeClaims, see the <a href="https://github.com/kubernetes/examples/blob/master/volumes/storageos">StorageOS examples</a>.</p> <h3 id="vspherevolume">vsphereVolume</h3> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must configure the Kubernetes vSphere Cloud Provider. For cloudprovider configuration, refer to the <a href="https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/">vSphere Getting Started guide</a>. </div> <p>A <code>vsphereVolume</code> is used to mount a vSphere VMDK volume into your Pod. The contents of a volume are preserved when it is unmounted. It supports both VMFS and VSAN datastore.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> You must create vSphere VMDK volume using one of the following methods before using with a Pod. </div> <h4 id="creating-vmdk-volume">Creating a VMDK volume</h4> <p>Choose one of the following methods to create a VMDK.</p> <ul class="nav nav-tabs" id="tabs-volumes" role="tablist">
<li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#tabs-volumes-0" role="tab" aria-controls="tabs-volumes-0" aria-selected="true">Create using vmkfstools</a></li> <li class="nav-item"><a data-toggle="tab" class="nav-link" href="#tabs-volumes-1" role="tab" aria-controls="tabs-volumes-1">Create using vmware-vdiskmanager</a></li>
</ul> <div class="tab-content" id="tabs-volumes">
<div id="tabs-volumes-0" class="tab-pane show active" role="tabpanel" aria-labelledby="tabs-volumes-0"> 
<p>First ssh into ESX, then use the following command to create a VMDK:</p> <pre class="highlight" data-language="shell">vmkfstools -c 2G /vmfs/volumes/DatastoreName/volumes/myDisk.vmdk
</pre>
</div> <div id="tabs-volumes-1" class="tab-pane" role="tabpanel" aria-labelledby="tabs-volumes-1"> 
<p>Use the following command to create a VMDK:</p> <pre class="highlight" data-language="shell">vmware-vdiskmanager -c -t 0 -s 40GB -a lsilogic myDisk.vmdk
</pre>
</div>
</div> <h4 id="vsphere-vmdk-configuration">vSphere VMDK configuration example</h4> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-vmdk
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /test-vmdk
      name: test-volume
  volumes:
  - name: test-volume
    # This VMDK volume must already exist.
    vsphereVolume:
      volumePath: "[DatastoreName] volumes/myDisk"
      fsType: ext4
</pre>
<p>For more information, see the <a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere">vSphere volume</a> examples.</p> <h4 id="vsphere-csi-migration">vSphere CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code> </div> <p>The <code>CSIMigration</code> feature for <code>vsphereVolume</code>, when enabled, redirects all plugin operations from the existing in-tree plugin to the <code>csi.vsphere.vmware.com</code> <a class="glossary-tooltip" title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle="tooltip" data-placement="top" href="volumes/index#csi" target="_blank" aria-label="CSI">CSI</a> driver. In order to use this feature, the <a href="https://github.com/kubernetes-sigs/vsphere-csi-driver">vSphere CSI driver</a> must be installed on the cluster and the <code>CSIMigration</code> and <code>CSIMigrationvSphere</code> <a href="../../reference/command-line-tools-reference/feature-gates/index">feature gates</a> must be enabled.</p> <p>This also requires minimum vSphere vCenter/ESXi Version to be 7.0u1 and minimum HW Version to be VM version 15.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> <p>The following StorageClass parameters from the built-in <code>vsphereVolume</code> plugin are not supported by the vSphere CSI driver:</p> <ul> <li><code>diskformat</code></li> <li><code>hostfailurestotolerate</code></li> <li><code>forceprovisioning</code></li> <li><code>cachereservation</code></li> <li><code>diskstripes</code></li> <li><code>objectspacereservation</code></li> <li><code>iopslimit</code></li> </ul> <p>Existing volumes created using these parameters will be migrated to the vSphere CSI driver, but new volumes created by the vSphere CSI driver will not be honoring these parameters.</p> </div> <h4 id="vsphere-csi-migration-complete">vSphere CSI migration complete</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code> </div> <p>To turn off the <code>vsphereVolume</code> plugin from being loaded by the controller manager and the kubelet, you need to set <code>InTreePluginvSphereUnregister</code> feature flag to <code>true</code>. You must install a <code>csi.vsphere.vmware.com</code> <a class="glossary-tooltip" title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle="tooltip" data-placement="top" href="volumes/index#csi" target="_blank" aria-label="CSI">CSI</a> driver on all worker nodes.</p> <h4 id="portworx-csi-migration">Portworx CSI migration</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code> </div> <p>The <code>CSIMigration</code> feature for Portworx has been added but disabled by default in Kubernetes 1.23 since it's in alpha state. It redirects all plugin operations from the existing in-tree plugin to the <code>pxd.portworx.com</code> Container Storage Interface (CSI) Driver. <a href="https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/csi/">Portworx CSI Driver</a> must be installed on the cluster. To enable the feature, set <code>CSIMigrationPortworx=true</code> in kube-controller-manager and kubelet.</p> <h2 id="using-subpath">Using subPath</h2> <p>Sometimes, it is useful to share one volume for multiple uses in a single pod. The <code>volumeMounts.subPath</code> property specifies a sub-path inside the referenced volume instead of its root.</p> <p>The following example shows how to configure a Pod with a LAMP stack (Linux Apache MySQL PHP) using a single, shared volume. This sample <code>subPath</code> configuration is not recommended for production use.</p> <p>The PHP application's code and assets map to the volume's <code>html</code> folder and the MySQL database is stored in the volume's <code>mysql</code> folder. For example:</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: my-lamp-site
spec:
    containers:
    - name: mysql
      image: mysql
      env:
      - name: MYSQL_ROOT_PASSWORD
        value: "rootpasswd"
      volumeMounts:
      - mountPath: /var/lib/mysql
        name: site-data
        subPath: mysql
    - name: php
      image: php:7.0-apache
      volumeMounts:
      - mountPath: /var/www/html
        name: site-data
        subPath: html
    volumes:
    - name: site-data
      persistentVolumeClaim:
        claimName: my-lamp-site-data
</pre>
<h3 id="using-subpath-expanded-environment">Using subPath with expanded environment variables</h3> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.17 [stable]</code> </div> <p>Use the <code>subPathExpr</code> field to construct <code>subPath</code> directory names from downward API environment variables. The <code>subPath</code> and <code>subPathExpr</code> properties are mutually exclusive.</p> <p>In this example, a <code>Pod</code> uses <code>subPathExpr</code> to create a directory <code>pod1</code> within the <code>hostPath</code> volume <code>/var/log/pods</code>. The <code>hostPath</code> volume takes the <code>Pod</code> name from the <code>downwardAPI</code>. The host directory <code>/var/log/pods/pod1</code> is mounted at <code>/logs</code> in the container.</p> <pre class="highlight" data-language="yaml">apiVersion: v1
kind: Pod
metadata:
  name: pod1
spec:
  containers:
  - name: container1
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    image: busybox
    command: [ "sh", "-c", "while [ true ]; do echo 'Hello'; sleep 10; done | tee -a /logs/hello.txt" ]
    volumeMounts:
    - name: workdir1
      mountPath: /logs
      subPathExpr: $(POD_NAME)
  restartPolicy: Never
  volumes:
  - name: workdir1
    hostPath:
      path: /var/log/pods
</pre>
<h2 id="resources">Resources</h2> <p>The storage media (such as Disk or SSD) of an <code>emptyDir</code> volume is determined by the medium of the filesystem holding the kubelet root dir (typically <code>/var/lib/kubelet</code>). There is no limit on how much space an <code>emptyDir</code> or <code>hostPath</code> volume can consume, and no isolation between containers or between pods.</p> <p>To learn about requesting space using a resource specification, see <a href="../configuration/manage-resources-containers/index">how to manage resources</a>.</p> <h2 id="out-of-tree-volume-plugins">Out-of-tree volume plugins</h2> <p>The out-of-tree volume plugins include <a class="glossary-tooltip" title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle="tooltip" data-placement="top" href="volumes/index#csi" target="_blank" aria-label="Container Storage Interface">Container Storage Interface</a> (CSI), and also FlexVolume (which is deprecated). These plugins enable storage vendors to create custom storage plugins without adding their plugin source code to the Kubernetes repository.</p> <p>Previously, all volume plugins were "in-tree". The "in-tree" plugins were built, linked, compiled, and shipped with the core Kubernetes binaries. This meant that adding a new storage system to Kubernetes (a volume plugin) required checking code into the core Kubernetes code repository.</p> <p>Both CSI and FlexVolume allow volume plugins to be developed independent of the Kubernetes code base, and deployed (installed) on Kubernetes clusters as extensions.</p> <p>For storage vendors looking to create an out-of-tree volume plugin, please refer to the <a href="https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md">volume plugin FAQ</a>.</p> <h3 id="csi">csi</h3> <p><a href="https://github.com/container-storage-interface/spec/blob/master/spec.md">Container Storage Interface</a> (CSI) defines a standard interface for container orchestration systems (like Kubernetes) to expose arbitrary storage systems to their container workloads.</p> <p>Please read the <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md">CSI design proposal</a> for more information.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> Support for CSI spec versions 0.2 and 0.3 are deprecated in Kubernetes v1.13 and will be removed in a future release. </div> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> CSI drivers may not be compatible across all Kubernetes releases. Please check the specific CSI driver's documentation for supported deployments steps for each Kubernetes release and a compatibility matrix. </div> <p>Once a CSI compatible volume driver is deployed on a Kubernetes cluster, users may use the <code>csi</code> volume type to attach or mount the volumes exposed by the CSI driver.</p> <p>A <code>csi</code> volume can be used in a Pod in three different ways:</p> <ul> <li>through a reference to a <a href="#persistentvolumeclaim">PersistentVolumeClaim</a>
</li> <li>with a <a href="ephemeral-volumes/index#generic-ephemeral-volume">generic ephemeral volume</a> (alpha feature)</li> <li>with a <a href="ephemeral-volumes/index#csi-ephemeral-volume">CSI ephemeral volume</a> if the driver supports that (beta feature)</li> </ul> <p>The following fields are available to storage administrators to configure a CSI persistent volume:</p> <ul> <li>
<code>driver</code>: A string value that specifies the name of the volume driver to use. This value must correspond to the value returned in the <code>GetPluginInfoResponse</code> by the CSI driver as defined in the <a href="https://github.com/container-storage-interface/spec/blob/master/spec.md#getplugininfo">CSI spec</a>. It is used by Kubernetes to identify which CSI driver to call out to, and by CSI driver components to identify which PV objects belong to the CSI driver.</li> <li>
<code>volumeHandle</code>: A string value that uniquely identifies the volume. This value must correspond to the value returned in the <code>volume.id</code> field of the <code>CreateVolumeResponse</code> by the CSI driver as defined in the <a href="https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume">CSI spec</a>. The value is passed as <code>volume_id</code> on all calls to the CSI volume driver when referencing the volume.</li> <li>
<code>readOnly</code>: An optional boolean value indicating whether the volume is to be "ControllerPublished" (attached) as read only. Default is false. This value is passed to the CSI driver via the <code>readonly</code> field in the <code>ControllerPublishVolumeRequest</code>.</li> <li>
<code>fsType</code>: If the PV's <code>VolumeMode</code> is <code>Filesystem</code> then this field may be used to specify the filesystem that should be used to mount the volume. If the volume has not been formatted and formatting is supported, this value will be used to format the volume. This value is passed to the CSI driver via the <code>VolumeCapability</code> field of <code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, and <code>NodePublishVolumeRequest</code>.</li> <li>
<code>volumeAttributes</code>: A map of string to string that specifies static properties of a volume. This map must correspond to the map returned in the <code>volume.attributes</code> field of the <code>CreateVolumeResponse</code> by the CSI driver as defined in the <a href="https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume">CSI spec</a>. The map is passed to the CSI driver via the <code>volume_context</code> field in the <code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, and <code>NodePublishVolumeRequest</code>.</li> <li>
<code>controllerPublishSecretRef</code>: A reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI <code>ControllerPublishVolume</code> and <code>ControllerUnpublishVolume</code> calls. This field is optional, and may be empty if no secret is required. If the Secret contains more than one secret, all secrets are passed.</li> <li>
<code>nodeStageSecretRef</code>: A reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI <code>NodeStageVolume</code> call. This field is optional, and may be empty if no secret is required. If the Secret contains more than one secret, all secrets are passed.</li> <li>
<code>nodePublishSecretRef</code>: A reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI <code>NodePublishVolume</code> call. This field is optional, and may be empty if no secret is required. If the secret object contains more than one secret, all secrets are passed.</li> </ul> <h4 id="csi-raw-block-volume-support">CSI raw block volume support</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code> </div> <p>Vendors with external CSI drivers can implement raw block volume support in Kubernetes workloads.</p> <p>You can set up your <a href="persistent-volumes/index#raw-block-volume-support">PersistentVolume/PersistentVolumeClaim with raw block volume support</a> as usual, without any CSI specific changes.</p> <h4 id="csi-ephemeral-volumes">CSI ephemeral volumes</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.16 [beta]</code> </div> <p>You can directly configure CSI volumes within the Pod specification. Volumes specified in this way are ephemeral and do not persist across pod restarts. See <a href="ephemeral-volumes/index#csi-ephemeral-volume">Ephemeral Volumes</a> for more information.</p> <p>For more information on how to develop a CSI driver, refer to the <a href="https://kubernetes-csi.github.io/docs/">kubernetes-csi documentation</a></p> <h4 id="migrating-to-csi-drivers-from-in-tree-plugins">Migrating to CSI drivers from in-tree plugins</h4> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code> </div> <p>The <code>CSIMigration</code> feature, when enabled, directs operations against existing in-tree plugins to corresponding CSI plugins (which are expected to be installed and configured). As a result, operators do not have to make any configuration changes to existing Storage Classes, PersistentVolumes or PersistentVolumeClaims (referring to in-tree plugins) when transitioning to a CSI driver that supersedes an in-tree plugin.</p> <p>The operations and features that are supported include: provisioning/delete, attach/detach, mount/unmount and resizing of volumes.</p> <p>In-tree plugins that support <code>CSIMigration</code> and have a corresponding CSI driver implemented are listed in <a href="#volume-types">Types of Volumes</a>.</p> <h3 id="flexvolume">flexVolume</h3> <div style="margin-top: 10px; margin-bottom: 10px;"> <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [deprecated]</code> </div> <p>FlexVolume is an out-of-tree plugin interface that uses an exec-based model to interface with storage drivers. The FlexVolume driver binaries must be installed in a pre-defined volume plugin path on each node and in some cases the control plane nodes as well.</p> <p>Pods interact with FlexVolume drivers through the <code>flexVolume</code> in-tree volume plugin. For more details, see the FlexVolume <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md#readme">README</a> document.</p> <div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> <p>FlexVolume is deprecated. Using an out-of-tree CSI driver is the recommended way to integrate external storage with Kubernetes.</p> <p>Maintainers of FlexVolume driver should implement a CSI Driver and help to migrate users of FlexVolume drivers to CSI. Users of FlexVolume should move their workloads to use the equivalent CSI Driver.</p> </div> <h2 id="mount-propagation">Mount propagation</h2> <p>Mount propagation allows for sharing volumes mounted by a container to other containers in the same pod, or even to other pods on the same node.</p> <p>Mount propagation of a volume is controlled by the <code>mountPropagation</code> field in <code>Container.volumeMounts</code>. Its values are:</p> <ul> <li> <p><code>None</code> - This volume mount will not receive any subsequent mounts that are mounted to this volume or any of its subdirectories by the host. In similar fashion, no mounts created by the container will be visible on the host. This is the default mode.</p> <p>This mode is equal to <code>private</code> mount propagation as described in the <a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt">Linux kernel documentation</a></p> </li> <li> <p><code>HostToContainer</code> - This volume mount will receive all subsequent mounts that are mounted to this volume or any of its subdirectories.</p> <p>In other words, if the host mounts anything inside the volume mount, the container will see it mounted there.</p> <p>Similarly, if any Pod with <code>Bidirectional</code> mount propagation to the same volume mounts anything there, the container with <code>HostToContainer</code> mount propagation will see it.</p> <p>This mode is equal to <code>rslave</code> mount propagation as described in the <a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt">Linux kernel documentation</a></p> </li> <li> <p><code>Bidirectional</code> - This volume mount behaves the same the <code>HostToContainer</code> mount. In addition, all volume mounts created by the container will be propagated back to the host and to all containers of all pods that use the same volume.</p> <p>A typical use case for this mode is a Pod with a FlexVolume or CSI driver or a Pod that needs to mount something on the host using a <code>hostPath</code> volume.</p> <p>This mode is equal to <code>rshared</code> mount propagation as described in the <a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt">Linux kernel documentation</a></p> <div class="alert alert-danger warning callout" role="alert"> <strong>Warning:</strong> <code>Bidirectional</code> mount propagation can be dangerous. It can damage the host operating system and therefore it is allowed only in privileged containers. Familiarity with Linux kernel behavior is strongly recommended. In addition, any volume mounts created by containers in pods must be destroyed (unmounted) by the containers on termination. </div> </li> </ul> <h3 id="configuration">Configuration</h3> <p>Before mount propagation can work properly on some deployments (CoreOS, RedHat/Centos, Ubuntu) mount share must be configured correctly in Docker as shown below.</p> <p>Edit your Docker's <code>systemd</code> service file. Set <code>MountFlags</code> as follows:</p> <pre class="highlight" data-language="shell">MountFlags=shared
</pre>
<p>Or, remove <code>MountFlags=slave</code> if present. Then restart the Docker daemon:</p> <pre class="highlight" data-language="shell">sudo systemctl daemon-reload
sudo systemctl restart docker
</pre>
<h2 id="what-s-next">What's next</h2> <p>Follow an example of <a href="../../tutorials/stateful-application/mysql-wordpress-persistent-volume/index">deploying WordPress and MySQL with Persistent Volumes</a>.</p>
<div class="_attribution">
  <p class="_attribution-p">
    © 2022 The Kubernetes Authors<br>Documentation Distributed under CC BY 4.0.<br>
    <a href="https://kubernetes.io/docs/concepts/storage/volumes" class="_attribution-link">https://kubernetes.io/docs/concepts/storage/volumes</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
