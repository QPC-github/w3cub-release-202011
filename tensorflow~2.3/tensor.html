
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.Tensor - TensorFlow 2.3 - W3cubDocs</title>
  
  <meta name="description" content=" ">
  <meta name="keywords" content="tf, tensor, tensorflow, tensorflow~2.3">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.3/tensor.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.3.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.3/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.3</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.Tensor</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L258-L958">  View source on GitHub </a> </td> </table> <p>A tensor is a multidimensional array of elements represented by a</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="0">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code translate="no" dir="ltr">tf.compat.v1.Tensor</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.Tensor(
    op, value_index, dtype
)
</pre>  <p><a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> object. All elements are of a single known data type.</p> <p>When writing a TensorFlow program, the main object that is manipulated and passed around is the <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a>.</p> <p>A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> has the following properties:</p> <ul> <li>a single data type (float32, int32, or string, for example)</li> <li>a shape</li> </ul> <p>TensorFlow supports eager execution and graph execution. In eager execution, operations are evaluated immediately. In graph execution, a computational graph is constructed for later evaluation.</p> <p>TensorFlow defaults to eager execution. In the example below, the matrix multiplication results are calculated immediately.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# Compute some values using a Tensor
c = tf.constant([[1.0, 2.0], [3.0, 4.0]])
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
e = tf.matmul(c, d)
print(e)
tf.Tensor(
[[1. 3.]
 [3. 7.]], shape=(2, 2), dtype=float32)
</pre> <p>Note that during eager execution, you may discover your <code translate="no" dir="ltr">Tensors</code> are actually of type <code translate="no" dir="ltr">EagerTensor</code>. This is an internal detail, but it does give you access to a useful function, <code translate="no" dir="ltr">numpy</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
type(e)
&lt;class '...ops.EagerTensor'&gt;
print(e.numpy())
  [[1. 3.]
   [3. 7.]]
</pre> <p>In TensorFlow, <a href="function"><code translate="no" dir="ltr">tf.function</code></a>s are a common way to define graph execution.</p> <p>A Tensor's shape (that is, the rank of the Tensor and the size of each dimension) may not always be fully known. In <a href="function"><code translate="no" dir="ltr">tf.function</code></a> definitions, the shape may only be partially known.</p> <p>Most operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it's only possible to find the shape of a tensor at execution time.</p> <p>A number of specialized tensors are available: see <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a>, <a href="constant"><code translate="no" dir="ltr">tf.constant</code></a>, <code translate="no" dir="ltr">tf.placeholder</code>, <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a>, and <a href="raggedtensor"><code translate="no" dir="ltr">tf.RaggedTensor</code></a>.</p> <p>For more on Tensors, see the <a href="https://tensorflow.org/guide/tensor">guide</a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> An <code translate="no" dir="ltr">Operation</code>. <code translate="no" dir="ltr">Operation</code> that computes this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> An <code translate="no" dir="ltr">int</code>. Index of the operation's endpoint that produces this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> A <code translate="no" dir="ltr">DType</code>. Type of elements stored in this tensor. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the op is not an <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">device</code> </td> <td> The name of the device on which this tensor will be produced, or None. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The <code translate="no" dir="ltr">DType</code> of elements in this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">graph</code> </td> <td> The <code translate="no" dir="ltr">Graph</code> that contains this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> The string name of this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> The <code translate="no" dir="ltr">Operation</code> that produces this tensor as an output. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> Returns a <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> that represents the shape of this tensor. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.constant([1,2,3,4,5])
t.shape
TensorShape([5])
</pre> <p><a href="tensor#shape"><code translate="no" dir="ltr">tf.Tensor.shape</code></a> is equivalent to <a href="tensor#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a>.</p> <p>In a <a href="function"><code translate="no" dir="ltr">tf.function</code></a> or when building a model using <a href="keras/input"><code translate="no" dir="ltr">tf.keras.Input</code></a>, they return the build-time shape of the tensor, which may be partially unknown.</p> <p>A <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> is not a tensor. Use <a href="shape"><code translate="no" dir="ltr">tf.shape(t)</code></a> to get a tensor containing the shape, calculated at runtime.</p> <p>See <a href="tensor#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a>, and <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> for details and examples. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> The index of this tensor in the outputs of its <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="0">Methods</h2> <h3 id="consumers" data-text="consumers" tabindex="0"><code translate="no" dir="ltr">consumers</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L762-L774">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
consumers()
</pre> <p>Returns a list of <code translate="no" dir="ltr">Operation</code>s that consume this tensor.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of <code translate="no" dir="ltr">Operation</code>s. </td> </tr> 
</table> <h3 id="eval" data-text="eval" tabindex="0"><code translate="no" dir="ltr">eval</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L889-L913">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
eval(
    feed_dict=None, session=None
)
</pre> <p>Evaluates this tensor in a <code translate="no" dir="ltr">Session</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> If you are not using <a href="compat/v1"><code translate="no" dir="ltr">compat.v1</code></a> libraries, you should not need this, (or <code translate="no" dir="ltr">feed_dict</code> or <code translate="no" dir="ltr">Session</code>). In eager execution (or within <a href="function"><code translate="no" dir="ltr">tf.function</code></a>) you do not need to call <code translate="no" dir="ltr">eval</code>.</span>
</blockquote> <p>Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.</p> <blockquote class="note">
<strong>Note:</strong><span> Before invoking <a href="tensor#eval"><code translate="no" dir="ltr">Tensor.eval()</code></a>, its graph must have been launched in a session, and either a default session must be available, or <code translate="no" dir="ltr">session</code> must be specified explicitly.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">feed_dict</code> </td> <td> A dictionary that maps <code translate="no" dir="ltr">Tensor</code> objects to feed values. See <code translate="no" dir="ltr">tf.Session.run</code> for a description of the valid feed values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">session</code> </td> <td> (Optional.) The <code translate="no" dir="ltr">Session</code> to be used to evaluate this tensor. If none, the default session will be used. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A numpy array corresponding to the value of this tensor. </td> </tr> 
</table> <h3 id="experimental_ref" data-text="experimental_ref" tabindex="0"><code translate="no" dir="ltr">experimental_ref</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L915-L917">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
experimental_ref()
</pre> <p>DEPRECATED FUNCTION</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use ref() instead.</span></aside> <h3 id="get_shape" data-text="get_shape" tabindex="0"><code translate="no" dir="ltr">get_shape</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L535-L614">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_shape()
</pre> <p>Returns a <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> that represents the shape of this tensor.</p> <p>In eager execution the shape is always fully-known.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
print(a.shape)
(2, 3)
</pre> <p><a href="tensor#get_shape"><code translate="no" dir="ltr">tf.Tensor.get_shape()</code></a> is equivalent to <a href="tensor#shape"><code translate="no" dir="ltr">tf.Tensor.shape</code></a>.</p> <p>When executing in a <a href="function"><code translate="no" dir="ltr">tf.function</code></a> or building a model using <a href="keras/input"><code translate="no" dir="ltr">tf.keras.Input</code></a>, <a href="tensor#shape"><code translate="no" dir="ltr">Tensor.shape</code></a> may return a partial shape (including <code translate="no" dir="ltr">None</code> for unknown dimensions). See <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> for more details.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
inputs = tf.keras.Input(shape = [10])
# Unknown batch size
print(inputs.shape)
(None, 10)
</pre> <p>The shape is computed using shape inference functions that are registered for each <a href="operation"><code translate="no" dir="ltr">tf.Operation</code></a>.</p> <p>The returned <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> is determined at <em>build</em> time, without executing the underlying kernel. It is not a <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a>. If you need a shape <em>tensor</em>, either convert the <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> to a <a href="constant"><code translate="no" dir="ltr">tf.constant</code></a>, or use the <a href="shape"><code translate="no" dir="ltr">tf.shape(tensor)</code></a> function, which returns the tensor's shape at <em>execution</em> time.</p> <p>This is useful for debugging and providing early errors. For example, when tracing a <a href="function"><code translate="no" dir="ltr">tf.function</code></a>, no ops are being executed, shapes may be unknown (See the <a href="https://www.tensorflow.org/guide/concrete_function">Concrete Functions Guide</a> for details).</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_matmul(a, b):
  result = a@b
  # the `print` executes during tracing.
  print("Result shape: ", result.shape)
  return result
</pre> <p>The shape inference functions propagate shapes to the extent possible:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
f = my_matmul.get_concrete_function(
  tf.TensorSpec([None,3]),
  tf.TensorSpec([3,5]))
Result shape: (None, 5)
</pre> <p>Tracing may fail if a shape missmatch can be detected:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = my_matmul.get_concrete_function(
  tf.TensorSpec([None,3]),
  tf.TensorSpec([4,5]))
Traceback (most recent call last):

ValueError: Dimensions must be equal, but are 3 and 4 for 'matmul' (op:
'MatMul') with input shapes: [?,3], [4,5].
</pre> <p>In some cases, the inferred shape may have unknown dimensions. If the caller has additional information about the values of these dimensions, <a href="tensor#set_shape"><code translate="no" dir="ltr">Tensor.set_shape()</code></a> can be used to augment the inferred shape.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_fun(a):
  a.set_shape([5, 5])
  # the `print` executes during tracing.
  print("Result shape: ", a.shape)
  return a
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = my_fun.get_concrete_function(
  tf.TensorSpec([None, None]))
Result shape: (5, 5)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> representing the shape of this tensor. </td> </tr> 
</table> <h3 id="ref" data-text="ref" tabindex="0"><code translate="no" dir="ltr">ref</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L919-L958">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
ref()
</pre> <p>Returns a hashable reference object to this Tensor.</p> <p>The primary use case for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as <code translate="no" dir="ltr">tensor.__hash__()</code> is no longer available starting Tensorflow 2.0.</p> <p>The following will raise an exception starting 2.0</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(5)
y = tf.constant(10)
z = tf.constant(10)
tensor_set = {x, y, z}
Traceback (most recent call last):

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
tensor_dict = {x: 'five', y: 'ten'}
Traceback (most recent call last):

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
</pre> <p>Instead, we can use <code translate="no" dir="ltr">tensor.ref()</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tensor_set = {x.ref(), y.ref(), z.ref()}
x.ref() in tensor_set
True
tensor_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}
tensor_dict[y.ref()]
'ten'
</pre> <p>Also, the reference object provides <code translate="no" dir="ltr">.deref()</code> function that returns the original Tensor.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant(5)
x.ref().deref()
&lt;tf.Tensor: shape=(), dtype=int32, numpy=5&gt;
</pre> <h3 id="set_shape" data-text="set_shape" tabindex="0"><code translate="no" dir="ltr">set_shape</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L616-L755">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_shape(
    shape
)
</pre> <p>Updates the shape of this tensor.</p> <p>With eager execution this operates as a shape assertion. Here the shapes match:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.constant([[1,2,3]])
t.set_shape([1, 3])
</pre> <p>Passing a <code translate="no" dir="ltr">None</code> in the new shape allows any value for that axis:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([1,None])
</pre> <p>An error is raised if an incompatible shape is passed.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([1,5])
Traceback (most recent call last):

ValueError: Tensor's shape (1, 3) is not compatible with supplied
shape [1, 5]
</pre> <p>When executing in a <a href="function"><code translate="no" dir="ltr">tf.function</code></a>, or building a model using <a href="keras/input"><code translate="no" dir="ltr">tf.keras.Input</code></a>, <a href="tensor#set_shape"><code translate="no" dir="ltr">Tensor.set_shape</code></a> will <em>merge</em> the given <code translate="no" dir="ltr">shape</code> with the current shape of this tensor, and set the tensor's shape to the merged value (see <a href="tensorshape#merge_with"><code translate="no" dir="ltr">tf.TensorShape.merge_with</code></a> for details):</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.keras.Input(shape=[None, None, 3])
print(t.shape)
(None, None, None, 3)
</pre> <p>Dimensions set to <code translate="no" dir="ltr">None</code> are not updated:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t.set_shape([None, 224, 224, None])
print(t.shape)
(None, 224, 224, 3)
</pre> <p>The main use case for this is to provide additional shape information that cannot be inferred from the graph alone.</p> <p>For example if you know all the images in a dataset have shape [28,28,3] you can set it with <code translate="no" dir="ltr">tf.set_shape</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def load_image(filename):
  raw = tf.io.read_file(filename)
  image = tf.image.decode_png(raw, channels=3)
  # the `print` executes during tracing.
  print("Initial shape: ", image.shape)
  image.set_shape([28, 28, 3])
  print("Final shape: ", image.shape)
  return image
</pre> <p>Trace the function, see the <a href="https://www.tensorflow.org/guide/concrete_function">Concrete Functions Guide</a> for details.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
cf = load_image.get_concrete_function(
    tf.TensorSpec([], dtype=tf.string))
Initial shape:  (None, None, 3)
Final shape: (28, 28, 3)
</pre> <p>Similarly the <a href="io/parse_tensor"><code translate="no" dir="ltr">tf.io.parse_tensor</code></a> function could return a tensor with any shape, even the <a href="rank"><code translate="no" dir="ltr">tf.rank</code></a> is unknown. If you know that all your serialized tensors will be 2d, set it with <code translate="no" dir="ltr">set_shape</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def my_parse(string_tensor):
  result = tf.io.parse_tensor(string_tensor, out_type=tf.float32)
  # the `print` executes during tracing.
  print("Initial shape: ", result.shape)
  result.set_shape([None, None])
  print("Final shape: ", result.shape)
  return result
</pre> <p>Trace the function</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
concrete_parse = my_parse.get_concrete_function(
    tf.TensorSpec([], dtype=tf.string))
Initial shape:  &lt;unknown&gt;
Final shape:  (None, None)
</pre> <h4 id="make_sure_it_works" data-text="Make sure it works:" tabindex="0">Make sure it works:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
t = tf.ones([5,3], dtype=tf.float32)
serialized = tf.io.serialize_tensor(t)
print(serialized.dtype)
&lt;dtype: 'string'&gt;
print(serialized.shape)
()
t2 = concrete_parse(serialized)
print(t2.shape)
(5, 3)
</pre> <aside class="caution"><strong>Caution:</strong><span> <code translate="no" dir="ltr">set_shape</code> ensures that the applied shape is compatible with the existing shape, but it does not check at runtime. Setting incorrect shapes can result in inconsistencies between the statically-known graph and the runtime value of tensors. For runtime validation of the shape, use <a href="ensure_shape"><code translate="no" dir="ltr">tf.ensure_shape</code></a> instead. It also modifies the <code translate="no" dir="ltr">shape</code> of the tensor.</span></aside> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# Serialize a rank-3 tensor
t = tf.ones([5,5,5], dtype=tf.float32)
serialized = tf.io.serialize_tensor(t)
# The function still runs, even though it `set_shape([None,None])`
t2 = concrete_parse(serialized)
print(t2.shape)
(5, 5, 5)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> A <code translate="no" dir="ltr">TensorShape</code> representing the shape of this tensor, a <code translate="no" dir="ltr">TensorShapeProto</code>, a list, a tuple, or None. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">shape</code> is not compatible with the current shape of this tensor. </td> </tr> </table> <h3 id="__abs__" data-text="__abs__" tabindex="0"><code translate="no" dir="ltr">__abs__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L358-L392">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__abs__(
    x, name=None
)
</pre> <p>Computes the absolute value of a tensor.</p> <p>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> of complex numbers, this operation returns a tensor of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code> that is the absolute value of each element in <code translate="no" dir="ltr">x</code>. For a complex number \(a + bj\), its absolute value is computed as \(\sqrt{a^2</p> <ul> <li>b^2}\). For example:</li> </ul> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)
&lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy=
array([[5.25594901],
       [6.60492241]])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of the same size, type and sparsity as <code translate="no" dir="ltr">x</code>, with absolute values. Note, for <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code> input, the returned <code translate="no" dir="ltr">Tensor</code> will be of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code>, respectively. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__add__" data-text="__add__" tabindex="0"><code translate="no" dir="ltr">__add__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__add__(
    x, y
)
</pre> <p>The operation invoked by the <a href="tensor#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> operator.</p> <p>Purpose in the API:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">This method is exposed in TensorFlow's API so that library developers
can register dispatching for &lt;a href="../tf/Tensor#__add__"&gt;&lt;code&gt;Tensor.__add__&lt;/code&gt;&lt;/a&gt; to allow it to handle
custom composite tensors &amp; other custom objects.

The API symbol is not intended to be called by users directly and does
appear in TensorFlow's generated documentation.
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> an optional name for the operation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">+</code> operation. </td> </tr> 
</table> <h3 id="__and__" data-text="__and__" tabindex="0"><code translate="no" dir="ltr">__and__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__and__(
    x, y
)
</pre> <p>Logical AND function.</p> <p>The operation works for the following input types:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</li> </ul> <h4 id="usage" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_and(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_and(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_and(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False,  True])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h3 id="__bool__" data-text="__bool__" tabindex="0"><code translate="no" dir="ltr">__bool__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L859-L877">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__bool__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This overload raises a <code translate="no" dir="ltr">TypeError</code> when the user inadvertently treats a <code translate="no" dir="ltr">Tensor</code> as a boolean (most commonly in an <code translate="no" dir="ltr">if</code> or <code translate="no" dir="ltr">while</code> statement), in code that was not converted by AutoGraph. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">if tf.constant(True):  # Will raise.
  # ...

if tf.constant(5) &lt; tf.constant(7):  # Will raise.
  # ...
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__div__" data-text="__div__" tabindex="0"><code translate="no" dir="ltr">__div__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__div__(
    x, y
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside><blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.</span>
</blockquote> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <h3 id="__eq__" data-text="__eq__" tabindex="0"><code translate="no" dir="ltr">__eq__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1653-L1688">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__eq__(
    other
)
</pre> <p>The operation invoked by the <a href="tensor#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> operator.</p> <p>Compares two tensors element-wise for equality if they are broadcast-compatible; or returns False if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/equal"><code translate="no" dir="ltr">tf.math.equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api" data-text="Purpose in the API:" tabindex="0">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor#__eq__"><code translate="no" dir="ltr">Tensor.<strong>eq</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">==</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">==</code> operation, or <code translate="no" dir="ltr">False</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__floordiv__" data-text="__floordiv__" tabindex="0"><code translate="no" dir="ltr">__floordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__floordiv__(
    x, y
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="raggedtensor#__div__"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded down. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__ge__" data-text="__ge__" tabindex="0"><code translate="no" dir="ltr">__ge__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ge__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &gt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater_equal"><code translate="no" dir="ltr">math.greater_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6, 7])
y = tf.constant([5, 2, 5, 10])
tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]

x = tf.constant([5, 4, 6, 7])
y = tf.constant([5])
tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__getitem__" data-text="__getitem__" tabindex="0"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/array_ops.py#L872-L1024">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__getitem__(
    tensor, slice_spec, var=None
)
</pre> <p>Overload for Tensor.<strong>getitem</strong>.</p> <p>This operation extracts the specified region from the tensor. The notation is similar to NumPy with the restriction that currently only support basic indexing. That means that using a non-scalar tensor as input is not currently allowed.</p> <h4 id="some_useful_examples" data-text="Some useful examples:" tabindex="0">Some useful examples:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Strip leading and trailing 2 elements
foo = tf.constant([1,2,3,4,5,6])
print(foo[2:-2].eval())  # =&gt; [3,4]

# Skip every other row and reverse the order of the columns
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[::2,::-1].eval())  # =&gt; [[3,2,1], [9,8,7]]

# Use scalar tensors as indices on both dimensions
print(foo[tf.constant(0), tf.constant(2)].eval())  # =&gt; 3

# Insert another dimension
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval()) # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[:, tf.newaxis, :].eval()) # =&gt; [[[1,2,3]], [[4,5,6]], [[7,8,9]]]
print(foo[:, :, tf.newaxis].eval()) # =&gt; [[[1],[2],[3]], [[4],[5],[6]],
[[7],[8],[9]]]

# Ellipses (3 equivalent operations)
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis, ...].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]

# Masks
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[foo &gt; 2].eval())  # =&gt; [3, 4, 5, 6, 7, 8, 9]
</pre> <h4 id="notes" data-text="Notes:" tabindex="0">Notes:</h4> <ul> <li>
<a href="../tf#newaxis"><code translate="no" dir="ltr">tf.newaxis</code></a> is <code translate="no" dir="ltr">None</code> as in NumPy.</li> <li>An implicit ellipsis is placed at the end of the <code translate="no" dir="ltr">slice_spec</code>
</li> <li>NumPy advanced indexing is currently not supported.</li> </ul> <h4 id="purpose_in_the_api_2" data-text="Purpose in the API:" tabindex="0">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor#__getitem__"><code translate="no" dir="ltr">Tensor.<strong>getitem</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor</code> </td> <td> An ops.Tensor object. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">slice_spec</code> </td> <td> The arguments to Tensor.<strong>getitem</strong>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">var</code> </td> <td> In the case of variable slice assignment, the Variable object to slice (i.e. tensor is the read-only view of this variable). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The appropriate slice of "tensor", based on "slice_spec". </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If a slice range is negative size. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the slice indices aren't int, slice, ellipsis, tf.newaxis or scalar int32/int64 tensors. </td> </tr> </table> <h3 id="__gt__" data-text="__gt__" tabindex="0"><code translate="no" dir="ltr">__gt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__gt__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &gt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater"><code translate="no" dir="ltr">math.greater</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_2" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5, 2, 5])
tf.math.greater(x, y) ==&gt; [False, True, True]

x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.greater(x, y) ==&gt; [False, False, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__invert__" data-text="__invert__" tabindex="0"><code translate="no" dir="ltr">__invert__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__invert__(
    x, name=None
)
</pre> <p>Returns the truth value of <code translate="no" dir="ltr">NOT x</code> element-wise.</p> <h4 id="example_3" data-text="Example:" tabindex="0">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
tf.math.logical_not(tf.constant([True, False]))
&lt;tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__iter__" data-text="__iter__" tabindex="0"><code translate="no" dir="ltr">__iter__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L501-L513">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__iter__()
</pre> <h3 id="__le__" data-text="__le__" tabindex="0"><code translate="no" dir="ltr">__le__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__le__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &lt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less_equal"><code translate="no" dir="ltr">math.less_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_4" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less_equal(x, y) ==&gt; [True, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 6])
tf.math.less_equal(x, y) ==&gt; [True, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__len__" data-text="__len__" tabindex="0"><code translate="no" dir="ltr">__len__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L850-L853">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__len__()
</pre> <h3 id="__lt__" data-text="__lt__" tabindex="0"><code translate="no" dir="ltr">__lt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__lt__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &lt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less"><code translate="no" dir="ltr">math.less</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote> <h4 id="example_5" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less(x, y) ==&gt; [False, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 7])
tf.math.less(x, y) ==&gt; [False, True, True]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__matmul__" data-text="__matmul__" tabindex="0"><code translate="no" dir="ltr">__matmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__matmul__(
    x, y
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])
a  # 2-D tensor
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])
b  # 2-D tensor
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[ 7,  8],
       [ 9, 10],
       [11, 12]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=
array([[ 58,  64],
       [139, 154]], dtype=int32)&gt;
</pre> <p>A batch matrix multiplication with batch shape [2]:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])
a  # 3-D tensor
&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]], dtype=int32)&gt;
b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])
b  # 3-D tensor
&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[13, 14],
        [15, 16],
        [17, 18]],
       [[19, 20],
        [21, 22],
        [23, 24]]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 94, 100],
        [229, 244]],
       [[508, 532],
        [697, 730]]], dtype=int32)&gt;
</pre> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="linalg/matmul"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = a @ b @ [[10], [11]]
d = tf.matmul(tf.matmul(a, b), [[10], [11]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>. </td> </tr> </table> <h3 id="__mod__" data-text="__mod__" tabindex="0"><code translate="no" dir="ltr">__mod__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mod__(
    x, y
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__mul__" data-text="__mul__" tabindex="0"><code translate="no" dir="ltr">__mul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mul__(
    x, y
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ne__" data-text="__ne__" tabindex="0"><code translate="no" dir="ltr">__ne__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1691-L1724">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ne__(
    other
)
</pre> <p>The operation invoked by the <a href="tensor#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> operator.</p> <p>Compares two tensors element-wise for inequality if they are broadcast-compatible; or returns True if they are not broadcast-compatible. (Note that this behavior differs from <a href="math/not_equal"><code translate="no" dir="ltr">tf.math.not_equal</code></a>, which raises an exception if the two tensors are not broadcast-compatible.)</p> <h4 id="purpose_in_the_api_3" data-text="Purpose in the API:" tabindex="0">Purpose in the API:</h4> <p>This method is exposed in TensorFlow's API so that library developers can register dispatching for <a href="tensor#__ne__"><code translate="no" dir="ltr">Tensor.<strong>ne</strong></code></a> to allow it to handle custom composite tensors &amp; other custom objects.</p> <p>The API symbol is not intended to be called by users directly and does appear in TensorFlow's generated documentation.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">self</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">other</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">!=</code> operator. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">!=</code> operation, or <code translate="no" dir="ltr">True</code> if the arguments are not broadcast-compatible. </td> </tr> 
</table> <h3 id="__neg__" data-text="__neg__" tabindex="0"><code translate="no" dir="ltr">__neg__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__neg__(
    x, name=None
)
</pre> <p>Computes numerical negative value element-wise.</p> <p>I.e., \(y = -x\).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__nonzero__" data-text="__nonzero__" tabindex="0"><code translate="no" dir="ltr">__nonzero__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/framework/ops.py#L879-L887">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__nonzero__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This is the Python 2.x counterpart to <code translate="no" dir="ltr">__bool__()</code> above.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__or__" data-text="__or__" tabindex="0"><code translate="no" dir="ltr">__or__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__or__(
    x, y
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__pow__" data-text="__pow__" tabindex="0"><code translate="no" dir="ltr">__pow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__pow__(
    x, y
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__radd__" data-text="__radd__" tabindex="0"><code translate="no" dir="ltr">__radd__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__radd__(
    y, x
)
</pre> <p>The operation invoked by the <a href="tensor#__add__"><code translate="no" dir="ltr">Tensor.<strong>add</strong></code></a> operator.</p> <p>Purpose in the API:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">This method is exposed in TensorFlow's API so that library developers
can register dispatching for &lt;a href="../tf/Tensor#__add__"&gt;&lt;code&gt;Tensor.__add__&lt;/code&gt;&lt;/a&gt; to allow it to handle
custom composite tensors &amp; other custom objects.

The API symbol is not intended to be called by users directly and does
appear in TensorFlow's generated documentation.
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> The left-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> The right-hand side of the <code translate="no" dir="ltr">+</code> operator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> an optional name for the operation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The result of the elementwise <code translate="no" dir="ltr">+</code> operation. </td> </tr> 
</table> <h3 id="__rand__" data-text="__rand__" tabindex="0"><code translate="no" dir="ltr">__rand__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rand__(
    y, x
)
</pre> <p>Logical AND function.</p> <p>The operation works for the following input types:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</li> </ul> <h4 id="usage_2" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_and(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_and(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_and(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False,  True])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h3 id="__rdiv__" data-text="__rdiv__" tabindex="0"><code translate="no" dir="ltr">__rdiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rdiv__(
    y, x
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside><blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.</span>
</blockquote> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <h3 id="__rfloordiv__" data-text="__rfloordiv__" tabindex="0"><code translate="no" dir="ltr">__rfloordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rfloordiv__(
    y, x
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="raggedtensor#__div__"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded down. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__rmatmul__" data-text="__rmatmul__" tabindex="0"><code translate="no" dir="ltr">__rmatmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmatmul__(
    y, x
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])
a  # 2-D tensor
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])
b  # 2-D tensor
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[ 7,  8],
       [ 9, 10],
       [11, 12]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=
array([[ 58,  64],
       [139, 154]], dtype=int32)&gt;
</pre> <p>A batch matrix multiplication with batch shape [2]:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])
a  # 3-D tensor
&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]], dtype=int32)&gt;
b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])
b  # 3-D tensor
&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[13, 14],
        [15, 16],
        [17, 18]],
       [[19, 20],
        [21, 22],
        [23, 24]]], dtype=int32)&gt;
c = tf.matmul(a, b)
c  # `a` * `b`
&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 94, 100],
        [229, 244]],
       [[508, 532],
        [697, 730]]], dtype=int32)&gt;
</pre> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="linalg/matmul"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = a @ b @ [[10], [11]]
d = tf.matmul(tf.matmul(a, b), [[10], [11]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. Notice, this <strong>does not support <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a></strong>, it just makes optimizations that assume most values in <code translate="no" dir="ltr">a</code> are zero. See <a href="sparse/sparse_dense_matmul"><code translate="no" dir="ltr">tf.sparse.sparse_dense_matmul</code></a> for some support for <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.sparse.SparseTensor</code></a> multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>. </td> </tr> </table> <h3 id="__rmod__" data-text="__rmod__" tabindex="0"><code translate="no" dir="ltr">__rmod__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmod__(
    y, x
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">uint64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rmul__" data-text="__rmul__" tabindex="0"><code translate="no" dir="ltr">__rmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmul__(
    y, x
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ror__" data-text="__ror__" tabindex="0"><code translate="no" dir="ltr">__ror__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ror__(
    y, x
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__rpow__" data-text="__rpow__" tabindex="0"><code translate="no" dir="ltr">__rpow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rpow__(
    y, x
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__rsub__" data-text="__rsub__" tabindex="0"><code translate="no" dir="ltr">__rsub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rsub__(
    y, x
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rtruediv__" data-text="__rtruediv__" tabindex="0"><code translate="no" dir="ltr">__rtruediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rtruediv__(
    y, x
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__rxor__" data-text="__rxor__" tabindex="0"><code translate="no" dir="ltr">__rxor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1153-L1156">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rxor__(
    y, x
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>The operation works for the following input types:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</li> </ul> <h4 id="usage_3" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_xor(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_xor(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_xor(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h3 id="__sub__" data-text="__sub__" tabindex="0"><code translate="no" dir="ltr">__sub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__sub__(
    x, y
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">uint32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__truediv__" data-text="__truediv__" tabindex="0"><code translate="no" dir="ltr">__truediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__truediv__(
    x, y
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <blockquote class="note">
<strong>Note:</strong><span> Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</span>
</blockquote> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> evaluated in floating point. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes. </td> </tr> </table> <h3 id="__xor__" data-text="__xor__" tabindex="0"><code translate="no" dir="ltr">__xor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/math_ops.py#L1122-L1143">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__xor__(
    x, y
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>The operation works for the following input types:</p> <ul> <li>Two single elements of type <code translate="no" dir="ltr">bool</code>
</li> <li>One <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">bool</code> and one single <code translate="no" dir="ltr">bool</code>, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</li> <li>Two <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> objects of type <code translate="no" dir="ltr">bool</code> of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</li> </ul> <h4 id="usage_4" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.constant([True])
b = tf.constant([False])
tf.math.logical_xor(a, b)
&lt;tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
c = tf.constant([True])
x = tf.constant([False, True, True, False])
tf.math.logical_xor(c, x)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
y = tf.constant([False, False, True, True])
z = tf.constant([False, True, False, True])
tf.math.logical_xor(y, z)
&lt;tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h2 id="class_variables" data-text="Class Variables" tabindex="0">Class Variables</h2> <ul> <li>
<code translate="no" dir="ltr">OVERLOADABLE_OPERATORS</code> 
</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/Tensor" class="_attribution-link">https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/Tensor</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
