
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.keras.preprocessing.text.Tokenizer - TensorFlow 2.3 - W3cubDocs</title>
  
  <meta name="description" content=" ">
  <meta name="keywords" content="tf, keras, preprocessing, text, tokenizerargumentsargumentsargumentsreturnsargumentsreturnsraisesargumentsreturnsargumentsyieldsargumentsreturnsargumentsreturnsargumentsyieldsargumentsreturns, tokenizer, tensorflow, tensorflow~2.3">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.3/keras/preprocessing/text/tokenizer.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.3.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.3/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.3</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.keras.preprocessing.text.Tokenizer</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>    <p>Text tokenization utility class.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="0">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"><code translate="no" dir="ltr">tf.compat.v1.keras.preprocessing.text.Tokenizer</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.preprocessing.text.Tokenizer(
    num_words=None, filters='!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n', lower=True,
    split=' ', char_level=False, oov_token=None, document_count=0, **kwargs
)
</pre>  <p>This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...</p> <h1 id="arguments" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">num_words: the maximum number of words to keep, based
    on word frequency. Only the most common `num_words-1` words will
    be kept.
filters: a string where each element is a character that will be
    filtered from the texts. The default is all punctuation, plus
    tabs and line breaks, minus the `'` character.
lower: boolean. Whether to convert the texts to lowercase.
split: str. Separator for word splitting.
char_level: if True, every character will be treated as a token.
oov_token: if given, it will be added to word_index and used to
    replace out-of-vocabulary words during text_to_sequence calls
</pre> <p>By default, all punctuation is removed, turning the texts into space-separated sequences of words (words maybe include the <code translate="no" dir="ltr">'</code> character). These sequences are then split into lists of tokens. They will then be indexed or vectorized.</p> <p><code translate="no" dir="ltr">0</code> is a reserved index that won't be assigned to any word.</p> <h2 id="methods" data-text="Methods" tabindex="0">Methods</h2> <h3 id="fit_on_sequences" data-text="fit_on_sequences" tabindex="0"><code translate="no" dir="ltr">fit_on_sequences</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
fit_on_sequences(
    sequences
)
</pre> <p>Updates internal vocabulary based on a list of sequences.</p> <p>Required before using <code translate="no" dir="ltr">sequences_to_matrix</code> (if <code translate="no" dir="ltr">fit_on_texts</code> was never called).</p> <h1 id="arguments_2" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">sequences: A list of sequence.
    A "sequence" is a list of integer word indices.
</pre> <h3 id="fit_on_texts" data-text="fit_on_texts" tabindex="0"><code translate="no" dir="ltr">fit_on_texts</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
fit_on_texts(
    texts
)
</pre> <p>Updates internal vocabulary based on a list of texts.</p> <p>In the case where texts contains lists, we assume each entry of the lists to be a token.</p> <p>Required before using <code translate="no" dir="ltr">texts_to_sequences</code> or <code translate="no" dir="ltr">texts_to_matrix</code>.</p> <h1 id="arguments_3" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">texts: can be a list of strings,
    a generator of strings (for memory-efficiency),
    or a list of list of strings.
</pre> <h3 id="get_config" data-text="get_config" tabindex="0"><code translate="no" dir="ltr">get_config</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_config()
</pre> <p>Returns the tokenizer configuration as Python dictionary. The word count dictionaries used by the tokenizer get serialized into plain JSON, so that the configuration can be read by other projects.</p> <h1 id="returns" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A Python dictionary with the tokenizer configuration.
</pre> <h3 id="sequences_to_matrix" data-text="sequences_to_matrix" tabindex="0"><code translate="no" dir="ltr">sequences_to_matrix</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
sequences_to_matrix(
    sequences, mode='binary'
)
</pre> <p>Converts a list of sequences into a Numpy matrix.</p> <h1 id="arguments_4" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">sequences: list of sequences
    (a sequence is a list of integer word indices).
mode: one of "binary", "count", "tfidf", "freq"
</pre> <h1 id="returns_2" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A Numpy matrix.
</pre> <h1 id="raises" class="page-title" data-text="Raises" tabindex="0">Raises</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">ValueError: In case of invalid `mode` argument,
    or if the Tokenizer requires to be fit to sample data.
</pre> <h3 id="sequences_to_texts" data-text="sequences_to_texts" tabindex="0"><code translate="no" dir="ltr">sequences_to_texts</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
sequences_to_texts(
    sequences
)
</pre> <p>Transforms each sequence into a list of text.</p> <p>Only top <code translate="no" dir="ltr">num_words-1</code> most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p> <h1 id="arguments_5" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">sequences: A list of sequences (list of integers).
</pre> <h1 id="returns_3" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A list of texts (strings)
</pre> <h3 id="sequences_to_texts_generator" data-text="sequences_to_texts_generator" tabindex="0"><code translate="no" dir="ltr">sequences_to_texts_generator</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
sequences_to_texts_generator(
    sequences
)
</pre> <p>Transforms each sequence in <code translate="no" dir="ltr">sequences</code> to a list of texts(strings).</p> <p>Each sequence has to a list of integers. In other words, sequences should be a list of sequences</p> <p>Only top <code translate="no" dir="ltr">num_words-1</code> most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p> <h1 id="arguments_6" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">sequences: A list of sequences.
</pre> <h1 id="yields" class="page-title" data-text="Yields" tabindex="0">Yields</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">Yields individual texts.
</pre> <h3 id="texts_to_matrix" data-text="texts_to_matrix" tabindex="0"><code translate="no" dir="ltr">texts_to_matrix</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
texts_to_matrix(
    texts, mode='binary'
)
</pre> <p>Convert a list of texts to a Numpy matrix.</p> <h1 id="arguments_7" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">texts: list of strings.
mode: one of "binary", "count", "tfidf", "freq".
</pre> <h1 id="returns_4" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A Numpy matrix.
</pre> <h3 id="texts_to_sequences" data-text="texts_to_sequences" tabindex="0"><code translate="no" dir="ltr">texts_to_sequences</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
texts_to_sequences(
    texts
)
</pre> <p>Transforms each text in texts to a sequence of integers.</p> <p>Only top <code translate="no" dir="ltr">num_words-1</code> most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p> <h1 id="arguments_8" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">texts: A list of texts (strings).
</pre> <h1 id="returns_5" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A list of sequences.
</pre> <h3 id="texts_to_sequences_generator" data-text="texts_to_sequences_generator" tabindex="0"><code translate="no" dir="ltr">texts_to_sequences_generator</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
texts_to_sequences_generator(
    texts
)
</pre> <p>Transforms each text in <code translate="no" dir="ltr">texts</code> to a sequence of integers.</p> <p>Each item in texts can also be a list, in which case we assume each item of that list to be a token.</p> <p>Only top <code translate="no" dir="ltr">num_words-1</code> most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p> <h1 id="arguments_9" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">texts: A list of texts (strings).
</pre> <h1 id="yields_2" class="page-title" data-text="Yields" tabindex="0">Yields</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">Yields individual sequences.
</pre> <h3 id="to_json" data-text="to_json" tabindex="0"><code translate="no" dir="ltr">to_json</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_json(
    **kwargs
)
</pre> <p>Returns a JSON string containing the tokenizer configuration. To load a tokenizer from a JSON string, use <a href="tokenizer_from_json"><code translate="no" dir="ltr">keras.preprocessing.text.tokenizer_from_json(json_string)</code></a>.</p> <h1 id="arguments_10" class="page-title" data-text="Arguments" tabindex="0">Arguments</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">**kwargs: Additional keyword arguments
    to be passed to `json.dumps()`.
</pre> <h1 id="returns_6" class="page-title" data-text="Returns" tabindex="0">Returns</h1> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">A JSON string containing the tokenizer configuration.
</pre>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/preprocessing/text/Tokenizer" class="_attribution-link">https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/preprocessing/text/Tokenizer</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
