
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Module&#58; Tf - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;__init__.py. ">
  <meta name="keywords" content="module, tf, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~python.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> Module: tf </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf"> <meta itemprop="path" content="r1.8"> <meta itemprop="property" content="AUTO_REUSE"> <meta itemprop="property" content="COMPILER_VERSION"> <meta itemprop="property" content="CXX11_ABI_FLAG"> <meta itemprop="property" content="GIT_VERSION"> <meta itemprop="property" content="GRAPH_DEF_VERSION"> <meta itemprop="property" content="GRAPH_DEF_VERSION_MIN_CONSUMER"> <meta itemprop="property" content="GRAPH_DEF_VERSION_MIN_PRODUCER"> <meta itemprop="property" content="MONOLITHIC_BUILD"> <meta itemprop="property" content="QUANTIZED_DTYPES"> <meta itemprop="property" content="VERSION"> <meta itemprop="property" content="__cached__"> <meta itemprop="property" content="__compiler_version__"> <meta itemprop="property" content="__cxx11_abi_flag__"> <meta itemprop="property" content="__git_version__"> <meta itemprop="property" content="__loader__"> <meta itemprop="property" content="__monolithic_build__"> <meta itemprop="property" content="__spec__"> <meta itemprop="property" content="__version__"> <meta itemprop="property" content="bfloat16"> <meta itemprop="property" content="bool"> <meta itemprop="property" content="complex128"> <meta itemprop="property" content="complex64"> <meta itemprop="property" content="double"> <meta itemprop="property" content="float16"> <meta itemprop="property" content="float32"> <meta itemprop="property" content="float64"> <meta itemprop="property" content="half"> <meta itemprop="property" content="int16"> <meta itemprop="property" content="int32"> <meta itemprop="property" content="int64"> <meta itemprop="property" content="int8"> <meta itemprop="property" content="newaxis"> <meta itemprop="property" content="qint16"> <meta itemprop="property" content="qint32"> <meta itemprop="property" content="qint8"> <meta itemprop="property" content="quint16"> <meta itemprop="property" content="quint8"> <meta itemprop="property" content="resource"> <meta itemprop="property" content="string"> <meta itemprop="property" content="uint16"> <meta itemprop="property" content="uint32"> <meta itemprop="property" content="uint64"> <meta itemprop="property" content="uint8"> <meta itemprop="property" content="variant"> </div> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/__init__.py"><code>tensorflow/__init__.py</code></a>.</p> <h2 id="modules">Modules</h2> <p><a href="tf/app"><code>app</code></a> module: Imports for Python API.</p> <p><a href="tf/bitwise"><code>bitwise</code></a> module: Imports for Python API.</p> <p><a href="tf/compat"><code>compat</code></a> module: Imports for Python API.</p> <p><a href="tf/contrib"><code>contrib</code></a> module: contrib module containing volatile or experimental code.</p> <p><a href="tf/data"><code>data</code></a> module: Imports for Python API.</p> <p><a href="tf/distributions"><code>distributions</code></a> module: Imports for Python API.</p> <p><a href="tf/errors"><code>errors</code></a> module: Imports for Python API.</p> <p><a href="tf/estimator"><code>estimator</code></a> module: Imports for Python API.</p> <p><a href="tf/feature_column"><code>feature_column</code></a> module: Imports for Python API.</p> <p><a href="tf/flags"><code>flags</code></a> module: Import router for absl.flags. See https://github.com/abseil/abseil-py.</p> <p><a href="tf/gfile"><code>gfile</code></a> module: Imports for Python API.</p> <p><a href="tf/graph_util"><code>graph_util</code></a> module: Imports for Python API.</p> <p><a href="tf/image"><code>image</code></a> module: Imports for Python API.</p> <p><a href="tf/initializers"><code>initializers</code></a> module: Imports for Python API.</p> <p><a href="tf/keras"><code>keras</code></a> module: Imports for Python API.</p> <p><a href="tf/layers"><code>layers</code></a> module: Imports for Python API.</p> <p><a href="tf/linalg"><code>linalg</code></a> module: Imports for Python API.</p> <p><a href="tf/logging"><code>logging</code></a> module: Imports for Python API.</p> <p><a href="tf/losses"><code>losses</code></a> module: Imports for Python API.</p> <p><a href="tf/manip"><code>manip</code></a> module: Imports for Python API.</p> <p><a href="tf/math"><code>math</code></a> module: Imports for Python API.</p> <p><a href="tf/metrics"><code>metrics</code></a> module: Imports for Python API.</p> <p><a href="tf/nn"><code>nn</code></a> module: Imports for Python API.</p> <p><a href="tf/profiler"><code>profiler</code></a> module: Imports for Python API.</p> <p><a href="tf/python_io"><code>python_io</code></a> module: Imports for Python API.</p> <p><a href="tf/pywrap_tensorflow"><code>pywrap_tensorflow</code></a> module: A wrapper for TensorFlow SWIG-generated bindings.</p> <p><a href="tf/resource_loader"><code>resource_loader</code></a> module: Imports for Python API.</p> <p><a href="tf/saved_model"><code>saved_model</code></a> module: Imports for Python API.</p> <p><a href="tf/sets"><code>sets</code></a> module: Imports for Python API.</p> <p><a href="tf/spectral"><code>spectral</code></a> module: Imports for Python API.</p> <p><a href="tf/summary"><code>summary</code></a> module: Imports for Python API.</p> <p><a href="tf/sysconfig"><code>sysconfig</code></a> module: Imports for Python API.</p> <p><a href="tf/test"><code>test</code></a> module: Imports for Python API.</p> <p><a href="tf/tools"><code>tools</code></a> module</p> <p><a href="tf/train"><code>train</code></a> module: Imports for Python API.</p> <p><a href="tf/user_ops"><code>user_ops</code></a> module: Imports for Python API.</p> <h2 id="classes">Classes</h2> <p><a href="tf/aggregationmethod"><code>class AggregationMethod</code></a>: A class listing aggregation methods used to combine gradients.</p> <p><a href="tf/attrvalue"><code>class AttrValue</code></a>: A ProtocolMessage</p> <p><a href="tf/conditionalaccumulator"><code>class ConditionalAccumulator</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="tf/conditionalaccumulatorbase"><code>class ConditionalAccumulatorBase</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="tf/configproto"><code>class ConfigProto</code></a>: A ProtocolMessage</p> <p><a href="tf/dtype"><code>class DType</code></a>: Represents the type of the elements in a <code>Tensor</code>.</p> <p><a href="tf/devicespec"><code>class DeviceSpec</code></a>: Represents a (possibly partial) specification for a TensorFlow device.</p> <p><a href="tf/dimension"><code>class Dimension</code></a>: Represents the value of one dimension in a TensorShape.</p> <p><a href="tf/event"><code>class Event</code></a>: A ProtocolMessage</p> <p><a href="tf/fifoqueue"><code>class FIFOQueue</code></a>: A queue implementation that dequeues elements in first-in first-out order.</p> <p><a href="tf/fixedlenfeature"><code>class FixedLenFeature</code></a>: Configuration for parsing a fixed-length input feature.</p> <p><a href="tf/fixedlensequencefeature"><code>class FixedLenSequenceFeature</code></a>: Configuration for parsing a variable-length input feature into a <code>Tensor</code>.</p> <p><a href="tf/fixedlengthrecordreader"><code>class FixedLengthRecordReader</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="tf/gpuoptions"><code>class GPUOptions</code></a>: A ProtocolMessage</p> <p><a href="tf/gradienttape"><code>class GradientTape</code></a>: Record operations for automatic differentiation.</p> <p><a href="tf/graph"><code>class Graph</code></a>: A TensorFlow computation, represented as a dataflow graph.</p> <p><a href="tf/graphdef"><code>class GraphDef</code></a>: A ProtocolMessage</p> <p><a href="tf/graphkeys"><code>class GraphKeys</code></a>: Standard names to use for graph collections.</p> <p><a href="tf/graphoptions"><code>class GraphOptions</code></a>: A ProtocolMessage</p> <p><a href="tf/histogramproto"><code>class HistogramProto</code></a>: A ProtocolMessage</p> <p><a href="tf/identityreader"><code>class IdentityReader</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="tf/indexedslices"><code>class IndexedSlices</code></a>: A sparse representation of a set of tensor slices at given indices.</p> <p><a href="tf/interactivesession"><code>class InteractiveSession</code></a>: A TensorFlow <code>Session</code> for use in interactive contexts, such as a shell.</p> <p><a href="tf/lmdbreader"><code>class LMDBReader</code></a>: A Reader that outputs the records from a LMDB file.</p> <p><a href="tf/logmessage"><code>class LogMessage</code></a>: A ProtocolMessage</p> <p><a href="tf/metagraphdef"><code>class MetaGraphDef</code></a>: A ProtocolMessage</p> <p><a href="tf/nameattrlist"><code>class NameAttrList</code></a>: A ProtocolMessage</p> <p><a href="tf/nodedef"><code>class NodeDef</code></a>: A ProtocolMessage</p> <p><a href="tf/operror"><code>class OpError</code></a>: A generic error that is raised when TensorFlow execution fails.</p> <p><a href="tf/operation"><code>class Operation</code></a>: Represents a graph node that performs computation on tensors.</p> <p><a href="tf/optimizeroptions"><code>class OptimizerOptions</code></a>: A ProtocolMessage</p> <p><a href="tf/paddingfifoqueue"><code>class PaddingFIFOQueue</code></a>: A FIFOQueue that supports batching variable-sized tensors by padding.</p> <p><a href="tf/priorityqueue"><code>class PriorityQueue</code></a>: A queue implementation that dequeues elements in prioritized order.</p> <p><a href="tf/queuebase"><code>class QueueBase</code></a>: Base class for queue implementations.</p> <p><a href="tf/randomshufflequeue"><code>class RandomShuffleQueue</code></a>: A queue implementation that dequeues elements in a random order.</p> <p><a href="tf/readerbase"><code>class ReaderBase</code></a>: Base class for different Reader types, that produce a record every step.</p> <p><a href="tf/registergradient"><code>class RegisterGradient</code></a>: A decorator for registering the gradient function for an op type.</p> <p><a href="tf/runmetadata"><code>class RunMetadata</code></a>: A ProtocolMessage</p> <p><a href="tf/runoptions"><code>class RunOptions</code></a>: A ProtocolMessage</p> <p><a href="tf/session"><code>class Session</code></a>: A class for running TensorFlow operations.</p> <p><a href="tf/sessionlog"><code>class SessionLog</code></a>: A ProtocolMessage</p> <p><a href="tf/sparseconditionalaccumulator"><code>class SparseConditionalAccumulator</code></a>: A conditional accumulator for aggregating sparse gradients.</p> <p><a href="tf/sparsefeature"><code>class SparseFeature</code></a>: Configuration for parsing a sparse input feature from an <code>Example</code>.</p> <p><a href="tf/sparsetensor"><code>class SparseTensor</code></a>: Represents a sparse tensor.</p> <p><a href="tf/sparsetensorvalue"><code>class SparseTensorValue</code></a>: SparseTensorValue(indices, values, dense_shape)</p> <p><a href="tf/summary"><code>class Summary</code></a>: A ProtocolMessage</p> <p><a href="tf/summarymetadata"><code>class SummaryMetadata</code></a>: A ProtocolMessage</p> <p><a href="tf/tfrecordreader"><code>class TFRecordReader</code></a>: A Reader that outputs the records from a TFRecords file.</p> <p><a href="tf/tensor"><code>class Tensor</code></a>: Represents one of the outputs of an <code>Operation</code>.</p> <p><a href="tf/tensorarray"><code>class TensorArray</code></a>: Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.</p> <p><a href="tf/tensorinfo"><code>class TensorInfo</code></a>: A ProtocolMessage</p> <p><a href="tf/tensorshape"><code>class TensorShape</code></a>: Represents the shape of a <code>Tensor</code>.</p> <p><a href="tf/textlinereader"><code>class TextLineReader</code></a>: A Reader that outputs the lines of a file delimited by newlines.</p> <p><a href="tf/varlenfeature"><code>class VarLenFeature</code></a>: Configuration for parsing a variable-length input feature.</p> <p><a href="tf/variable"><code>class Variable</code></a>: See the <a href="https://www.tensorflow.org/programmers_guide/variables">Variables How To</a> for a high level overview.</p> <p><a href="tf/variablescope"><code>class VariableScope</code></a>: Variable scope object to carry defaults to provide to <code>get_variable</code>.</p> <p><a href="tf/wholefilereader"><code>class WholeFileReader</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="tf/constant_initializer"><code>class constant_initializer</code></a>: Initializer that generates tensors with constant values.</p> <p><a href="tf/name_scope"><code>class name_scope</code></a>: A context manager for use when defining a Python op.</p> <p><a href="tf/ones_initializer"><code>class ones_initializer</code></a>: Initializer that generates tensors initialized to 1.</p> <p><a href="tf/orthogonal_initializer"><code>class orthogonal_initializer</code></a>: Initializer that generates an orthogonal matrix.</p> <p><a href="tf/random_normal_initializer"><code>class random_normal_initializer</code></a>: Initializer that generates tensors with a normal distribution.</p> <p><a href="tf/random_uniform_initializer"><code>class random_uniform_initializer</code></a>: Initializer that generates tensors with a uniform distribution.</p> <p><a href="tf/truncated_normal_initializer"><code>class truncated_normal_initializer</code></a>: Initializer that generates a truncated normal distribution.</p> <p><a href="tf/uniform_unit_scaling_initializer"><code>class uniform_unit_scaling_initializer</code></a>: Initializer that generates tensors without scaling variance.</p> <p><a href="tf/variable_scope"><code>class variable_scope</code></a>: A context manager for defining ops that creates variables (layers).</p> <p><a href="tf/variance_scaling_initializer"><code>class variance_scaling_initializer</code></a>: Initializer capable of adapting its scale to the shape of weights tensors.</p> <p><a href="tf/zeros_initializer"><code>class zeros_initializer</code></a>: Initializer that generates tensors initialized to 0.</p> <h2 id="functions">Functions</h2> <p><a href="tf/assert"><code>Assert(...)</code></a>: Asserts that the given condition is true.</p> <p><a href="tf/nogradient"><code>NoGradient(...)</code></a>: Specifies that ops of type <code>op_type</code> is not differentiable.</p> <p><a href="tf/nogradient"><code>NotDifferentiable(...)</code></a>: Specifies that ops of type <code>op_type</code> is not differentiable.</p> <p><a href="tf/print"><code>Print(...)</code></a>: Prints a list of tensors.</p> <p><a href="tf/abs"><code>abs(...)</code></a>: Computes the absolute value of a tensor.</p> <p><a href="tf/accumulate_n"><code>accumulate_n(...)</code></a>: Returns the element-wise sum of a list of tensors.</p> <p><a href="tf/acos"><code>acos(...)</code></a>: Computes acos of x element-wise.</p> <p><a href="tf/acosh"><code>acosh(...)</code></a>: Computes inverse hyperbolic cosine of x element-wise.</p> <p><a href="tf/add"><code>add(...)</code></a>: Returns x + y element-wise.</p> <p><a href="tf/add_check_numerics_ops"><code>add_check_numerics_ops(...)</code></a>: Connect a <code>check_numerics</code> to every floating point tensor.</p> <p><a href="tf/add_n"><code>add_n(...)</code></a>: Adds all input tensors element-wise.</p> <p><a href="tf/add_to_collection"><code>add_to_collection(...)</code></a>: Wrapper for <code>Graph.add_to_collection()</code> using the default graph.</p> <p><a href="tf/add_to_collections"><code>add_to_collections(...)</code></a>: Wrapper for <code>Graph.add_to_collections()</code> using the default graph.</p> <p><a href="tf/all_variables"><code>all_variables(...)</code></a>: See <a href="tf/global_variables"><code>tf.global_variables</code></a>. (deprecated)</p> <p><a href="tf/angle"><code>angle(...)</code></a>: Returns the element-wise argument of a complex (or real) tensor.</p> <p><a href="tf/arg_max"><code>arg_max(...)</code></a>: Returns the index with the largest value across dimensions of a tensor. (deprecated)</p> <p><a href="tf/arg_min"><code>arg_min(...)</code></a>: Returns the index with the smallest value across dimensions of a tensor. (deprecated)</p> <p><a href="tf/argmax"><code>argmax(...)</code></a>: Returns the index with the largest value across axes of a tensor. (deprecated arguments)</p> <p><a href="tf/argmin"><code>argmin(...)</code></a>: Returns the index with the smallest value across axes of a tensor. (deprecated arguments)</p> <p><a href="tf/as_dtype"><code>as_dtype(...)</code></a>: Converts the given <code>type_value</code> to a <code>DType</code>.</p> <p><a href="tf/as_string"><code>as_string(...)</code></a>: Converts each entry in the given tensor to strings. Supports many numeric</p> <p><a href="tf/asin"><code>asin(...)</code></a>: Computes asin of x element-wise.</p> <p><a href="tf/asinh"><code>asinh(...)</code></a>: Computes inverse hyperbolic sine of x element-wise.</p> <p><a href="tf/assert_equal"><code>assert_equal(...)</code></a>: Assert the condition <code>x == y</code> holds element-wise.</p> <p><a href="tf/assert_greater"><code>assert_greater(...)</code></a>: Assert the condition <code>x &gt; y</code> holds element-wise.</p> <p><a href="tf/assert_greater_equal"><code>assert_greater_equal(...)</code></a>: Assert the condition <code>x &gt;= y</code> holds element-wise.</p> <p><a href="tf/assert_integer"><code>assert_integer(...)</code></a>: Assert that <code>x</code> is of integer dtype.</p> <p><a href="tf/assert_less"><code>assert_less(...)</code></a>: Assert the condition <code>x &lt; y</code> holds element-wise.</p> <p><a href="tf/assert_less_equal"><code>assert_less_equal(...)</code></a>: Assert the condition <code>x &lt;= y</code> holds element-wise.</p> <p><a href="tf/assert_near"><code>assert_near(...)</code></a>: Assert the condition <code>x</code> and <code>y</code> are close element-wise.</p> <p><a href="tf/assert_negative"><code>assert_negative(...)</code></a>: Assert the condition <code>x &lt; 0</code> holds element-wise.</p> <p><a href="tf/assert_non_negative"><code>assert_non_negative(...)</code></a>: Assert the condition <code>x &gt;= 0</code> holds element-wise.</p> <p><a href="tf/assert_non_positive"><code>assert_non_positive(...)</code></a>: Assert the condition <code>x &lt;= 0</code> holds element-wise.</p> <p><a href="tf/assert_none_equal"><code>assert_none_equal(...)</code></a>: Assert the condition <code>x != y</code> holds for all elements.</p> <p><a href="tf/assert_positive"><code>assert_positive(...)</code></a>: Assert the condition <code>x &gt; 0</code> holds element-wise.</p> <p><a href="tf/assert_proper_iterable"><code>assert_proper_iterable(...)</code></a>: Static assert that values is a "proper" iterable.</p> <p><a href="tf/assert_rank"><code>assert_rank(...)</code></a>: Assert <code>x</code> has rank equal to <code>rank</code>.</p> <p><a href="tf/assert_rank_at_least"><code>assert_rank_at_least(...)</code></a>: Assert <code>x</code> has rank equal to <code>rank</code> or higher.</p> <p><a href="tf/assert_rank_in"><code>assert_rank_in(...)</code></a>: Assert <code>x</code> has rank in <code>ranks</code>.</p> <p><a href="tf/assert_same_float_dtype"><code>assert_same_float_dtype(...)</code></a>: Validate and return float type based on <code>tensors</code> and <code>dtype</code>.</p> <p><a href="tf/assert_scalar"><code>assert_scalar(...)</code></a></p> <p><a href="tf/assert_type"><code>assert_type(...)</code></a>: Statically asserts that the given <code>Tensor</code> is of the specified type.</p> <p><a href="tf/assert_variables_initialized"><code>assert_variables_initialized(...)</code></a>: Returns an Op to check if variables are initialized.</p> <p><a href="tf/assign"><code>assign(...)</code></a>: Update 'ref' by assigning 'value' to it.</p> <p><a href="tf/assign_add"><code>assign_add(...)</code></a>: Update 'ref' by adding 'value' to it.</p> <p><a href="tf/assign_sub"><code>assign_sub(...)</code></a>: Update 'ref' by subtracting 'value' from it.</p> <p><a href="tf/atan"><code>atan(...)</code></a>: Computes atan of x element-wise.</p> <p><a href="tf/atan2"><code>atan2(...)</code></a>: Computes arctangent of <code>y/x</code> element-wise, respecting signs of the arguments.</p> <p><a href="tf/atanh"><code>atanh(...)</code></a>: Computes inverse hyperbolic tangent of x element-wise.</p> <p><a href="tf/batch_to_space"><code>batch_to_space(...)</code></a>: BatchToSpace for 4-D tensors of type T.</p> <p><a href="tf/batch_to_space_nd"><code>batch_to_space_nd(...)</code></a>: BatchToSpace for N-D tensors of type T.</p> <p><a href="tf/betainc"><code>betainc(...)</code></a>: Compute the regularized incomplete beta integral \(I_x(a, b)\).</p> <p><a href="tf/bincount"><code>bincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="tf/bitcast"><code>bitcast(...)</code></a>: Bitcasts a tensor from one type to another without copying data.</p> <p><a href="tf/boolean_mask"><code>boolean_mask(...)</code></a>: Apply boolean mask to tensor. Numpy equivalent is <code>tensor[mask]</code>.</p> <p><a href="tf/broadcast_dynamic_shape"><code>broadcast_dynamic_shape(...)</code></a>: Returns the broadcasted dynamic shape between <code>shape_x</code> and <code>shape_y</code>.</p> <p><a href="tf/broadcast_static_shape"><code>broadcast_static_shape(...)</code></a>: Returns the broadcasted static shape between <code>shape_x</code> and <code>shape_y</code>.</p> <p><a href="tf/case"><code>case(...)</code></a>: Create a case operation.</p> <p><a href="tf/cast"><code>cast(...)</code></a>: Casts a tensor to a new type.</p> <p><a href="tf/ceil"><code>ceil(...)</code></a>: Returns element-wise smallest integer in not less than x.</p> <p><a href="tf/check_numerics"><code>check_numerics(...)</code></a>: Checks a tensor for NaN and Inf values.</p> <p><a href="tf/cholesky"><code>cholesky(...)</code></a>: Computes the Cholesky decomposition of one or more square matrices.</p> <p><a href="tf/cholesky_solve"><code>cholesky_solve(...)</code></a>: Solves systems of linear eqns <code>A X = RHS</code>, given Cholesky factorizations.</p> <p><a href="tf/clip_by_average_norm"><code>clip_by_average_norm(...)</code></a>: Clips tensor values to a maximum average L2-norm.</p> <p><a href="tf/clip_by_global_norm"><code>clip_by_global_norm(...)</code></a>: Clips values of multiple tensors by the ratio of the sum of their norms.</p> <p><a href="tf/clip_by_norm"><code>clip_by_norm(...)</code></a>: Clips tensor values to a maximum L2-norm.</p> <p><a href="tf/clip_by_value"><code>clip_by_value(...)</code></a>: Clips tensor values to a specified min and max.</p> <p><a href="tf/colocate_with"><code>colocate_with(...)</code></a></p> <p><a href="tf/complex"><code>complex(...)</code></a>: Converts two real numbers to a complex number.</p> <p><a href="tf/concat"><code>concat(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="tf/cond"><code>cond(...)</code></a>: Return <code>true_fn()</code> if the predicate <code>pred</code> is true else <code>false_fn()</code>. (deprecated arguments)</p> <p><a href="tf/confusion_matrix"><code>confusion_matrix(...)</code></a>: Computes the confusion matrix from predictions and labels.</p> <p><a href="tf/conj"><code>conj(...)</code></a>: Returns the complex conjugate of a complex number.</p> <p><a href="tf/constant"><code>constant(...)</code></a>: Creates a constant tensor.</p> <p><a href="tf/container"><code>container(...)</code></a>: Wrapper for <code>Graph.container()</code> using the default graph.</p> <p><a href="tf/control_dependencies"><code>control_dependencies(...)</code></a>: Wrapper for <code>Graph.control_dependencies()</code> using the default graph.</p> <p><a href="tf/convert_to_tensor"><code>convert_to_tensor(...)</code></a>: Converts the given <code>value</code> to a <code>Tensor</code>.</p> <p><a href="tf/convert_to_tensor_or_indexed_slices"><code>convert_to_tensor_or_indexed_slices(...)</code></a>: Converts the given object to a <code>Tensor</code> or an <code>IndexedSlices</code>.</p> <p><a href="tf/convert_to_tensor_or_sparse_tensor"><code>convert_to_tensor_or_sparse_tensor(...)</code></a>: Converts value to a <code>SparseTensor</code> or <code>Tensor</code>.</p> <p><a href="tf/cos"><code>cos(...)</code></a>: Computes cos of x element-wise.</p> <p><a href="tf/cosh"><code>cosh(...)</code></a>: Computes hyperbolic cosine of x element-wise.</p> <p><a href="tf/count_nonzero"><code>count_nonzero(...)</code></a>: Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/count_up_to"><code>count_up_to(...)</code></a>: Increments 'ref' until it reaches 'limit'.</p> <p><a href="tf/create_partitioned_variables"><code>create_partitioned_variables(...)</code></a>: Create a list of partitioned variables according to the given <code>slicing</code>.</p> <p><a href="tf/cross"><code>cross(...)</code></a>: Compute the pairwise cross product.</p> <p><a href="tf/cumprod"><code>cumprod(...)</code></a>: Compute the cumulative product of the tensor <code>x</code> along <code>axis</code>.</p> <p><a href="tf/cumsum"><code>cumsum(...)</code></a>: Compute the cumulative sum of the tensor <code>x</code> along <code>axis</code>.</p> <p><a href="tf/custom_gradient"><code>custom_gradient(...)</code></a>: Decorator to define a function with a custom gradient.</p> <p><a href="tf/decode_base64"><code>decode_base64(...)</code></a>: Decode web-safe base64-encoded strings.</p> <p><a href="tf/decode_csv"><code>decode_csv(...)</code></a>: Convert CSV records to tensors. Each column maps to one tensor.</p> <p><a href="tf/decode_json_example"><code>decode_json_example(...)</code></a>: Convert JSON-encoded Example records to binary protocol buffer strings.</p> <p><a href="tf/decode_raw"><code>decode_raw(...)</code></a>: Reinterpret the bytes of a string as a vector of numbers.</p> <p><a href="tf/delete_session_tensor"><code>delete_session_tensor(...)</code></a>: Delete the tensor for the given tensor handle.</p> <p><a href="tf/depth_to_space"><code>depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="tf/dequantize"><code>dequantize(...)</code></a>: Dequantize the 'input' tensor into a float Tensor.</p> <p><a href="tf/deserialize_many_sparse"><code>deserialize_many_sparse(...)</code></a>: Deserialize and concatenate <code>SparseTensors</code> from a serialized minibatch.</p> <p><a href="tf/device"><code>device(...)</code></a>: Wrapper for <code>Graph.device()</code> using the default graph.</p> <p><a href="tf/diag"><code>diag(...)</code></a>: Returns a diagonal tensor with a given diagonal values.</p> <p><a href="tf/diag_part"><code>diag_part(...)</code></a>: Returns the diagonal part of the tensor.</p> <p><a href="tf/digamma"><code>digamma(...)</code></a>: Computes Psi, the derivative of Lgamma (the log of the absolute value of</p> <p><a href="tf/div"><code>div(...)</code></a>: Divides x / y elementwise (using Python 2 division operator semantics).</p> <p><a href="tf/divide"><code>divide(...)</code></a>: Computes Python style division of <code>x</code> by <code>y</code>.</p> <p><a href="tf/dynamic_partition"><code>dynamic_partition(...)</code></a>: Partitions <code>data</code> into <code>num_partitions</code> tensors using indices from <code>partitions</code>.</p> <p><a href="tf/dynamic_stitch"><code>dynamic_stitch(...)</code></a>: Interleave the values from the <code>data</code> tensors into a single tensor.</p> <p><a href="tf/edit_distance"><code>edit_distance(...)</code></a>: Computes the Levenshtein distance between sequences.</p> <p><a href="tf/einsum"><code>einsum(...)</code></a>: A generalized contraction between tensors of arbitrary dimension.</p> <p><a href="tf/enable_eager_execution"><code>enable_eager_execution(...)</code></a>: Enables eager execution for the lifetime of this program.</p> <p><a href="tf/encode_base64"><code>encode_base64(...)</code></a>: Encode strings into web-safe base64 format.</p> <p><a href="tf/equal"><code>equal(...)</code></a>: Returns the truth value of (x == y) element-wise.</p> <p><a href="tf/erf"><code>erf(...)</code></a>: Computes the Gauss error function of <code>x</code> element-wise.</p> <p><a href="tf/erfc"><code>erfc(...)</code></a>: Computes the complementary error function of <code>x</code> element-wise.</p> <p><a href="tf/executing_eagerly"><code>executing_eagerly(...)</code></a>: Returns True if the current thread has eager execution enabled.</p> <p><a href="tf/exp"><code>exp(...)</code></a>: Computes exponential of x element-wise. \(y = e^x\).</p> <p><a href="tf/expand_dims"><code>expand_dims(...)</code></a>: Inserts a dimension of 1 into a tensor's shape.</p> <p><a href="tf/expm1"><code>expm1(...)</code></a>: Computes exponential of x - 1 element-wise.</p> <p><a href="tf/extract_image_patches"><code>extract_image_patches(...)</code></a>: Extract <code>patches</code> from <code>images</code> and put them in the "depth" output dimension.</p> <p><a href="tf/eye"><code>eye(...)</code></a>: Construct an identity matrix, or a batch of matrices.</p> <p><a href="tf/fake_quant_with_min_max_args"><code>fake_quant_with_min_max_args(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p> <p><a href="tf/fake_quant_with_min_max_args_gradient"><code>fake_quant_with_min_max_args_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="tf/fake_quant_with_min_max_vars"><code>fake_quant_with_min_max_vars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars <code>min</code></p> <p><a href="tf/fake_quant_with_min_max_vars_gradient"><code>fake_quant_with_min_max_vars_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="tf/fake_quant_with_min_max_vars_per_channel"><code>fake_quant_with_min_max_vars_per_channel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float and one of the shapes: <code>[d]</code>,</p> <p><a href="tf/fake_quant_with_min_max_vars_per_channel_gradient"><code>fake_quant_with_min_max_vars_per_channel_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="tf/fft"><code>fft(...)</code></a>: Fast Fourier transform.</p> <p><a href="tf/fft2d"><code>fft2d(...)</code></a>: 2D fast Fourier transform.</p> <p><a href="tf/fft3d"><code>fft3d(...)</code></a>: 3D fast Fourier transform.</p> <p><a href="tf/fill"><code>fill(...)</code></a>: Creates a tensor filled with a scalar value.</p> <p><a href="tf/fixed_size_partitioner"><code>fixed_size_partitioner(...)</code></a>: Partitioner to specify a fixed number of shards along given axis.</p> <p><a href="tf/floor"><code>floor(...)</code></a>: Returns element-wise largest integer not greater than x.</p> <p><a href="tf/floor_div"><code>floor_div(...)</code></a>: Returns x // y element-wise.</p> <p><a href="tf/floordiv"><code>floordiv(...)</code></a>: Divides <code>x / y</code> elementwise, rounding toward the most negative integer.</p> <p><a href="tf/floormod"><code>floormod(...)</code></a>: Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p> <p><a href="tf/foldl"><code>foldl(...)</code></a>: foldl on the list of tensors unpacked from <code>elems</code> on dimension 0.</p> <p><a href="tf/foldr"><code>foldr(...)</code></a>: foldr on the list of tensors unpacked from <code>elems</code> on dimension 0.</p> <p><a href="tf/gather"><code>gather(...)</code></a>: Gather slices from <code>params</code> axis <code>axis</code> according to <code>indices</code>.</p> <p><a href="tf/gather_nd"><code>gather_nd(...)</code></a>: Gather slices from <code>params</code> into a Tensor with shape specified by <code>indices</code>.</p> <p><a href="tf/get_collection"><code>get_collection(...)</code></a>: Wrapper for <code>Graph.get_collection()</code> using the default graph.</p> <p><a href="tf/get_collection_ref"><code>get_collection_ref(...)</code></a>: Wrapper for <code>Graph.get_collection_ref()</code> using the default graph.</p> <p><a href="tf/get_default_graph"><code>get_default_graph(...)</code></a>: Returns the default graph for the current thread.</p> <p><a href="tf/get_default_session"><code>get_default_session(...)</code></a>: Returns the default session for the current thread.</p> <p><a href="tf/get_local_variable"><code>get_local_variable(...)</code></a>: Gets an existing <em>local</em> variable or creates a new one.</p> <p><a href="tf/get_seed"><code>get_seed(...)</code></a>: Returns the local seeds an operation should use given an op-specific seed.</p> <p><a href="tf/get_session_handle"><code>get_session_handle(...)</code></a>: Return the handle of <code>data</code>.</p> <p><a href="tf/get_session_tensor"><code>get_session_tensor(...)</code></a>: Get the tensor of type <code>dtype</code> by feeding a tensor handle.</p> <p><a href="tf/get_variable"><code>get_variable(...)</code></a>: Gets an existing variable with these parameters or create a new one.</p> <p><a href="tf/get_variable_scope"><code>get_variable_scope(...)</code></a>: Returns the current variable scope.</p> <p><a href="tf/global_norm"><code>global_norm(...)</code></a>: Computes the global norm of multiple tensors.</p> <p><a href="tf/global_variables"><code>global_variables(...)</code></a>: Returns global variables.</p> <p><a href="tf/global_variables_initializer"><code>global_variables_initializer(...)</code></a>: Returns an Op that initializes global variables.</p> <p><a href="tf/glorot_normal_initializer"><code>glorot_normal_initializer(...)</code></a>: The Glorot normal initializer, also called Xavier normal initializer.</p> <p><a href="tf/glorot_uniform_initializer"><code>glorot_uniform_initializer(...)</code></a>: The Glorot uniform initializer, also called Xavier uniform initializer.</p> <p><a href="tf/gradients"><code>gradients(...)</code></a>: Constructs symbolic derivatives of sum of <code>ys</code> w.r.t. x in <code>xs</code>.</p> <p><a href="tf/greater"><code>greater(...)</code></a>: Returns the truth value of (x &gt; y) element-wise.</p> <p><a href="tf/greater_equal"><code>greater_equal(...)</code></a>: Returns the truth value of (x &gt;= y) element-wise.</p> <p><a href="tf/group"><code>group(...)</code></a>: Create an op that groups multiple operations.</p> <p><a href="tf/guarantee_const"><code>guarantee_const(...)</code></a>: Gives a guarantee to the TF runtime that the input tensor is a constant.</p> <p><a href="tf/hessians"><code>hessians(...)</code></a>: Constructs the Hessian of sum of <code>ys</code> with respect to <code>x</code> in <code>xs</code>.</p> <p><a href="tf/histogram_fixed_width"><code>histogram_fixed_width(...)</code></a>: Return histogram of values.</p> <p><a href="tf/histogram_fixed_width_bins"><code>histogram_fixed_width_bins(...)</code></a>: Bins the given values for use in a histogram.</p> <p><a href="tf/identity"><code>identity(...)</code></a>: Return a tensor with the same shape and contents as input.</p> <p><a href="tf/identity_n"><code>identity_n(...)</code></a>: Returns a list of tensors with the same shapes and contents as the input</p> <p><a href="tf/ifft"><code>ifft(...)</code></a>: Inverse fast Fourier transform.</p> <p><a href="tf/ifft2d"><code>ifft2d(...)</code></a>: Inverse 2D fast Fourier transform.</p> <p><a href="tf/ifft3d"><code>ifft3d(...)</code></a>: Inverse 3D fast Fourier transform.</p> <p><a href="tf/igamma"><code>igamma(...)</code></a>: Compute the lower regularized incomplete Gamma function <code>Q(a, x)</code>.</p> <p><a href="tf/igammac"><code>igammac(...)</code></a>: Compute the upper regularized incomplete Gamma function <code>Q(a, x)</code>.</p> <p><a href="tf/imag"><code>imag(...)</code></a>: Returns the imaginary part of a complex (or real) tensor.</p> <p><a href="tf/import_graph_def"><code>import_graph_def(...)</code></a>: Imports the graph from <code>graph_def</code> into the current default <code>Graph</code>. (deprecated arguments)</p> <p><a href="tf/initialize_all_tables"><code>initialize_all_tables(...)</code></a>: Returns an Op that initializes all tables of the default graph. (deprecated)</p> <p><a href="tf/initialize_all_variables"><code>initialize_all_variables(...)</code></a>: See <a href="tf/global_variables_initializer"><code>tf.global_variables_initializer</code></a>. (deprecated)</p> <p><a href="tf/initialize_local_variables"><code>initialize_local_variables(...)</code></a>: See <a href="tf/local_variables_initializer"><code>tf.local_variables_initializer</code></a>. (deprecated)</p> <p><a href="tf/initialize_variables"><code>initialize_variables(...)</code></a>: See <a href="tf/variables_initializer"><code>tf.variables_initializer</code></a>. (deprecated)</p> <p><a href="tf/invert_permutation"><code>invert_permutation(...)</code></a>: Computes the inverse permutation of a tensor.</p> <p><a href="tf/is_finite"><code>is_finite(...)</code></a>: Returns which elements of x are finite.</p> <p><a href="tf/is_inf"><code>is_inf(...)</code></a>: Returns which elements of x are Inf.</p> <p><a href="tf/is_nan"><code>is_nan(...)</code></a>: Returns which elements of x are NaN.</p> <p><a href="tf/is_non_decreasing"><code>is_non_decreasing(...)</code></a>: Returns <code>True</code> if <code>x</code> is non-decreasing.</p> <p><a href="tf/is_numeric_tensor"><code>is_numeric_tensor(...)</code></a></p> <p><a href="tf/is_strictly_increasing"><code>is_strictly_increasing(...)</code></a>: Returns <code>True</code> if <code>x</code> is strictly increasing.</p> <p><a href="tf/is_variable_initialized"><code>is_variable_initialized(...)</code></a>: Tests if a variable has been initialized.</p> <p><a href="tf/lbeta"><code>lbeta(...)</code></a>: Computes \(ln(|Beta(x)|)\), reducing along the last dimension.</p> <p><a href="tf/less"><code>less(...)</code></a>: Returns the truth value of (x &lt; y) element-wise.</p> <p><a href="tf/less_equal"><code>less_equal(...)</code></a>: Returns the truth value of (x &lt;= y) element-wise.</p> <p><a href="tf/lgamma"><code>lgamma(...)</code></a>: Computes the log of the absolute value of <code>Gamma(x)</code> element-wise.</p> <p><a href="tf/lin_space"><code>lin_space(...)</code></a>: Generates values in an interval.</p> <p><a href="tf/lin_space"><code>linspace(...)</code></a>: Generates values in an interval.</p> <p><a href="tf/load_file_system_library"><code>load_file_system_library(...)</code></a>: Loads a TensorFlow plugin, containing file system implementation.</p> <p><a href="tf/load_op_library"><code>load_op_library(...)</code></a>: Loads a TensorFlow plugin, containing custom ops and kernels.</p> <p><a href="tf/local_variables"><code>local_variables(...)</code></a>: Returns local variables.</p> <p><a href="tf/local_variables_initializer"><code>local_variables_initializer(...)</code></a>: Returns an Op that initializes all local variables.</p> <p><a href="tf/log"><code>log(...)</code></a>: Computes natural logarithm of x element-wise.</p> <p><a href="tf/log1p"><code>log1p(...)</code></a>: Computes natural logarithm of (1 + x) element-wise.</p> <p><a href="tf/log_sigmoid"><code>log_sigmoid(...)</code></a>: Computes log sigmoid of <code>x</code> element-wise.</p> <p><a href="tf/logical_and"><code>logical_and(...)</code></a>: Returns the truth value of x AND y element-wise.</p> <p><a href="tf/logical_not"><code>logical_not(...)</code></a>: Returns the truth value of NOT x element-wise.</p> <p><a href="tf/logical_or"><code>logical_or(...)</code></a>: Returns the truth value of x OR y element-wise.</p> <p><a href="tf/logical_xor"><code>logical_xor(...)</code></a>: x ^ y = (x | y) &amp; ~(x &amp; y).</p> <p><a href="tf/make_ndarray"><code>make_ndarray(...)</code></a>: Create a numpy ndarray from a tensor.</p> <p><a href="tf/make_template"><code>make_template(...)</code></a>: Given an arbitrary function, wrap it so that it does variable sharing.</p> <p><a href="tf/make_tensor_proto"><code>make_tensor_proto(...)</code></a>: Create a TensorProto.</p> <p><a href="tf/map_fn"><code>map_fn(...)</code></a>: map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p> <p><a href="tf/matching_files"><code>matching_files(...)</code></a>: Returns the set of files matching one or more glob patterns.</p> <p><a href="tf/matmul"><code>matmul(...)</code></a>: Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p> <p><a href="tf/matrix_band_part"><code>matrix_band_part(...)</code></a>: Copy a tensor setting everything outside a central band in each innermost matrix</p> <p><a href="tf/matrix_determinant"><code>matrix_determinant(...)</code></a>: Computes the determinant of one or more square matrices.</p> <p><a href="tf/matrix_diag"><code>matrix_diag(...)</code></a>: Returns a batched diagonal tensor with a given batched diagonal values.</p> <p><a href="tf/matrix_diag_part"><code>matrix_diag_part(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="tf/matrix_inverse"><code>matrix_inverse(...)</code></a>: Computes the inverse of one or more square invertible matrices or their</p> <p><a href="tf/matrix_set_diag"><code>matrix_set_diag(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="tf/matrix_solve"><code>matrix_solve(...)</code></a>: Solves systems of linear equations.</p> <p><a href="tf/matrix_solve_ls"><code>matrix_solve_ls(...)</code></a>: Solves one or more linear least-squares problems.</p> <p><a href="tf/matrix_transpose"><code>matrix_transpose(...)</code></a>: Transposes last two dimensions of tensor <code>a</code>.</p> <p><a href="tf/matrix_triangular_solve"><code>matrix_triangular_solve(...)</code></a>: Solves systems of linear equations with upper or lower triangular matrices by</p> <p><a href="tf/maximum"><code>maximum(...)</code></a>: Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</p> <p><a href="tf/meshgrid"><code>meshgrid(...)</code></a>: Broadcasts parameters for evaluation on an N-D grid.</p> <p><a href="tf/min_max_variable_partitioner"><code>min_max_variable_partitioner(...)</code></a>: Partitioner to allocate minimum size per slice.</p> <p><a href="tf/minimum"><code>minimum(...)</code></a>: Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</p> <p><a href="tf/floormod"><code>mod(...)</code></a>: Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p> <p><a href="tf/model_variables"><code>model_variables(...)</code></a>: Returns all variables in the MODEL_VARIABLES collection.</p> <p><a href="tf/moving_average_variables"><code>moving_average_variables(...)</code></a>: Returns all variables that maintain their moving averages.</p> <p><a href="tf/multinomial"><code>multinomial(...)</code></a>: Draws samples from a multinomial distribution.</p> <p><a href="tf/multiply"><code>multiply(...)</code></a>: Returns x * y element-wise.</p> <p><a href="tf/negative"><code>negative(...)</code></a>: Computes numerical negative value element-wise.</p> <p><a href="tf/no_op"><code>no_op(...)</code></a>: Does nothing. Only useful as a placeholder for control edges.</p> <p><a href="tf/no_regularizer"><code>no_regularizer(...)</code></a>: Use this function to prevent regularization of variables.</p> <p><a href="tf/norm"><code>norm(...)</code></a>: Computes the norm of vectors, matrices, and tensors. (deprecated arguments)</p> <p><a href="tf/not_equal"><code>not_equal(...)</code></a>: Returns the truth value of (x != y) element-wise.</p> <p><a href="tf/one_hot"><code>one_hot(...)</code></a>: Returns a one-hot tensor.</p> <p><a href="tf/ones"><code>ones(...)</code></a>: Creates a tensor with all elements set to 1.</p> <p><a href="tf/ones_like"><code>ones_like(...)</code></a>: Creates a tensor with all elements set to 1.</p> <p><a href="tf/op_scope"><code>op_scope(...)</code></a>: DEPRECATED. Same as name_scope above, just different argument order.</p> <p><a href="tf/pad"><code>pad(...)</code></a>: Pads a tensor.</p> <p><a href="tf/parallel_stack"><code>parallel_stack(...)</code></a>: Stacks a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor in parallel.</p> <p><a href="tf/parse_example"><code>parse_example(...)</code></a>: Parses <code>Example</code> protos into a <code>dict</code> of tensors.</p> <p><a href="tf/parse_single_example"><code>parse_single_example(...)</code></a>: Parses a single <code>Example</code> proto.</p> <p><a href="tf/parse_single_sequence_example"><code>parse_single_sequence_example(...)</code></a>: Parses a single <code>SequenceExample</code> proto.</p> <p><a href="tf/parse_tensor"><code>parse_tensor(...)</code></a>: Transforms a serialized tensorflow.TensorProto proto into a Tensor.</p> <p><a href="tf/placeholder"><code>placeholder(...)</code></a>: Inserts a placeholder for a tensor that will be always fed.</p> <p><a href="tf/placeholder_with_default"><code>placeholder_with_default(...)</code></a>: A placeholder op that passes through <code>input</code> when its output is not fed.</p> <p><a href="tf/polygamma"><code>polygamma(...)</code></a>: Compute the polygamma function \(\psi^{(n)} (x)\).</p> <p><a href="tf/pow"><code>pow(...)</code></a>: Computes the power of one value to another.</p> <p><a href="tf/py_func"><code>py_func(...)</code></a>: Wraps a python function and uses it as a TensorFlow op.</p> <p><a href="tf/qr"><code>qr(...)</code></a>: Computes the QR decompositions of one or more matrices.</p> <p><a href="tf/quantize"><code>quantize(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="tf/quantize_v2"><code>quantize_v2(...)</code></a>: Please use <a href="tf/quantize"><code>tf.quantize</code></a> instead.</p> <p><a href="tf/quantized_concat"><code>quantized_concat(...)</code></a>: Concatenates quantized tensors along one dimension.</p> <p><a href="tf/random_crop"><code>random_crop(...)</code></a>: Randomly crops a tensor to a given size.</p> <p><a href="tf/random_gamma"><code>random_gamma(...)</code></a>: Draws <code>shape</code> samples from each of the given Gamma distribution(s).</p> <p><a href="tf/random_normal"><code>random_normal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="tf/random_poisson"><code>random_poisson(...)</code></a>: Draws <code>shape</code> samples from each of the given Poisson distribution(s).</p> <p><a href="tf/random_shuffle"><code>random_shuffle(...)</code></a>: Randomly shuffles a tensor along its first dimension.</p> <p><a href="tf/random_uniform"><code>random_uniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="tf/range"><code>range(...)</code></a>: Creates a sequence of numbers.</p> <p><a href="tf/rank"><code>rank(...)</code></a>: Returns the rank of a tensor.</p> <p><a href="tf/read_file"><code>read_file(...)</code></a>: Reads and outputs the entire contents of the input filename.</p> <p><a href="tf/real"><code>real(...)</code></a>: Returns the real part of a complex (or real) tensor.</p> <p><a href="tf/realdiv"><code>realdiv(...)</code></a>: Returns x / y element-wise for real types.</p> <p><a href="tf/reciprocal"><code>reciprocal(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="tf/reduce_all"><code>reduce_all(...)</code></a>: Computes the "logical and" of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_any"><code>reduce_any(...)</code></a>: Computes the "logical or" of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_join"><code>reduce_join(...)</code></a>: Joins a string Tensor across the given dimensions.</p> <p><a href="tf/reduce_logsumexp"><code>reduce_logsumexp(...)</code></a>: Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)</p> <p><a href="tf/reduce_max"><code>reduce_max(...)</code></a>: Computes the maximum of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_mean"><code>reduce_mean(...)</code></a>: Computes the mean of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_min"><code>reduce_min(...)</code></a>: Computes the minimum of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_prod"><code>reduce_prod(...)</code></a>: Computes the product of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/reduce_sum"><code>reduce_sum(...)</code></a>: Computes the sum of elements across dimensions of a tensor. (deprecated arguments)</p> <p><a href="tf/regex_replace"><code>regex_replace(...)</code></a>: Replaces the match of pattern in input with rewrite.</p> <p><a href="tf/register_tensor_conversion_function"><code>register_tensor_conversion_function(...)</code></a>: Registers a function for converting objects of <code>base_type</code> to <code>Tensor</code>.</p> <p><a href="tf/report_uninitialized_variables"><code>report_uninitialized_variables(...)</code></a>: Adds ops to list the names of uninitialized variables.</p> <p><a href="tf/required_space_to_batch_paddings"><code>required_space_to_batch_paddings(...)</code></a>: Calculate padding required to make block_shape divide input_shape.</p> <p><a href="tf/reset_default_graph"><code>reset_default_graph(...)</code></a>: Clears the default graph stack and resets the global default graph.</p> <p><a href="tf/reshape"><code>reshape(...)</code></a>: Reshapes a tensor.</p> <p><a href="tf/reverse"><code>reverse(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="tf/reverse_sequence"><code>reverse_sequence(...)</code></a>: Reverses variable length slices.</p> <p><a href="tf/reverse_v2"><code>reverse_v2(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="tf/rint"><code>rint(...)</code></a>: Returns element-wise integer closest to x.</p> <p><a href="tf/round"><code>round(...)</code></a>: Rounds the values of a tensor to the nearest integer, element-wise.</p> <p><a href="tf/rsqrt"><code>rsqrt(...)</code></a>: Computes reciprocal of square root of x element-wise.</p> <p><a href="tf/saturate_cast"><code>saturate_cast(...)</code></a>: Performs a safe saturating cast of <code>value</code> to <code>dtype</code>.</p> <p><a href="tf/scalar_mul"><code>scalar_mul(...)</code></a>: Multiplies a scalar times a <code>Tensor</code> or <code>IndexedSlices</code> object.</p> <p><a href="tf/scan"><code>scan(...)</code></a>: scan on the list of tensors unpacked from <code>elems</code> on dimension 0.</p> <p><a href="tf/scatter_add"><code>scatter_add(...)</code></a>: Adds sparse updates to the variable referenced by <code>resource</code>.</p> <p><a href="tf/scatter_div"><code>scatter_div(...)</code></a>: Divides a variable reference by sparse updates.</p> <p><a href="tf/scatter_max"><code>scatter_max(...)</code></a>: Reduces sparse updates into a variable reference using the <code>max</code> operation.</p> <p><a href="tf/scatter_min"><code>scatter_min(...)</code></a>: Reduces sparse updates into a variable reference using the <code>min</code> operation.</p> <p><a href="tf/scatter_mul"><code>scatter_mul(...)</code></a>: Multiplies sparse updates into a variable reference.</p> <p><a href="tf/scatter_nd"><code>scatter_nd(...)</code></a>: Scatter <code>updates</code> into a new (initially zero) tensor according to <code>indices</code>.</p> <p><a href="tf/scatter_nd_add"><code>scatter_nd_add(...)</code></a>: Applies sparse addition between <code>updates</code> and individual values or slices</p> <p><a href="tf/scatter_nd_sub"><code>scatter_nd_sub(...)</code></a>: Applies sparse subtraction between <code>updates</code> and individual values or slices</p> <p><a href="tf/scatter_nd_update"><code>scatter_nd_update(...)</code></a>: Applies sparse <code>updates</code> to individual values or slices in a Variable.</p> <p><a href="tf/scatter_sub"><code>scatter_sub(...)</code></a>: Subtracts sparse updates to a variable reference.</p> <p><a href="tf/scatter_update"><code>scatter_update(...)</code></a>: Applies sparse updates to a variable reference.</p> <p><a href="tf/segment_max"><code>segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="tf/segment_mean"><code>segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="tf/segment_min"><code>segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="tf/segment_prod"><code>segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="tf/segment_sum"><code>segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="tf/self_adjoint_eig"><code>self_adjoint_eig(...)</code></a>: Computes the eigen decomposition of a batch of self-adjoint matrices.</p> <p><a href="tf/self_adjoint_eigvals"><code>self_adjoint_eigvals(...)</code></a>: Computes the eigenvalues of one or more self-adjoint matrices.</p> <p><a href="tf/sequence_mask"><code>sequence_mask(...)</code></a>: Returns a mask tensor representing the first N positions of each cell.</p> <p><a href="tf/serialize_many_sparse"><code>serialize_many_sparse(...)</code></a>: Serialize <code>N</code>-minibatch <code>SparseTensor</code> into an <code>[N, 3]</code> <code>Tensor</code>.</p> <p><a href="tf/serialize_sparse"><code>serialize_sparse(...)</code></a>: Serialize a <code>SparseTensor</code> into a 3-vector (1-D <code>Tensor</code>) object.</p> <p><a href="tf/serialize_tensor"><code>serialize_tensor(...)</code></a>: Transforms a Tensor into a serialized TensorProto proto.</p> <p><a href="tf/set_random_seed"><code>set_random_seed(...)</code></a>: Sets the graph-level random seed.</p> <p><a href="tf/setdiff1d"><code>setdiff1d(...)</code></a>: Computes the difference between two lists of numbers or strings.</p> <p><a href="tf/shape"><code>shape(...)</code></a>: Returns the shape of a tensor.</p> <p><a href="tf/shape_n"><code>shape_n(...)</code></a>: Returns shape of tensors.</p> <p><a href="tf/sigmoid"><code>sigmoid(...)</code></a>: Computes sigmoid of <code>x</code> element-wise.</p> <p><a href="tf/sign"><code>sign(...)</code></a>: Returns an element-wise indication of the sign of a number.</p> <p><a href="tf/sin"><code>sin(...)</code></a>: Computes sin of x element-wise.</p> <p><a href="tf/sinh"><code>sinh(...)</code></a>: Computes hyperbolic sine of x element-wise.</p> <p><a href="tf/size"><code>size(...)</code></a>: Returns the size of a tensor.</p> <p><a href="tf/slice"><code>slice(...)</code></a>: Extracts a slice from a tensor.</p> <p><a href="tf/space_to_batch"><code>space_to_batch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p> <p><a href="tf/space_to_batch_nd"><code>space_to_batch_nd(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="tf/space_to_depth"><code>space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="tf/sparse_add"><code>sparse_add(...)</code></a>: Adds two tensors, at least one of each is a <code>SparseTensor</code>.</p> <p><a href="tf/sparse_concat"><code>sparse_concat(...)</code></a>: Concatenates a list of <code>SparseTensor</code> along the specified dimension.</p> <p><a href="tf/sparse_fill_empty_rows"><code>sparse_fill_empty_rows(...)</code></a>: Fills empty rows in the input 2-D <code>SparseTensor</code> with a default value.</p> <p><a href="tf/sparse_mask"><code>sparse_mask(...)</code></a>: Masks elements of <code>IndexedSlices</code>.</p> <p><a href="tf/sparse_matmul"><code>sparse_matmul(...)</code></a>: Multiply matrix "a" by matrix "b".</p> <p><a href="tf/sparse_maximum"><code>sparse_maximum(...)</code></a>: Returns the element-wise max of two SparseTensors.</p> <p><a href="tf/sparse_merge"><code>sparse_merge(...)</code></a>: Combines a batch of feature ids and values into a single <code>SparseTensor</code>.</p> <p><a href="tf/sparse_minimum"><code>sparse_minimum(...)</code></a>: Returns the element-wise min of two SparseTensors.</p> <p><a href="tf/sparse_placeholder"><code>sparse_placeholder(...)</code></a>: Inserts a placeholder for a sparse tensor that will be always fed.</p> <p><a href="tf/sparse_reduce_max"><code>sparse_reduce_max(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="tf/sparse_reduce_max_sparse"><code>sparse_reduce_max_sparse(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="tf/sparse_reduce_sum"><code>sparse_reduce_sum(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="tf/sparse_reduce_sum_sparse"><code>sparse_reduce_sum_sparse(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="tf/sparse_reorder"><code>sparse_reorder(...)</code></a>: Reorders a <code>SparseTensor</code> into the canonical, row-major ordering.</p> <p><a href="tf/sparse_reset_shape"><code>sparse_reset_shape(...)</code></a>: Resets the shape of a <code>SparseTensor</code> with indices and values unchanged.</p> <p><a href="tf/sparse_reshape"><code>sparse_reshape(...)</code></a>: Reshapes a <code>SparseTensor</code> to represent values in a new dense shape.</p> <p><a href="tf/sparse_retain"><code>sparse_retain(...)</code></a>: Retains specified non-empty values within a <code>SparseTensor</code>.</p> <p><a href="tf/sparse_segment_mean"><code>sparse_segment_mean(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="tf/sparse_segment_sqrt_n"><code>sparse_segment_sqrt_n(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt(N).</p> <p><a href="tf/sparse_segment_sum"><code>sparse_segment_sum(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="tf/sparse_slice"><code>sparse_slice(...)</code></a>: Slice a <code>SparseTensor</code> based on the <code>start</code> and `size.</p> <p><a href="tf/sparse_softmax"><code>sparse_softmax(...)</code></a>: Applies softmax to a batched N-D <code>SparseTensor</code>.</p> <p><a href="tf/sparse_split"><code>sparse_split(...)</code></a>: Split a <code>SparseTensor</code> into <code>num_split</code> tensors along <code>axis</code>.</p> <p><a href="tf/sparse_tensor_dense_matmul"><code>sparse_tensor_dense_matmul(...)</code></a>: Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p> <p><a href="tf/sparse_tensor_to_dense"><code>sparse_tensor_to_dense(...)</code></a>: Converts a <code>SparseTensor</code> into a dense tensor.</p> <p><a href="tf/sparse_to_dense"><code>sparse_to_dense(...)</code></a>: Converts a sparse representation into a dense tensor.</p> <p><a href="tf/sparse_to_indicator"><code>sparse_to_indicator(...)</code></a>: Converts a <code>SparseTensor</code> of ids into a dense bool indicator tensor.</p> <p><a href="tf/sparse_transpose"><code>sparse_transpose(...)</code></a>: Transposes a <code>SparseTensor</code></p> <p><a href="tf/split"><code>split(...)</code></a>: Splits a tensor into sub tensors.</p> <p><a href="tf/sqrt"><code>sqrt(...)</code></a>: Computes square root of x element-wise.</p> <p><a href="tf/square"><code>square(...)</code></a>: Computes square of x element-wise.</p> <p><a href="tf/squared_difference"><code>squared_difference(...)</code></a>: Returns (x - y)(x - y) element-wise.</p> <p><a href="tf/squeeze"><code>squeeze(...)</code></a>: Removes dimensions of size 1 from the shape of a tensor.</p> <p><a href="tf/stack"><code>stack(...)</code></a>: Stacks a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor.</p> <p><a href="tf/stop_gradient"><code>stop_gradient(...)</code></a>: Stops gradient computation.</p> <p><a href="tf/strided_slice"><code>strided_slice(...)</code></a>: Extracts a strided slice of a tensor (generalized python array indexing).</p> <p><a href="tf/string_join"><code>string_join(...)</code></a>: Joins the strings in the given list of string tensors into one tensor;</p> <p><a href="tf/string_split"><code>string_split(...)</code></a>: Split elements of <code>source</code> based on <code>delimiter</code> into a <code>SparseTensor</code>.</p> <p><a href="tf/string_to_hash_bucket"><code>string_to_hash_bucket(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="tf/string_to_hash_bucket_fast"><code>string_to_hash_bucket_fast(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="tf/string_to_hash_bucket_strong"><code>string_to_hash_bucket_strong(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="tf/string_to_number"><code>string_to_number(...)</code></a>: Converts each string in the input Tensor to the specified numeric type.</p> <p><a href="tf/substr"><code>substr(...)</code></a>: Return substrings from <code>Tensor</code> of strings.</p> <p><a href="tf/subtract"><code>subtract(...)</code></a>: Returns x - y element-wise.</p> <p><a href="tf/svd"><code>svd(...)</code></a>: Computes the singular value decompositions of one or more matrices.</p> <p><a href="tf/tables_initializer"><code>tables_initializer(...)</code></a>: Returns an Op that initializes all tables of the default graph.</p> <p><a href="tf/tan"><code>tan(...)</code></a>: Computes tan of x element-wise.</p> <p><a href="tf/tanh"><code>tanh(...)</code></a>: Computes hyperbolic tangent of <code>x</code> element-wise.</p> <p><a href="tf/tensordot"><code>tensordot(...)</code></a>: Tensor contraction of a and b along specified axes.</p> <p><a href="tf/tile"><code>tile(...)</code></a>: Constructs a tensor by tiling a given tensor.</p> <p><a href="tf/timestamp"><code>timestamp(...)</code></a>: Provides the time since epoch in seconds.</p> <p><a href="tf/to_bfloat16"><code>to_bfloat16(...)</code></a>: Casts a tensor to type <code>bfloat16</code>.</p> <p><a href="tf/to_complex128"><code>to_complex128(...)</code></a>: Casts a tensor to type <code>complex128</code>.</p> <p><a href="tf/to_complex64"><code>to_complex64(...)</code></a>: Casts a tensor to type <code>complex64</code>.</p> <p><a href="tf/to_double"><code>to_double(...)</code></a>: Casts a tensor to type <code>float64</code>.</p> <p><a href="tf/to_float"><code>to_float(...)</code></a>: Casts a tensor to type <code>float32</code>.</p> <p><a href="tf/to_int32"><code>to_int32(...)</code></a>: Casts a tensor to type <code>int32</code>.</p> <p><a href="tf/to_int64"><code>to_int64(...)</code></a>: Casts a tensor to type <code>int64</code>.</p> <p><a href="tf/trace"><code>trace(...)</code></a>: Compute the trace of a tensor <code>x</code>.</p> <p><a href="tf/trainable_variables"><code>trainable_variables(...)</code></a>: Returns all variables created with <code>trainable=True</code>.</p> <p><a href="tf/transpose"><code>transpose(...)</code></a>: Transposes <code>a</code>. Permutes the dimensions according to <code>perm</code>.</p> <p><a href="tf/truediv"><code>truediv(...)</code></a>: Divides x / y elementwise (using Python 3 division operator semantics).</p> <p><a href="tf/truncated_normal"><code>truncated_normal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="tf/truncatediv"><code>truncatediv(...)</code></a>: Returns x / y element-wise for integer types.</p> <p><a href="tf/truncatemod"><code>truncatemod(...)</code></a>: Returns element-wise remainder of division. This emulates C semantics in that</p> <p><a href="tf/tuple"><code>tuple(...)</code></a>: Group tensors together.</p> <p><a href="tf/unique"><code>unique(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="tf/unique_with_counts"><code>unique_with_counts(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="tf/unravel_index"><code>unravel_index(...)</code></a>: Converts a flat index or array of flat indices into a tuple of</p> <p><a href="tf/unsorted_segment_max"><code>unsorted_segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="tf/unsorted_segment_mean"><code>unsorted_segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="tf/unsorted_segment_min"><code>unsorted_segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="tf/unsorted_segment_prod"><code>unsorted_segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="tf/unsorted_segment_sqrt_n"><code>unsorted_segment_sqrt_n(...)</code></a>: Computes the sum along segments of a tensor divided by the sqrt(N).</p> <p><a href="tf/unsorted_segment_sum"><code>unsorted_segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="tf/unstack"><code>unstack(...)</code></a>: Unpacks the given dimension of a rank-<code>R</code> tensor into rank-<code>(R-1)</code> tensors.</p> <p><a href="tf/variable_axis_size_partitioner"><code>variable_axis_size_partitioner(...)</code></a>: Get a partitioner for VariableScope to keep shards below <code>max_shard_bytes</code>.</p> <p><a href="tf/variable_op_scope"><code>variable_op_scope(...)</code></a>: Deprecated: context manager for defining an op that creates variables.</p> <p><a href="tf/variables_initializer"><code>variables_initializer(...)</code></a>: Returns an Op that initializes a list of variables.</p> <p><a href="tf/verify_tensor_all_finite"><code>verify_tensor_all_finite(...)</code></a>: Assert that the tensor does not contain any NaN's or Inf's.</p> <p><a href="tf/where"><code>where(...)</code></a>: Return the elements, either from <code>x</code> or <code>y</code>, depending on the <code>condition</code>.</p> <p><a href="tf/while_loop"><code>while_loop(...)</code></a>: Repeat <code>body</code> while the condition <code>cond</code> is true.</p> <p><a href="tf/write_file"><code>write_file(...)</code></a>: Writes contents to the file at input filename. Creates file and recursively</p> <p><a href="tf/zeros"><code>zeros(...)</code></a>: Creates a tensor with all elements set to zero.</p> <p><a href="tf/zeros_like"><code>zeros_like(...)</code></a>: Creates a tensor with all elements set to zero.</p> <p><a href="tf/zeta"><code>zeta(...)</code></a>: Compute the Hurwitz zeta function \(\zeta(x, q)\).</p> <h2 id="other_members">Other Members</h2> <p><code>AUTO_REUSE</code></p> <p><code>COMPILER_VERSION</code></p> <p><code>CXX11_ABI_FLAG</code></p> <p><code>GIT_VERSION</code></p> <p><code>GRAPH_DEF_VERSION</code></p> <p><code>GRAPH_DEF_VERSION_MIN_CONSUMER</code></p> <p><code>GRAPH_DEF_VERSION_MIN_PRODUCER</code></p> <p><code>MONOLITHIC_BUILD</code></p> <p><code>QUANTIZED_DTYPES</code></p> <p><code>VERSION</code></p> <p><code>__cached__</code></p> <p><code>__compiler_version__</code></p> <p><code>__cxx11_abi_flag__</code></p> <p><code>__git_version__</code></p> <p><code>__loader__</code></p> <p><code>__monolithic_build__</code></p> <p><code>__spec__</code></p> <p><code>__version__</code></p> <p><code>bfloat16</code></p> <p><code>bool</code></p> <p><code>complex128</code></p> <p><code>complex64</code></p> <p><code>double</code></p> <p><code>float16</code></p> <p><code>float32</code></p> <p><code>float64</code></p> <p><code>half</code></p> <p><code>int16</code></p> <p><code>int32</code></p> <p><code>int64</code></p> <p><code>int8</code></p> <p><code>newaxis</code></p> <p><code>qint16</code></p> <p><code>qint32</code></p> <p><code>qint8</code></p> <p><code>quint16</code></p> <p><code>quint8</code></p> <p><code>resource</code></p> <p><code>string</code></p> <p><code>uint16</code></p> <p><code>uint32</code></p> <p><code>uint64</code></p> <p><code>uint8</code></p> <p><code>variant</code></p>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
