
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.keras.preprocessing.image.ImageDataGenerator - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;python&#47;keras&#47;_impl&#47;keras&#47;preprocessing&#47;image.py. ">
  <meta name="keywords" content="tf, keras, preprocessing, image, imagedatagenerator, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/keras/preprocessing/image/imagedatagenerator.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.keras.preprocessing.image.ImageDataGenerator </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.preprocessing.image.ImageDataGenerator"> <meta itemprop="path" content="r1.8"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="fit"> <meta itemprop="property" content="flow"> <meta itemprop="property" content="flow_from_directory"> <meta itemprop="property" content="random_transform"> <meta itemprop="property" content="standardize"> </div> <h2 id="class_imagedatagenerator">Class <code>ImageDataGenerator</code>
</h2> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/keras/_impl/keras/preprocessing/image.py"><code>tensorflow/python/keras/_impl/keras/preprocessing/image.py</code></a>.</p> <p>Generate minibatches of image data with real-time data augmentation.</p> <h4 id="arguments">Arguments:</h4> <ul> <li>
<b><code>featurewise_center</code></b>: set input mean to 0 over the dataset.</li> <li>
<b><code>samplewise_center</code></b>: set each sample mean to 0.</li> <li>
<b><code>featurewise_std_normalization</code></b>: divide inputs by std of the dataset.</li> <li>
<b><code>samplewise_std_normalization</code></b>: divide each input by its std.</li> <li>
<b><code>zca_whitening</code></b>: apply ZCA whitening.</li> <li>
<b><code>zca_epsilon</code></b>: epsilon for ZCA whitening. Default is 1e-6.</li> <li>
<b><code>rotation_range</code></b>: degrees (0 to 180).</li> <li>
<b><code>width_shift_range</code></b>: fraction of total width, if &lt; 1, or pixels if &gt;= 1.</li> <li>
<b><code>height_shift_range</code></b>: fraction of total height, if &lt; 1, or pixels if &gt;= 1.</li> <li>
<b><code>brightness_range</code></b>: the range of brightness to apply</li> <li>
<b><code>shear_range</code></b>: shear intensity (shear angle in degrees).</li> <li>
<b><code>zoom_range</code></b>: amount of zoom. if scalar z, zoom will be randomly picked in the range [1-z, 1+z]. A sequence of two can be passed instead to select this range.</li> <li>
<b><code>channel_shift_range</code></b>: shift range for each channel.</li> <li>
<b><code>fill_mode</code></b>: points outside the boundaries are filled according to the given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default is 'nearest'. Points outside the boundaries of the input are filled according to the given mode: 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k) 'nearest': aaaaaaaa|abcd|dddddddd 'reflect': abcddcba|abcd|dcbaabcd 'wrap': abcdabcd|abcd|abcdabcd</li> <li>
<b><code>cval</code></b>: value used for points outside the boundaries when fill_mode is 'constant'. Default is 0.</li> <li>
<b><code>horizontal_flip</code></b>: whether to randomly flip images horizontally.</li> <li>
<b><code>vertical_flip</code></b>: whether to randomly flip images vertically.</li> <li>
<b><code>rescale</code></b>: rescaling factor. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided. This is applied after the <code>preprocessing_function</code> (if any provided) but before any other transformation.</li> <li>
<b><code>preprocessing_function</code></b>: function that will be implied on each input. The function will run before any other modification on it. The function should take one argument: one image (Numpy tensor with rank 3), and should output a Numpy tensor with the same shape.</li> <li>
<b><code>data_format</code></b>: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode it is at index 3. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be "channels_last".</li> <li>
<b><code>validation_split</code></b>: fraction of images reserved for validation (strictly between 0 and 1).</li> </ul> <h2 id="methods">Methods</h2> <h3 id="__init__"><code>__init__</code></h3> <pre class="prettyprint lang-python" data-language="python">__init__(
    featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    zca_whitening=False,
    zca_epsilon=1e-06,
    rotation_range=0.0,
    width_shift_range=0.0,
    height_shift_range=0.0,
    brightness_range=None,
    shear_range=0.0,
    zoom_range=0.0,
    channel_shift_range=0.0,
    fill_mode='nearest',
    cval=0.0,
    horizontal_flip=False,
    vertical_flip=False,
    rescale=None,
    preprocessing_function=None,
    data_format=None,
    validation_split=0.0
)
</pre> <p>Initialize self. See help(type(self)) for accurate signature.</p> <h3 id="fit"><code>fit</code></h3> <pre class="prettyprint lang-python" data-language="python">fit(
    x,
    augment=False,
    rounds=1,
    seed=None
)
</pre> <p>Fits internal statistics to some sample data.</p> <p>Required for featurewise_center, featurewise_std_normalization and zca_whitening.</p> <h4 id="arguments_1">Arguments:</h4> <ul> <li>
<b><code>x</code></b>: Numpy array, the data to fit on. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, it should have value 3.</li> <li>
<b><code>augment</code></b>: Whether to fit on randomly augmented samples</li> <li>
<b><code>rounds</code></b>: If <code>augment</code>, how many augmentation passes to do over the data</li> <li>
<b><code>seed</code></b>: random seed.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>ValueError</code></b>: in case of invalid input <code>x</code>.</li> <li>
<b><code>ImportError</code></b>: if Scipy is not available.</li> </ul> <h3 id="flow"><code>flow</code></h3> <pre class="prettyprint lang-python" data-language="python">flow(
    x,
    y=None,
    batch_size=32,
    shuffle=True,
    seed=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    subset=None
)
</pre> <h3 id="flow_from_directory"><code>flow_from_directory</code></h3> <pre class="prettyprint lang-python" data-language="python">flow_from_directory(
    directory,
    target_size=(256, 256),
    color_mode='rgb',
    classes=None,
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    follow_links=False,
    subset=None,
    interpolation='nearest'
)
</pre> <h3 id="random_transform"><code>random_transform</code></h3> <pre class="prettyprint lang-python" data-language="python">random_transform(
    x,
    seed=None
)
</pre> <p>Randomly augment a single image tensor.</p> <h4 id="arguments_2">Arguments:</h4> <ul> <li>
<b><code>x</code></b>: 3D tensor, single image.</li> <li>
<b><code>seed</code></b>: random seed.</li> </ul> <h4 id="returns">Returns:</h4> <p>A randomly transformed version of the input (same shape).</p> <h4 id="raises_1">Raises:</h4> <ul> <li>
<b><code>ImportError</code></b>: if Scipy is not available.</li> </ul> <h3 id="standardize"><code>standardize</code></h3> <pre class="prettyprint lang-python" data-language="python">standardize(x)
</pre> <p>Apply the normalization configuration to a batch of inputs.</p> <h4 id="arguments_3">Arguments:</h4> <ul> <li>
<b><code>x</code></b>: batch of inputs to be normalized.</li> </ul> <h4 id="returns_1">Returns:</h4> <p>The inputs, normalized.</p>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
