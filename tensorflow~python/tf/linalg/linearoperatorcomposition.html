
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.linalg.LinearOperatorComposition - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Inherits From&#58; LinearOperator ">
  <meta name="keywords" content="tf, linalg, linearoperatorcomposition, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/linalg/linearoperatorcomposition.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.linalg.LinearOperatorComposition </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.linalg.LinearOperatorComposition"> <meta itemprop="path" content="r1.8"> <meta itemprop="property" content="batch_shape"> <meta itemprop="property" content="domain_dimension"> <meta itemprop="property" content="dtype"> <meta itemprop="property" content="graph_parents"> <meta itemprop="property" content="is_non_singular"> <meta itemprop="property" content="is_positive_definite"> <meta itemprop="property" content="is_self_adjoint"> <meta itemprop="property" content="is_square"> <meta itemprop="property" content="name"> <meta itemprop="property" content="operators"> <meta itemprop="property" content="range_dimension"> <meta itemprop="property" content="shape"> <meta itemprop="property" content="tensor_rank"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="add_to_tensor"> <meta itemprop="property" content="assert_non_singular"> <meta itemprop="property" content="assert_positive_definite"> <meta itemprop="property" content="assert_self_adjoint"> <meta itemprop="property" content="batch_shape_tensor"> <meta itemprop="property" content="determinant"> <meta itemprop="property" content="diag_part"> <meta itemprop="property" content="domain_dimension_tensor"> <meta itemprop="property" content="log_abs_determinant"> <meta itemprop="property" content="matmul"> <meta itemprop="property" content="matvec"> <meta itemprop="property" content="range_dimension_tensor"> <meta itemprop="property" content="shape_tensor"> <meta itemprop="property" content="solve"> <meta itemprop="property" content="solvevec"> <meta itemprop="property" content="tensor_rank_tensor"> <meta itemprop="property" content="to_dense"> <meta itemprop="property" content="trace"> </div> <h2 id="class_linearoperatorcomposition">Class <code>LinearOperatorComposition</code>
</h2> <p>Inherits From: <a href="linearoperator"><code>LinearOperator</code></a></p> <h3 id="aliases">Aliases:</h3> <ul> <li>Class <code>tf.contrib.linalg.LinearOperatorComposition</code>
</li> <li>Class <code>tf.linalg.LinearOperatorComposition</code>
</li> </ul> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/linalg/linear_operator_composition.py"><code>tensorflow/python/ops/linalg/linear_operator_composition.py</code></a>.</p> <p>See the guide: <a href="https://www.tensorflow.org/api_guides/python/contrib.linalg#_LinearOperator_">Linear Algebra (contrib) &gt; <code>LinearOperator</code></a></p> <p>Composes one or more <code>LinearOperators</code>.</p> <p>This operator composes one or more linear operators <code>[op1,...,opJ]</code>, building a new <code>LinearOperator</code> with action defined by:</p> <pre class="prettyprint" data-language="python">op_composed(x) := op1(op2(...(opJ(x)...))
</pre> <p>If <code>opj</code> acts like [batch] matrix <code>Aj</code>, then <code>op_composed</code> acts like the [batch] matrix formed with the multiplication <code>A1 A2...AJ</code>.</p> <p>If <code>opj</code> has shape <code>batch_shape_j + [M_j, N_j]</code>, then we must have <code>N_j = M_{j+1}</code>, in which case the composed operator has shape equal to <code>broadcast_batch_shape + [M_1, N_J]</code>, where <code>broadcast_batch_shape</code> is the mutual broadcast of <code>batch_shape_j</code>, <code>j = 1,...,J</code>, assuming the intermediate batch shapes broadcast. Even if the composed shape is well defined, the composed operator's methods may fail due to lack of broadcasting ability in the defining operators' methods.</p> <pre class="prettyprint lang-python" data-language="python"># Create a 2 x 2 linear operator composed of two 2 x 2 operators.
operator_1 = LinearOperatorFullMatrix([[1., 2.], [3., 4.]])
operator_2 = LinearOperatorFullMatrix([[1., 0.], [0., 1.]])
operator = LinearOperatorComposition([operator_1, operator_2])

operator.to_dense()
==&gt; [[1., 2.]
     [3., 4.]]

operator.shape
==&gt; [2, 2]

operator.log_abs_determinant()
==&gt; scalar Tensor

x = ... Shape [2, 4] Tensor
operator.matmul(x)
==&gt; Shape [2, 4] Tensor

# Create a [2, 3] batch of 4 x 5 linear operators.
matrix_45 = tf.random_normal(shape=[2, 3, 4, 5])
operator_45 = LinearOperatorFullMatrix(matrix)

# Create a [2, 3] batch of 5 x 6 linear operators.
matrix_56 = tf.random_normal(shape=[2, 3, 5, 6])
operator_56 = LinearOperatorFullMatrix(matrix_56)

# Compose to create a [2, 3] batch of 4 x 6 operators.
operator_46 = LinearOperatorComposition([operator_45, operator_56])

# Create a shape [2, 3, 6, 2] vector.
x = tf.random_normal(shape=[2, 3, 6, 2])
operator.matmul(x)
==&gt; Shape [2, 3, 4, 2] Tensor
</pre> <h4 id="performance">Performance</h4> <p>The performance of <code>LinearOperatorComposition</code> on any operation is equal to the sum of the individual operators' operations.</p> <h4 id="matrix_property_hints">Matrix property hints</h4> <p>This <code>LinearOperator</code> is initialized with boolean flags of the form <code>is_X</code>, for <code>X = non_singular, self_adjoint, positive_definite, square</code>. These have the following meaning:</p> <ul> <li>If <code>is_X == True</code>, callers should expect the operator to have the property <code>X</code>. This is a promise that should be fulfilled, but is <em>not</em> a runtime assert. For example, finite floating point precision may result in these promises being violated.</li> <li>If <code>is_X == False</code>, callers should expect the operator to not have <code>X</code>.</li> <li>If <code>is_X == None</code> (the default), callers should have no expectation either way.</li> </ul> <h2 id="properties">Properties</h2> <h3 id="batch_shape"><code>batch_shape</code></h3> <p><code>TensorShape</code> of batch dimensions of this <code>LinearOperator</code>.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>TensorShape([B1,...,Bb])</code>, equivalent to <code>A.get_shape()[:-2]</code></p> <h4 id="returns">Returns:</h4> <p><code>TensorShape</code>, statically determined, may be undefined.</p> <h3 id="domain_dimension"><code>domain_dimension</code></h3> <p>Dimension (in the sense of vector spaces) of the domain of this operator.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p> <h4 id="returns_1">Returns:</h4> <p><code>Dimension</code> object.</p> <h3 id="dtype"><code>dtype</code></h3> <p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>LinearOperator</code>.</p> <h3 id="graph_parents"><code>graph_parents</code></h3> <p>List of graph dependencies of this <code>LinearOperator</code>.</p> <h3 id="is_non_singular"><code>is_non_singular</code></h3> <h3 id="is_positive_definite"><code>is_positive_definite</code></h3> <h3 id="is_self_adjoint"><code>is_self_adjoint</code></h3> <h3 id="is_square"><code>is_square</code></h3> <p>Return <code>True/False</code> depending on if this operator is square.</p> <h3 id="name"><code>name</code></h3> <p>Name prepended to all ops created by this <code>LinearOperator</code>.</p> <h3 id="operators"><code>operators</code></h3> <h3 id="range_dimension"><code>range_dimension</code></h3> <p>Dimension (in the sense of vector spaces) of the range of this operator.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p> <h4 id="returns_2">Returns:</h4> <p><code>Dimension</code> object.</p> <h3 id="shape"><code>shape</code></h3> <p><code>TensorShape</code> of this <code>LinearOperator</code>.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>TensorShape([B1,...,Bb, M, N])</code>, equivalent to <code>A.get_shape()</code>.</p> <h4 id="returns_3">Returns:</h4> <p><code>TensorShape</code>, statically determined, may be undefined.</p> <h3 id="tensor_rank"><code>tensor_rank</code></h3> <p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_4">Returns:</h4> <p>Python integer, or None if the tensor rank is undefined.</p> <h2 id="methods">Methods</h2> <h3 id="__init__"><code>__init__</code></h3> <pre class="prettyprint lang-python" data-language="python">__init__(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
</pre> <p>Initialize a <code>LinearOperatorComposition</code>.</p> <p><code>LinearOperatorComposition</code> is initialized with a list of operators <code>[op_1,...,op_J]</code>. For the <code>matmul</code> method to be well defined, the composition <code>op_i.matmul(op_{i+1}(x))</code> must be defined. Other methods have similar constraints.</p> <h4 id="args_1">Args:</h4> <ul> <li>
<b><code>operators</code></b>: Iterable of <code>LinearOperator</code> objects, each with the same <code>dtype</code> and composable shape.</li> <li>
<b><code>is_non_singular</code></b>: Expect that this operator is non-singular.</li> <li>
<b><code>is_self_adjoint</code></b>: Expect that this operator is equal to its hermitian transpose.</li> <li>
<b><code>is_positive_definite</code></b>: Expect that this operator is positive definite, meaning the quadratic form <code>x^H A x</code> has positive real part for all nonzero <code>x</code>. Note that we do not require the operator to be self-adjoint to be positive-definite. See: https://en.wikipedia.org/wiki/Positive-definite_matrix#Extension_for_non-symmetric_matrices</li> <li>
<b><code>is_square</code></b>: Expect that this operator acts like square [batch] matrices.</li> <li>
<b><code>name</code></b>: A name for this <code>LinearOperator</code>. Default is the individual operators names joined with <code>_o_</code>.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>TypeError</code></b>: If all operators do not have the same <code>dtype</code>.</li> <li>
<b><code>ValueError</code></b>: If <code>operators</code> is empty.</li> </ul> <h3 id="add_to_tensor"><code>add_to_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">add_to_tensor(
    x,
    name='add_to_tensor'
)
</pre> <p>Add matrix represented by this operator to <code>x</code>. Equivalent to <code>A + x</code>.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code>x</code></b>: <code>Tensor</code> with same <code>dtype</code> and shape broadcastable to <code>self.shape</code>.</li> <li>
<b><code>name</code></b>: A name to give this <code>Op</code>.</li> </ul> <h4 id="returns_5">Returns:</h4> <p>A <code>Tensor</code> with broadcast shape and same <code>dtype</code> as <code>self</code>.</p> <h3 id="assert_non_singular"><code>assert_non_singular</code></h3> <pre class="prettyprint lang-python" data-language="python">assert_non_singular(name='assert_non_singular')
</pre> <p>Returns an <code>Op</code> that asserts this operator is non singular.</p> <p>This operator is considered non-singular if</p> <pre class="prettyprint" data-language="python">ConditionNumber &lt; max{100, range_dimension, domain_dimension} * eps,
eps := np.finfo(self.dtype.as_numpy_dtype).eps
</pre> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code>name</code></b>: A string name to prepend to created ops.</li> </ul> <h4 id="returns_6">Returns:</h4> <p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is singular.</p> <h3 id="assert_positive_definite"><code>assert_positive_definite</code></h3> <pre class="prettyprint lang-python" data-language="python">assert_positive_definite(name='assert_positive_definite')
</pre> <p>Returns an <code>Op</code> that asserts this operator is positive definite.</p> <p>Here, positive definite means that the quadratic form <code>x^H A x</code> has positive real part for all nonzero <code>x</code>. Note that we do not require the operator to be self-adjoint to be positive definite.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name to give this <code>Op</code>.</li> </ul> <h4 id="returns_7">Returns:</h4> <p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is not positive definite.</p> <h3 id="assert_self_adjoint"><code>assert_self_adjoint</code></h3> <pre class="prettyprint lang-python" data-language="python">assert_self_adjoint(name='assert_self_adjoint')
</pre> <p>Returns an <code>Op</code> that asserts this operator is self-adjoint.</p> <p>Here we check that this operator is <em>exactly</em> equal to its hermitian transpose.</p> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code>name</code></b>: A string name to prepend to created ops.</li> </ul> <h4 id="returns_8">Returns:</h4> <p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is not self-adjoint.</p> <h3 id="batch_shape_tensor"><code>batch_shape_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">batch_shape_tensor(name='batch_shape_tensor')
</pre> <p>Shape of batch dimensions of this operator, determined at runtime.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding <code>[B1,...,Bb]</code>.</p> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_9">Returns:</h4> <p><code>int32</code> <code>Tensor</code></p> <h3 id="determinant"><code>determinant</code></h3> <pre class="prettyprint lang-python" data-language="python">determinant(name='det')
</pre> <p>Determinant for every batch member.</p> <h4 id="args_7">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_10">Returns:</h4> <p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p> <h4 id="raises_1">Raises:</h4> <ul> <li>
<b><code>NotImplementedError</code></b>: If <code>self.is_square</code> is <code>False</code>.</li> </ul> <h3 id="diag_part"><code>diag_part</code></h3> <pre class="prettyprint lang-python" data-language="python">diag_part(name='diag_part')
</pre> <p>Efficiently get the [batch] diagonal part of this operator.</p> <p>If this operator has shape <code>[B1,...,Bb, M, N]</code>, this returns a <code>Tensor</code> <code>diagonal</code>, of shape <code>[B1,...,Bb, min(M, N)]</code>, where <code>diagonal[b1,...,bb, i] = self.to_dense()[b1,...,bb, i, i]</code>.</p> <pre class="prettyprint" data-language="python">my_operator = LinearOperatorDiag([1., 2.])

# Efficiently get the diagonal
my_operator.diag_part()
==&gt; [1., 2.]

# Equivalent, but inefficient method
tf.matrix_diag_part(my_operator.to_dense())
==&gt; [1., 2.]
</pre> <h4 id="args_8">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this <code>Op</code>.</li> </ul> <h4 id="returns_11">Returns:</h4> <ul> <li>
<b><code>diag_part</code></b>: A <code>Tensor</code> of same <code>dtype</code> as self.</li> </ul> <h3 id="domain_dimension_tensor"><code>domain_dimension_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">domain_dimension_tensor(name='domain_dimension_tensor')
</pre> <p>Dimension (in the sense of vector spaces) of the domain of this operator.</p> <p>Determined at runtime.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p> <h4 id="args_9">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this <code>Op</code>.</li> </ul> <h4 id="returns_12">Returns:</h4> <p><code>int32</code> <code>Tensor</code></p> <h3 id="log_abs_determinant"><code>log_abs_determinant</code></h3> <pre class="prettyprint lang-python" data-language="python">log_abs_determinant(name='log_abs_det')
</pre> <p>Log absolute value of determinant for every batch member.</p> <h4 id="args_10">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_13">Returns:</h4> <p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code>NotImplementedError</code></b>: If <code>self.is_square</code> is <code>False</code>.</li> </ul> <h3 id="matmul"><code>matmul</code></h3> <pre class="prettyprint lang-python" data-language="python">matmul(
    x,
    adjoint=False,
    adjoint_arg=False,
    name='matmul'
)
</pre> <p>Transform [batch] matrix <code>x</code> with left multiplication: <code>x --&gt; Ax</code>.</p> <pre class="prettyprint lang-python" data-language="python"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]
operator = LinearOperator(...)
operator.shape = [..., M, N]

X = ... # shape [..., N, R], batch matrix, R &gt; 0.

Y = operator.matmul(X)
Y.shape
==&gt; [..., M, R]

Y[..., :, r] = sum_j A[..., :, j] X[j, r]
</pre> <h4 id="args_11">Args:</h4> <ul> <li>
<b><code>x</code></b>: <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>. See class docstring for definition of compatibility.</li> <li>
<b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li> <li>
<b><code>adjoint_arg</code></b>: Python <code>bool</code>. If <code>True</code>, compute <code>A x^H</code> where <code>x^H</code> is the hermitian transpose (transposition and complex conjugation).</li> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_14">Returns:</h4> <p>A <code>Tensor</code> with shape <code>[..., M, R]</code> and same <code>dtype</code> as <code>self</code>.</p> <h3 id="matvec"><code>matvec</code></h3> <pre class="prettyprint lang-python" data-language="python">matvec(
    x,
    adjoint=False,
    name='matvec'
)
</pre> <p>Transform [batch] vector <code>x</code> with left multiplication: <code>x --&gt; Ax</code>.</p> <pre class="prettyprint lang-python" data-language="python"># Make an operator acting like batch matric A.  Assume A.shape = [..., M, N]
operator = LinearOperator(...)

X = ... # shape [..., N], batch vector

Y = operator.matvec(X)
Y.shape
==&gt; [..., M]

Y[..., :] = sum_j A[..., :, j] X[..., j]
</pre> <h4 id="args_12">Args:</h4> <ul> <li>
<b><code>x</code></b>: <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>. <code>x</code> is treated as a [batch] vector meaning for every set of leading dimensions, the last dimension defines a vector. See class docstring for definition of compatibility.</li> <li>
<b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_15">Returns:</h4> <p>A <code>Tensor</code> with shape <code>[..., M]</code> and same <code>dtype</code> as <code>self</code>.</p> <h3 id="range_dimension_tensor"><code>range_dimension_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">range_dimension_tensor(name='range_dimension_tensor')
</pre> <p>Dimension (in the sense of vector spaces) of the range of this operator.</p> <p>Determined at runtime.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p> <h4 id="args_13">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this <code>Op</code>.</li> </ul> <h4 id="returns_16">Returns:</h4> <p><code>int32</code> <code>Tensor</code></p> <h3 id="shape_tensor"><code>shape_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">shape_tensor(name='shape_tensor')
</pre> <p>Shape of this <code>LinearOperator</code>, determined at runtime.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding <code>[B1,...,Bb, M, N]</code>, equivalent to <code>tf.shape(A)</code>.</p> <h4 id="args_14">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_17">Returns:</h4> <p><code>int32</code> <code>Tensor</code></p> <h3 id="solve"><code>solve</code></h3> <pre class="prettyprint lang-python" data-language="python">solve(
    rhs,
    adjoint=False,
    adjoint_arg=False,
    name='solve'
)
</pre> <p>Solve (exact or approx) <code>R</code> (batch) systems of equations: <code>A X = rhs</code>.</p> <p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well conditioned. Otherwise closeness will vary. See class docstring for details.</p> <p>Examples:</p> <pre class="prettyprint lang-python" data-language="python"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]
operator = LinearOperator(...)
operator.shape = [..., M, N]

# Solve R &gt; 0 linear systems for every member of the batch.
RHS = ... # shape [..., M, R]

X = operator.solve(RHS)
# X[..., :, r] is the solution to the r'th linear system
# sum_j A[..., :, j] X[..., j, r] = RHS[..., :, r]

operator.matmul(X)
==&gt; RHS
</pre> <h4 id="args_15">Args:</h4> <ul> <li>
<b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator and compatible shape. <code>rhs</code> is treated like a [batch] matrix meaning for every set of leading dimensions, the last two dimensions defines a matrix. See class docstring for definition of compatibility.</li> <li>
<b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, solve the system involving the adjoint of this <code>LinearOperator</code>: <code>A^H X = rhs</code>.</li> <li>
<b><code>adjoint_arg</code></b>: Python <code>bool</code>. If <code>True</code>, solve <code>A X = rhs^H</code> where <code>rhs^H</code> is the hermitian transpose (transposition and complex conjugation).</li> <li>
<b><code>name</code></b>: A name scope to use for ops added by this method.</li> </ul> <h4 id="returns_18">Returns:</h4> <p><code>Tensor</code> with shape <code>[...,N, R]</code> and same <code>dtype</code> as <code>rhs</code>.</p> <h4 id="raises_3">Raises:</h4> <ul> <li>
<b><code>NotImplementedError</code></b>: If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li> </ul> <h3 id="solvevec"><code>solvevec</code></h3> <pre class="prettyprint lang-python" data-language="python">solvevec(
    rhs,
    adjoint=False,
    name='solve'
)
</pre> <p>Solve single equation with best effort: <code>A X = rhs</code>.</p> <p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well conditioned. Otherwise closeness will vary. See class docstring for details.</p> <p>Examples:</p> <pre class="prettyprint lang-python" data-language="python"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]
operator = LinearOperator(...)
operator.shape = [..., M, N]

# Solve one linear system for every member of the batch.
RHS = ... # shape [..., M]

X = operator.solvevec(RHS)
# X is the solution to the linear system
# sum_j A[..., :, j] X[..., j] = RHS[..., :]

operator.matvec(X)
==&gt; RHS
</pre> <h4 id="args_16">Args:</h4> <ul> <li>
<b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator. <code>rhs</code> is treated like a [batch] vector meaning for every set of leading dimensions, the last dimension defines a vector. See class docstring for definition of compatibility regarding batch dimensions.</li> <li>
<b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, solve the system involving the adjoint of this <code>LinearOperator</code>: <code>A^H X = rhs</code>.</li> <li>
<b><code>name</code></b>: A name scope to use for ops added by this method.</li> </ul> <h4 id="returns_19">Returns:</h4> <p><code>Tensor</code> with shape <code>[...,N]</code> and same <code>dtype</code> as <code>rhs</code>.</p> <h4 id="raises_4">Raises:</h4> <ul> <li>
<b><code>NotImplementedError</code></b>: If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li> </ul> <h3 id="tensor_rank_tensor"><code>tensor_rank_tensor</code></h3> <pre class="prettyprint lang-python" data-language="python">tensor_rank_tensor(name='tensor_rank_tensor')
</pre> <p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p> <p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p> <h4 id="args_17">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this `Op.</li> </ul> <h4 id="returns_20">Returns:</h4> <p><code>int32</code> <code>Tensor</code>, determined at runtime.</p> <h3 id="to_dense"><code>to_dense</code></h3> <pre class="prettyprint lang-python" data-language="python">to_dense(name='to_dense')
</pre> <p>Return a dense (batch) matrix representing this operator.</p> <h3 id="trace"><code>trace</code></h3> <pre class="prettyprint lang-python" data-language="python">trace(name='trace')
</pre> <p>Trace of the linear operator, equal to sum of <code>self.diag_part()</code>.</p> <p>If the operator is square, this is also the sum of the eigenvalues.</p> <h4 id="args_18">Args:</h4> <ul> <li>
<b><code>name</code></b>: A name for this <code>Op</code>.</li> </ul> <h4 id="returns_21">Returns:</h4> <p>Shape <code>[B1,...,Bb]</code> <code>Tensor</code> of same <code>dtype</code> as <code>self</code>.</p>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/LinearOperatorComposition" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/linalg/LinearOperatorComposition</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
