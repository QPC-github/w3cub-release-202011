
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.nn.atrous_conv2d - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;python&#47;ops&#47;nn_ops.py. ">
  <meta name="keywords" content="tf, nn, atrous, conv, d, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/nn/atrous_conv2d.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.nn.atrous_conv2d </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn.atrous_conv2d"> <meta itemprop="path" content="r1.8"> </div> <pre class="prettyprint lang-python" data-language="python">tf.nn.atrous_conv2d(
    value,
    filters,
    rate,
    padding,
    name=None
)
</pre> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/nn_ops.py"><code>tensorflow/python/ops/nn_ops.py</code></a>.</p> <p>See the guide: <a href="https://www.tensorflow.org/api_guides/python/nn#Convolution">Neural Network &gt; Convolution</a></p> <p>Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p> <p>This function is a simpler wrapper around the more general <a href="convolution"><code>tf.nn.convolution</code></a>, and exists only for backwards compatibility. You can use <a href="convolution"><code>tf.nn.convolution</code></a> to perform 1-D, 2-D, or 3-D atrous convolution.</p> <p>Computes a 2-D atrous convolution, also known as convolution with holes or dilated convolution, given 4-D <code>value</code> and <code>filters</code> tensors. If the <code>rate</code> parameter is equal to one, it performs regular 2-D convolution. If the <code>rate</code> parameter is greater than one, it performs convolution with holes, sampling the input values every <code>rate</code> pixels in the <code>height</code> and <code>width</code> dimensions. This is equivalent to convolving the input with a set of upsampled filters, produced by inserting <code>rate - 1</code> zeros between two consecutive values of the filters along the <code>height</code> and <code>width</code> dimensions, hence the name atrous convolution or convolution with holes (the French word trous means holes in English).</p> <p>More specifically:</p> <pre class="prettyprint" data-language="python">output[batch, height, width, out_channel] =
    sum_{dheight, dwidth, in_channel} (
        filters[dheight, dwidth, in_channel, out_channel] *
        value[batch, height + rate*dheight, width + rate*dwidth, in_channel]
    )
</pre> <p>Atrous convolution allows us to explicitly control how densely to compute feature responses in fully convolutional networks. Used in conjunction with bilinear interpolation, it offers an alternative to <code>conv2d_transpose</code> in dense prediction tasks such as semantic image segmentation, optical flow computation, or depth estimation. It also allows us to effectively enlarge the field of view of filters without increasing the number of parameters or the amount of computation.</p> <p>For a description of atrous convolution and how it can be used for dense feature extraction, please see: <a href="http://arxiv.org/abs/1412.7062">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</a>. The same operation is investigated further in <a href="http://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation by Dilated Convolutions</a>. Previous works that effectively use atrous convolution in different ways are, among others, <a href="http://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a> and <a href="http://arxiv.org/abs/1302.1700">Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks</a>. Atrous convolution is also closely related to the so-called noble identities in multi-rate signal processing.</p> <p>There are many different ways to implement atrous convolution (see the refs above). The implementation here reduces</p> <pre class="prettyprint lang-python" data-language="python">atrous_conv2d(value, filters, rate, padding=padding)
</pre> <p>to the following three operations:</p> <pre class="prettyprint lang-python" data-language="python">paddings = ...
net = space_to_batch(value, paddings, block_size=rate)
net = conv2d(net, filters, strides=[1, 1, 1, 1], padding="VALID")
crops = ...
net = batch_to_space(net, crops, block_size=rate)
</pre> <p>Advanced usage. Note the following optimization: A sequence of <code>atrous_conv2d</code> operations with identical <code>rate</code> parameters, 'SAME' <code>padding</code>, and filters with odd heights/ widths:</p> <pre class="prettyprint lang-python" data-language="python">net = atrous_conv2d(net, filters1, rate, padding="SAME")
net = atrous_conv2d(net, filters2, rate, padding="SAME")
...
net = atrous_conv2d(net, filtersK, rate, padding="SAME")
</pre> <p>can be equivalently performed cheaper in terms of computation and memory as:</p> <pre class="prettyprint lang-python" data-language="python">pad = ...  # padding so that the input dims are multiples of rate
net = space_to_batch(net, paddings=pad, block_size=rate)
net = conv2d(net, filters1, strides=[1, 1, 1, 1], padding="SAME")
net = conv2d(net, filters2, strides=[1, 1, 1, 1], padding="SAME")
...
net = conv2d(net, filtersK, strides=[1, 1, 1, 1], padding="SAME")
net = batch_to_space(net, crops=pad, block_size=rate)
</pre> <p>because a pair of consecutive <code>space_to_batch</code> and <code>batch_to_space</code> ops with the same <code>block_size</code> cancel out when their respective <code>paddings</code> and <code>crops</code> inputs are identical.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>value</code></b>: A 4-D <code>Tensor</code> of type <code>float</code>. It needs to be in the default "NHWC" format. Its shape is <code>[batch, in_height, in_width, in_channels]</code>.</li> <li>
<b><code>filters</code></b>: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape <code>[filter_height, filter_width, in_channels, out_channels]</code>. <code>filters</code>' <code>in_channels</code> dimension must match that of <code>value</code>. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height <code>filter_height + (filter_height - 1) * (rate - 1)</code> and effective width <code>filter_width + (filter_width - 1) * (rate - 1)</code>, produced by inserting <code>rate - 1</code> zeros along consecutive elements across the <code>filters</code>' spatial dimensions.</li> <li>
<b><code>rate</code></b>: A positive int32. The stride with which we sample input values across the <code>height</code> and <code>width</code> dimensions. Equivalently, the rate by which we upsample the filter values by inserting zeros across the <code>height</code> and <code>width</code> dimensions. In the literature, the same parameter is sometimes called <code>input stride</code> or <code>dilation</code>.</li> <li>
<b><code>padding</code></b>: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.</li> <li>
<b><code>name</code></b>: Optional name for the returned tensor.</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code>Tensor</code> with the same type as <code>value</code>. Output shape with `'VALID`` padding is:</p> <pre class="prettyprint notranslate" translate="no" data-language="python">[batch, height - 2 * (filter_width - 1),
 width - 2 * (filter_height - 1), out_channels].
</pre> <p>Output shape with <code>'SAME'</code> padding is:</p> <pre class="prettyprint notranslate" translate="no" data-language="python">[batch, height, width, out_channels].
</pre> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>ValueError</code></b>: If input/output depth does not match <code>filters</code>' shape, or if padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
