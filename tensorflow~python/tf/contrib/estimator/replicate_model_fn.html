
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>contrib.estimator.replicate_model_fn - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;contrib&#47;estimator&#47;python&#47;estimator&#47;replicate_model_fn.py. ">
  <meta name="keywords" content="tf, contrib, estimator, replicate, model, fn, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/contrib/estimator/replicate_model_fn.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.contrib.estimator.replicate_model_fn </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.contrib.estimator.replicate_model_fn"> <meta itemprop="path" content="r1.8"> </div> <pre class="prettyprint lang-python" data-language="python">tf.contrib.estimator.replicate_model_fn(
    model_fn,
    loss_reduction=losses.Reduction.SUM_BY_NONZERO_WEIGHTS,
    devices=None
)
</pre> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py"><code>tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py</code></a>.</p> <p>Replicate <code>Estimator.model_fn</code> over GPUs.</p> <p>The given <code>model_fn</code> specifies a single forward pass of a model. To replicate such a model over GPUs, each GPU gets its own instance of the forward pass (a.k.a. a tower). The input features and labels get sharded into the chunks that correspond to the number of GPUs. Each tower computes a loss based on its input. For each such loss, gradients are computed. After that, the available losses are aggregated to form aggregated loss. Available gradients are summed. Then, they update weights using the specified optimizer.</p> <p>If <code>devices</code> are <code>None</code>, then all available GPUs are going to be used for replication. If no GPUs are available, then the model is going to be placed on the CPU.</p> <p>Two modes of local replication over available GPUs are supported: 1) If exactly 1 GPU is detected, then variables and operations are placed onto the GPU. 2) If more than 1 GPU is detected, then variables are going to be placed on the CPU. Replicas of operations are placed on each individual GPU.</p> <p>Here is an example of how one might use their <code>model_fn</code> to run over GPUs:</p> <pre class="prettyprint notranslate" translate="no" data-language="python">...
def model_fn(...):  # See `model_fn` in `Estimator`.
  loss = ...
  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
  optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)
  if mode == tf.estimator.ModeKeys.TRAIN:
    #  See the section below on `EstimatorSpec.train_op`.
    return EstimatorSpec(mode=mode, loss=loss,
                         train_op=optimizer.minimize(loss))

  #  No change for `ModeKeys.EVAL` or `ModeKeys.PREDICT`.
  return EstimatorSpec(...)
...
classifier = tf.estimator.Estimator(
  model_fn=tf.contrib.estimator.replicate_model_fn(model_fn))
</pre> <p>Please see <code>DNNClassifierIntegrationTest</code> for an example with a canned Estimator.</p> <p>On <code>EstimatorSpec.train_op</code>: <code>model_fn</code> returns <code>EstimatorSpec.train_op</code> for <code>tf.estimator.GraphKeys.TRAIN</code>. It is typically derived using an optimizer. Towers are expected to populate it in the same way. Gradients from all towers are reduced and applied in the last tower. To achieve that in the case of multiple towers, <code>TowerOptimizer</code> needs to be used. See <code>TowerOptimizer</code>.</p> <p>On sharding input features and labels: Input features and labels are split for consumption by each tower. They are split across the dimension 0. Features and labels need to be batch major.</p> <p>On reduction algorithms: Certain algorithms were chosen for aggregating results of computations on multiple towers: - Losses from all towers are reduced according to <code>loss_reduction</code>. - Gradients from all towers are reduced according to <code>loss_reduction</code> for each trainable variable. - <code>eval_metrics_ops</code> are reduced per metric using <code>reduce_mean</code>. - <code>EstimatorSpec.predictions</code> and <code>EstimatorSpec.export_outputs</code> are reduced using concatenation. - For all other fields of <code>EstimatorSpec</code> the values of the first tower are taken.</p> <p>On distribution of variables: Variables are not duplicated between towers. Instead, they are placed on a single device as defined above and shared across towers.</p> <p>On overhead: If only one device is specified, then aggregation of loss and gradients doesn't happen. Replication consists of placing <code>model_fn</code> onto the specified device.</p> <p>On current limitations: - <code>predictions</code> are not supported for <code>ModeKeys.EVAL</code>. They are required for <a href="add_metrics"><code>tf.contrib.estimator.add_metrics</code></a>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>model_fn</code></b>: <code>model_fn</code> as defined in <code>Estimator</code>. See the section above about the train_op argument of <code>EstimatorSpec</code>.</li> <li>
<b><code>loss_reduction</code></b>: controls whether losses are summed or averaged.</li> <li>
<b><code>devices</code></b>: Optional list of devices to replicate the model across. This argument can be used to replicate only on the subset of available GPUs. If <code>None</code>, then all available GPUs are going to be used for replication. If no GPUs are available, then the model is going to be placed on the CPU.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>ValueError</code></b>: if there is no <code>loss_reduction</code> or if TowerOptimizer is mis-used.</li> </ul> <h4 id="returns">Returns:</h4> <p>A replicated version of the supplied <code>model_fn</code>. Returned function that conforms to the requirements of <code>Estimator</code>'s <code>model_fn</code> and can be used instead of the supplied <code>model_fn</code>.</p>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/replicate_model_fn" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/replicate_model_fn</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
