
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>contrib.distributions.bijectors.masked_autoregressive_default_template - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;contrib&#47;distributions&#47;python&#47;ops&#47;bijectors&#47;masked_autoregressive.py. ">
  <meta name="keywords" content="tf, contrib, distributions, bijectors, masked, autoregressive, default, template, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/contrib/distributions/bijectors/masked_autoregressive_default_template.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.contrib.distributions.bijectors.masked_autoregressive_default_template </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.contrib.distributions.bijectors.masked_autoregressive_default_template"> <meta itemprop="path" content="r1.8"> </div> <pre class="prettyprint lang-python" data-language="python">tf.contrib.distributions.bijectors.masked_autoregressive_default_template(
    hidden_layers,
    shift_only=False,
    activation=tf.nn.relu,
    log_scale_min_clip=-5.0,
    log_scale_max_clip=3.0,
    log_scale_clip_gradient=False,
    name=None,
    *args,
    **kwargs
)
</pre> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py"><code>tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py</code></a>.</p> <p>Build the Masked Autoregressive Density Estimator (Germain et al., 2015).</p> <p>This will be wrapped in a make_template to ensure the variables are only created once. It takes the input and returns the <code>loc</code> ("mu" in [Germain et al. (2015)][1]) and <code>log_scale</code> ("alpha" in [Germain et al. (2015)][1]) from the MADE network.</p> <aside class="warning"><strong>Warning:</strong><span> This function uses <code>masked_dense</code> to create randomly initialized <code>tf.Variables</code>. It is presumed that these will be fit, just as you would any other neural architecture which uses <a href="../../../layers/dense"><code>tf.layers.dense</code></a>.</span></aside> <h4 id="about_hidden_layers">About Hidden Layers</h4> <p>Each element of <code>hidden_layers</code> should be greater than the <code>input_depth</code> (i.e., <code>input_depth = tf.shape(input)[-1]</code> where <code>input</code> is the input to the neural network). This is necessary to ensure the autoregressivity property.</p> <h4 id="about_clipping">About Clipping</h4> <p>This function also optionally clips the <code>log_scale</code> (but possibly not its gradient). This is useful because if <code>log_scale</code> is too small/large it might underflow/overflow making it impossible for the <code>MaskedAutoregressiveFlow</code> bijector to implement a bijection. Additionally, the <code>log_scale_clip_gradient</code> <code>bool</code> indicates whether the gradient should also be clipped. The default does not clip the gradient; this is useful because it still provides gradient information (for fitting) yet solves the numerical stability problem. I.e., <code>log_scale_clip_gradient = False</code> means <code>grad[exp(clip(x))] = grad[x] exp(clip(x))</code> rather than the usual <code>grad[clip(x)] exp(clip(x))</code>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>hidden_layers</code></b>: Python <code>list</code>-like of non-negative integer, scalars indicating the number of units in each hidden layer. Default: `[512, 512].</li> <li>
<b><code>shift_only</code></b>: Python <code>bool</code> indicating if only the <code>shift</code> term shall be computed. Default: <code>False</code>.</li> <li>
<b><code>activation</code></b>: Activation function (callable). Explicitly setting to <code>None</code> implies a linear activation.</li> <li>
<b><code>log_scale_min_clip</code></b>: <code>float</code>-like scalar <code>Tensor</code>, or a <code>Tensor</code> with the same shape as <code>log_scale</code>. The minimum value to clip by. Default: -5.</li> <li>
<b><code>log_scale_max_clip</code></b>: <code>float</code>-like scalar <code>Tensor</code>, or a <code>Tensor</code> with the same shape as <code>log_scale</code>. The maximum value to clip by. Default: 3.</li> <li>
<b><code>log_scale_clip_gradient</code></b>: Python <code>bool</code> indicating that the gradient of <a href="../../../clip_by_value"><code>tf.clip_by_value</code></a> should be preserved. Default: <code>False</code>.</li> <li>
<b><code>name</code></b>: A name for ops managed by this function. Default: "masked_autoregressive_default_template".</li> <li>
<b><code>*args</code></b>: <a href="../../../layers/dense"><code>tf.layers.dense</code></a> arguments.</li> <li>
<b><code>**kwargs</code></b>: <a href="../../../layers/dense"><code>tf.layers.dense</code></a> keyword arguments.</li> </ul> <h4 id="returns">Returns:</h4> <ul> <li>
<b><code>shift</code></b>: <code>Float</code>-like <code>Tensor</code> of shift terms (the "mu" in [Germain et al. (2015)][1]).</li> <li>
<b><code>log_scale</code></b>: <code>Float</code>-like <code>Tensor</code> of log(scale) terms (the "alpha" in [Germain et al. (2015)][1]).</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>NotImplementedError</code></b>: if rightmost dimension of <code>inputs</code> is unknown prior to graph execution.</li> </ul> <h4 id="references">References</h4> <p>[1]: Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle. MADE: Masked Autoencoder for Distribution Estimation. In <em>International Conference on Machine Learning</em>, 2015. https://arxiv.org/abs/1502.03509</p>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/masked_autoregressive_default_template" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/masked_autoregressive_default_template</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
