
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>contrib.training.NextQueuedSequenceBatch - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;contrib&#47;training&#47;python&#47;training&#47;sequence_queueing_state_saver.py. ">
  <meta name="keywords" content="tf, contrib, training, nextqueuedsequencebatch, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/contrib/training/nextqueuedsequencebatch.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~python.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.contrib.training.NextQueuedSequenceBatch </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.contrib.training.NextQueuedSequenceBatch"> <meta itemprop="path" content="r1.8"> <meta itemprop="property" content="batch_size"> <meta itemprop="property" content="context"> <meta itemprop="property" content="insertion_index"> <meta itemprop="property" content="key"> <meta itemprop="property" content="length"> <meta itemprop="property" content="next_key"> <meta itemprop="property" content="sequence"> <meta itemprop="property" content="sequence_count"> <meta itemprop="property" content="sequences"> <meta itemprop="property" content="total_length"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="save_state"> <meta itemprop="property" content="state"> </div> <h2 id="class_nextqueuedsequencebatch">Class <code>NextQueuedSequenceBatch</code>
</h2> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/training/python/training/sequence_queueing_state_saver.py"><code>tensorflow/contrib/training/python/training/sequence_queueing_state_saver.py</code></a>.</p> <p>See the guide: <a href="https://www.tensorflow.org/api_guides/python/contrib.training#Splitting_sequence_inputs_into_minibatches_with_state_saving">Training (contrib) &gt; Splitting sequence inputs into minibatches with state saving</a></p> <p>NextQueuedSequenceBatch stores deferred SequenceQueueingStateSaver data.</p> <p>This class is instantiated by <code>SequenceQueueingStateSaver</code> and is accessible via its <code>next_batch</code> property.</p> <h2 id="properties">Properties</h2> <h3 id="batch_size"><code>batch_size</code></h3> <p>The batch_size of the given batch.</p> <p>Usually, this is the batch_size requested when initializing the SQSS, but if allow_small_batch=True this will become smaller when inputs are exhausted.</p> <h4 id="returns">Returns:</h4> <p>A scalar integer tensor, the batch_size</p> <h3 id="context"><code>context</code></h3> <p>A dict mapping keys of <code>input_context</code> to batched context.</p> <h4 id="returns_1">Returns:</h4> <p>A dict mapping keys of <code>input_context</code> to tensors. If we had at input:</p> <pre class="prettyprint lang-python" data-language="python">context["name"].get_shape() == [d1, d2, ...]
</pre> <p>then for this property:</p> <pre class="prettyprint lang-python" data-language="python">context["name"].get_shape() == [batch_size, d1, d2, ...]
</pre> <h3 id="insertion_index"><code>insertion_index</code></h3> <p>The insertion indices of the examples (when they were first added).</p> <p>These indices start with the value -2**63 and increase with every call to the prefetch op. Each whole example gets its own insertion index, and this is used to prioritize the example so that its truncated segments appear in adjacent iterations, even if new examples are inserted by the prefetch op between iterations.</p> <h4 id="returns_2">Returns:</h4> <p>An int64 vector of length <code>batch_size</code>, the insertion indices.</p> <h3 id="key"><code>key</code></h3> <p>The key names of the given truncated unrolled examples.</p> <p>The format of the key is:</p> <pre class="prettyprint lang-python" data-language="python">"%05d_of_%05d:%s" % (sequence, sequence_count, original_key)
</pre> <p>where <code>original_key</code> is the unique key read in by the prefetcher.</p> <h4 id="returns_3">Returns:</h4> <p>A string vector of length <code>batch_size</code>, the keys.</p> <h3 id="length"><code>length</code></h3> <p>The lengths of the given truncated unrolled examples.</p> <p>For initial iterations, for which <code>sequence * num_unroll &lt; length</code>, this number is <code>num_unroll</code>. For the remainder, this number is between <code>0</code> and <code>num_unroll</code>.</p> <h4 id="returns_4">Returns:</h4> <p>An integer vector of length <code>batch_size</code>, the lengths.</p> <h3 id="next_key"><code>next_key</code></h3> <p>The key names of the next (in iteration) truncated unrolled examples.</p> <p>The format of the key is:</p> <pre class="prettyprint lang-python" data-language="python">"%05d_of_%05d:%s" % (sequence + 1, sequence_count, original_key)
</pre> <p>if <code>sequence + 1 &lt; sequence_count</code>, otherwise:</p> <pre class="prettyprint lang-python" data-language="python">"STOP:%s" % original_key
</pre> <p>where <code>original_key</code> is the unique key read in by the prefetcher.</p> <h4 id="returns_5">Returns:</h4> <p>A string vector of length <code>batch_size</code>, the keys.</p> <h3 id="sequence"><code>sequence</code></h3> <p>An int32 vector, length <code>batch_size</code>: the sequence index of each entry.</p> <p>When an input is split up, the sequence values</p> <pre class="prettyprint" data-language="python">0, 1, ..., sequence_count - 1
</pre> <p>are assigned to each split.</p> <h4 id="returns_6">Returns:</h4> <p>An int32 vector <code>Tensor</code>.</p> <h3 id="sequence_count"><code>sequence_count</code></h3> <p>An int32 vector, length <code>batch_size</code>: the sequence count of each entry.</p> <p>When an input is split up, the number of splits is equal to: <code>padded_length / num_unroll</code>. This is the sequence_count.</p> <h4 id="returns_7">Returns:</h4> <p>An int32 vector <code>Tensor</code>.</p> <h3 id="sequences"><code>sequences</code></h3> <p>A dict mapping keys of <code>input_sequences</code> to split and rebatched data.</p> <h4 id="returns_8">Returns:</h4> <p>A dict mapping keys of <code>input_sequences</code> to tensors. If we had at input:</p> <pre class="prettyprint lang-python" data-language="python">sequences["name"].get_shape() == [None, d1, d2, ...]
</pre> <p>where <code>None</code> meant the sequence time was dynamic, then for this property:</p> <pre class="prettyprint lang-python" data-language="python">sequences["name"].get_shape() == [batch_size, num_unroll, d1, d2, ...].
</pre> <h3 id="total_length"><code>total_length</code></h3> <p>The lengths of the original (non-truncated) unrolled examples.</p> <h4 id="returns_9">Returns:</h4> <p>An integer vector of length <code>batch_size</code>, the total lengths.</p> <h2 id="methods">Methods</h2> <h3 id="__init__"><code>__init__</code></h3> <pre class="prettyprint lang-python" data-language="python">__init__(state_saver)
</pre> <p>Initialize self. See help(type(self)) for accurate signature.</p> <h3 id="save_state"><code>save_state</code></h3> <pre class="prettyprint lang-python" data-language="python">save_state(
    state_name,
    value,
    name=None
)
</pre> <p>Returns an op to save the current batch of state <code>state_name</code>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>state_name</code></b>: string, matches a key provided in <code>initial_states</code>.</li> <li> <p><b><code>value</code></b>: A <code>Tensor</code>. Its type must match that of <code>initial_states[state_name].dtype</code>. If we had at input:</p> <p><code>python initial_states[state_name].get_shape() == [d1, d2, ...]</code></p> <p>then the shape of <code>value</code> must match:</p> <p><code>python tf.shape(value) == [batch_size, d1, d2, ...]</code></p> </li> <li> <p><b><code>name</code></b>: string (optional). The name scope for newly created ops.</p> </li> </ul> <h4 id="returns_10">Returns:</h4> <p>A control flow op that stores the new state of each entry into the state saver. This op must be run for every iteration that accesses data from the state saver (otherwise the state saver will never progress through its states and run out of capacity).</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>KeyError</code></b>: if <code>state_name</code> does not match any of the initial states declared in <code>initial_states</code>.</li> </ul> <h3 id="state"><code>state</code></h3> <pre class="prettyprint lang-python" data-language="python">state(state_name)
</pre> <p>Returns batched state tensors.</p> <h4 id="args_1">Args:</h4> <ul> <li>
<b><code>state_name</code></b>: string, matches a key provided in <code>initial_states</code>.</li> </ul> <h4 id="returns_11">Returns:</h4> <p>A <code>Tensor</code>: a batched set of states, either initial states (if this is the first run of the given example), or a value as stored during a previous iteration via <code>save_state</code> control flow. Its type is the same as <code>initial_states["state_name"].dtype</code>. If we had at input:</p> <pre class="prettyprint lang-python" data-language="python">initial_states[state_name].get_shape() == [d1, d2, ...],
</pre> <p>then</p> <pre class="prettyprint lang-python" data-language="python">state(state_name).get_shape() == [batch_size, d1, d2, ...]
</pre> <h4 id="raises_1">Raises:</h4> <ul> <li>
<b><code>KeyError</code></b>: if <code>state_name</code> does not match any of the initial states declared in <code>initial_states</code>.</li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/training/NextQueuedSequenceBatch" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/contrib/training/NextQueuedSequenceBatch</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
