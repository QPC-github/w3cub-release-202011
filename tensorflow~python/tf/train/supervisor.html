
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.train.Supervisor - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Defined in tensorflow&#47;python&#47;training&#47;supervisor.py. ">
  <meta name="keywords" content="tf, train, supervisor, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/tf/train/supervisor.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> tf.train.Supervisor </h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.train.Supervisor"> <meta itemprop="path" content="r1.8"> <meta itemprop="property" content="coord"> <meta itemprop="property" content="global_step"> <meta itemprop="property" content="init_feed_dict"> <meta itemprop="property" content="init_op"> <meta itemprop="property" content="is_chief"> <meta itemprop="property" content="ready_for_local_init_op"> <meta itemprop="property" content="ready_op"> <meta itemprop="property" content="save_model_secs"> <meta itemprop="property" content="save_path"> <meta itemprop="property" content="save_summaries_secs"> <meta itemprop="property" content="saver"> <meta itemprop="property" content="session_manager"> <meta itemprop="property" content="summary_op"> <meta itemprop="property" content="summary_writer"> <meta itemprop="property" content="Loop"> <meta itemprop="property" content="PrepareSession"> <meta itemprop="property" content="RequestStop"> <meta itemprop="property" content="ShouldStop"> <meta itemprop="property" content="StartQueueRunners"> <meta itemprop="property" content="StartStandardServices"> <meta itemprop="property" content="Stop"> <meta itemprop="property" content="StopOnException"> <meta itemprop="property" content="SummaryComputed"> <meta itemprop="property" content="WaitForStop"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="loop"> <meta itemprop="property" content="managed_session"> <meta itemprop="property" content="prepare_or_wait_for_session"> <meta itemprop="property" content="request_stop"> <meta itemprop="property" content="should_stop"> <meta itemprop="property" content="start_queue_runners"> <meta itemprop="property" content="start_standard_services"> <meta itemprop="property" content="stop"> <meta itemprop="property" content="stop_on_exception"> <meta itemprop="property" content="summary_computed"> <meta itemprop="property" content="wait_for_stop"> <meta itemprop="property" content="USE_DEFAULT"> </div> <h2 id="class_supervisor">Class <code>Supervisor</code>
</h2> <p>Defined in <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/supervisor.py"><code>tensorflow/python/training/supervisor.py</code></a>.</p> <p>See the guide: <a href="https://www.tensorflow.org/api_guides/python/train#Distributed_execution">Training &gt; Distributed execution</a></p> <p>A training helper that checkpoints models and computes summaries.</p> <p>This class is deprecated. Please use <a href="monitoredtrainingsession"><code>tf.train.MonitoredTrainingSession</code></a> instead.</p> <p>The Supervisor is a small wrapper around a <code>Coordinator</code>, a <code>Saver</code>, and a <code>SessionManager</code> that takes care of common needs of TensorFlow training programs.</p> <h4 id="use_for_a_single_program">Use for a single program</h4> <pre class="prettyprint lang-python" data-language="python">with tf.Graph().as_default():
  ...add operations to the graph...
  # Create a Supervisor that will checkpoint the model in '/tmp/mydir'.
  sv = Supervisor(logdir='/tmp/mydir')
  # Get a TensorFlow session managed by the supervisor.
  with sv.managed_session(FLAGS.master) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op&gt;)
</pre> <p>Within the <code>with sv.managed_session()</code> block all variables in the graph have been initialized. In addition, a few services have been started to checkpoint the model and add summaries to the event log.</p> <p>If the program crashes and is restarted, the managed session automatically reinitialize variables from the most recent checkpoint.</p> <p>The supervisor is notified of any exception raised by one of the services. After an exception is raised, <code>should_stop()</code> returns <code>True</code>. In that case the training loop should also stop. This is why the training loop has to check for <code>sv.should_stop()</code>.</p> <p>Exceptions that indicate that the training inputs have been exhausted, <a href="../errors/outofrangeerror"><code>tf.errors.OutOfRangeError</code></a>, also cause <code>sv.should_stop()</code> to return <code>True</code> but are not re-raised from the <code>with</code> block: they indicate a normal termination.</p> <h4 id="use_for_multiple_replicas">Use for multiple replicas</h4> <p>To train with replicas you deploy the same program in a <code>Cluster</code>. One of the tasks must be identified as the <em>chief</em>: the task that handles initialization, checkpoints, summaries, and recovery. The other tasks depend on the <em>chief</em> for these services.</p> <p>The only change you have to do to the single program code is to indicate if the program is running as the <em>chief</em>.</p> <pre class="prettyprint lang-python" data-language="python"># Choose a task as the chief. This could be based on server_def.task_index,
# or job_def.name, or job_def.tasks. It's entirely up to the end user.
# But there can be only one *chief*.
is_chief = (server_def.task_index == 0)
server = tf.train.Server(server_def)

with tf.Graph().as_default():
  ...add operations to the graph...
  # Create a Supervisor that uses log directory on a shared file system.
  # Indicate if you are the 'chief'
  sv = Supervisor(logdir='/shared_directory/...', is_chief=is_chief)
  # Get a Session in a TensorFlow server on the cluster.
  with sv.managed_session(server.target) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op&gt;)
</pre> <p>In the <em>chief</em> task, the <code>Supervisor</code> works exactly as in the first example above. In the other tasks <code>sv.managed_session()</code> waits for the Model to have been initialized before returning a session to the training code. The non-chief tasks depend on the chief task for initializing the model.</p> <p>If one of the tasks crashes and restarts, <code>managed_session()</code> checks if the Model is initialized. If yes, it just creates a session and returns it to the training code that proceeds normally. If the model needs to be initialized, the chief task takes care of reinitializing it; the other tasks just wait for the model to have been initialized.</p> <p>NOTE: This modified program still works fine as a single program. The single program marks itself as the chief.</p> <h4 id="what_master_string_to_use">What <code>master</code> string to use</h4> <p>Whether you are running on your machine or in the cluster you can use the following values for the --master flag:</p> <ul> <li> <p>Specifying <code>''</code> requests an in-process session that does not use RPC.</p> </li> <li> <p>Specifying <code>'local'</code> requests a session that uses the RPC-based "Master interface" to run TensorFlow programs. See <a href="server#create_local_server"><code>tf.train.Server.create_local_server</code></a> for details.</p> </li> <li> <p>Specifying <code>'grpc://hostname:port'</code> requests a session that uses the RPC interface to a specific host, and also allows the in-process master to access remote tensorflow workers. Often, it is appropriate to pass <code>server.target</code> (for some <a href="server"><code>tf.train.Server</code></a> named `server).</p> </li> </ul> <h4 id="advanced_use">Advanced use</h4> <h5 id="launching_additional_services">Launching additional services</h5> <p><code>managed_session()</code> launches the Checkpoint and Summary services (threads). If you need more services to run you can simply launch them in the block controlled by <code>managed_session()</code>.</p> <p>Example: Start a thread to print losses. We want this thread to run every 60 seconds, so we launch it with <code>sv.loop()</code>.</p> <pre class="prettyprint lang-python" data-language="python">...
sv = Supervisor(logdir='/tmp/mydir')
with sv.managed_session(FLAGS.master) as sess:
  sv.loop(60, print_loss, (sess, ))
  while not sv.should_stop():
    sess.run(my_train_op)
</pre> <h5 id="launching_fewer_services">Launching fewer services</h5> <p><code>managed_session()</code> launches the "summary" and "checkpoint" threads which use either the optionally <code>summary_op</code> and <code>saver</code> passed to the constructor, or default ones created automatically by the supervisor. If you want to run your own summary and checkpointing logic, disable these services by passing <code>None</code> to the <code>summary_op</code> and <code>saver</code> parameters.</p> <p>Example: Create summaries manually every 100 steps in the chief.</p> <pre class="prettyprint lang-python" data-language="python"># Create a Supervisor with no automatic summaries.
sv = Supervisor(logdir='/tmp/mydir', is_chief=is_chief, summary_op=None)
# As summary_op was None, managed_session() does not start the
# summary thread.
with sv.managed_session(FLAGS.master) as sess:
  for step in xrange(1000000):
    if sv.should_stop():
      break
    if is_chief and step % 100 == 0:
      # Create the summary every 100 chief steps.
      sv.summary_computed(sess, sess.run(my_summary_op))
    else:
      # Train normally
      sess.run(my_train_op)
</pre> <h5 id="custom_model_initialization">Custom model initialization</h5> <p><code>managed_session()</code> only supports initializing the model by running an <code>init_op</code> or restoring from the latest checkpoint. If you have special initialization needs, see how to specify a <code>local_init_op</code> when creating the supervisor. You can also use the <code>SessionManager</code> directly to create a session and check if it could be initialized automatically.</p> <h2 id="properties">Properties</h2> <h3 id="coord"><code>coord</code></h3> <p>Return the Coordinator used by the Supervisor.</p> <p>The Coordinator can be useful if you want to run multiple threads during your training.</p> <h4 id="returns">Returns:</h4> <p>A Coordinator object.</p> <h3 id="global_step"><code>global_step</code></h3> <p>Return the global_step Tensor used by the supervisor.</p> <h4 id="returns_1">Returns:</h4> <p>An integer Tensor for the global_step.</p> <h3 id="init_feed_dict"><code>init_feed_dict</code></h3> <p>Return the feed dictionary used when evaluating the <code>init_op</code>.</p> <h4 id="returns_2">Returns:</h4> <p>A feed dictionary or <code>None</code>.</p> <h3 id="init_op"><code>init_op</code></h3> <p>Return the Init Op used by the supervisor.</p> <h4 id="returns_3">Returns:</h4> <p>An Op or <code>None</code>.</p> <h3 id="is_chief"><code>is_chief</code></h3> <p>Return True if this is a chief supervisor.</p> <h4 id="returns_4">Returns:</h4> <p>A bool.</p> <h3 id="ready_for_local_init_op"><code>ready_for_local_init_op</code></h3> <h3 id="ready_op"><code>ready_op</code></h3> <p>Return the Ready Op used by the supervisor.</p> <h4 id="returns_5">Returns:</h4> <p>An Op or <code>None</code>.</p> <h3 id="save_model_secs"><code>save_model_secs</code></h3> <p>Return the delay between checkpoints.</p> <h4 id="returns_6">Returns:</h4> <p>A timestamp.</p> <h3 id="save_path"><code>save_path</code></h3> <p>Return the save path used by the supervisor.</p> <h4 id="returns_7">Returns:</h4> <p>A string.</p> <h3 id="save_summaries_secs"><code>save_summaries_secs</code></h3> <p>Return the delay between summary computations.</p> <h4 id="returns_8">Returns:</h4> <p>A timestamp.</p> <h3 id="saver"><code>saver</code></h3> <p>Return the Saver used by the supervisor.</p> <h4 id="returns_9">Returns:</h4> <p>A Saver object.</p> <h3 id="session_manager"><code>session_manager</code></h3> <p>Return the SessionManager used by the Supervisor.</p> <h4 id="returns_10">Returns:</h4> <p>A SessionManager object.</p> <h3 id="summary_op"><code>summary_op</code></h3> <p>Return the Summary Tensor used by the chief supervisor.</p> <h4 id="returns_11">Returns:</h4> <p>A string Tensor for the summary or <code>None</code>.</p> <h3 id="summary_writer"><code>summary_writer</code></h3> <p>Return the SummaryWriter used by the chief supervisor.</p> <h4 id="returns_12">Returns:</h4> <p>A SummaryWriter.</p> <h2 id="methods">Methods</h2> <h3 id="__init__"><code>__init__</code></h3> <pre class="prettyprint lang-python" data-language="python">__init__(
    graph=None,
    ready_op=USE_DEFAULT,
    ready_for_local_init_op=USE_DEFAULT,
    is_chief=True,
    init_op=USE_DEFAULT,
    init_feed_dict=None,
    local_init_op=USE_DEFAULT,
    logdir=None,
    summary_op=USE_DEFAULT,
    saver=USE_DEFAULT,
    global_step=USE_DEFAULT,
    save_summaries_secs=120,
    save_model_secs=600,
    recovery_wait_secs=30,
    stop_grace_secs=120,
    checkpoint_basename='model.ckpt',
    session_manager=None,
    summary_writer=USE_DEFAULT,
    init_fn=None
)
</pre> <p>Create a <code>Supervisor</code>. (deprecated)</p> <p>THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please switch to tf.train.MonitoredTrainingSession</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>graph</code></b>: A <code>Graph</code>. The graph that the model will use. Defaults to the default <code>Graph</code>. The supervisor may add operations to the graph before creating a session, but the graph should not be modified by the caller after passing it to the supervisor.</li> <li>
<b><code>ready_op</code></b>: 1-D string <code>Tensor</code>. This tensor is evaluated by supervisors in <code>prepare_or_wait_for_session()</code> to check if the model is ready to use. The model is considered ready if it returns an empty array. Defaults to the tensor returned from <code>tf.report_uninitialized_variables()</code> If <code>None</code>, the model is not checked for readiness.</li> <li>
<b><code>ready_for_local_init_op</code></b>: 1-D string <code>Tensor</code>. This tensor is evaluated by supervisors in <code>prepare_or_wait_for_session()</code> to check if the model is ready to run the local_init_op. The model is considered ready if it returns an empty array. Defaults to the tensor returned from <code>tf.report_uninitialized_variables(tf.global_variables())</code>. If <code>None</code>, the model is not checked for readiness before running local_init_op.</li> <li>
<b><code>is_chief</code></b>: If True, create a chief supervisor in charge of initializing and restoring the model. If False, create a supervisor that relies on a chief supervisor for inits and restore.</li> <li>
<b><code>init_op</code></b>: <code>Operation</code>. Used by chief supervisors to initialize the model when it can not be recovered. Defaults to an <code>Operation</code> that initializes all global variables. If <code>None</code>, no initialization is done automatically unless you pass a value for <code>init_fn</code>, see below.</li> <li>
<b><code>init_feed_dict</code></b>: A dictionary that maps <code>Tensor</code> objects to feed values. This feed dictionary will be used when <code>init_op</code> is evaluated.</li> <li>
<b><code>local_init_op</code></b>: <code>Operation</code>. Used by all supervisors to run initializations that should run for every new supervisor instance. By default these are table initializers and initializers for local variables. If <code>None</code>, no further per supervisor-instance initialization is done automatically.</li> <li>
<b><code>logdir</code></b>: A string. Optional path to a directory where to checkpoint the model and log events for the visualizer. Used by chief supervisors. The directory will be created if it does not exist.</li> <li>
<b><code>summary_op</code></b>: An <code>Operation</code> that returns a Summary for the event logs. Used by chief supervisors if a <code>logdir</code> was specified. Defaults to the operation returned from summary.merge_all(). If <code>None</code>, summaries are not computed automatically.</li> <li>
<b><code>saver</code></b>: A Saver object. Used by chief supervisors if a <code>logdir</code> was specified. Defaults to the saved returned by Saver(). If <code>None</code>, the model is not saved automatically.</li> <li>
<b><code>global_step</code></b>: An integer Tensor of size 1 that counts steps. The value from 'global_step' is used in summaries and checkpoint filenames. Default to the op named 'global_step' in the graph if it exists, is of rank 1, size 1, and of type tf.int32 or tf.int64. If <code>None</code> the global step is not recorded in summaries and checkpoint files. Used by chief supervisors if a <code>logdir</code> was specified.</li> <li>
<b><code>save_summaries_secs</code></b>: Number of seconds between the computation of summaries for the event log. Defaults to 120 seconds. Pass 0 to disable summaries.</li> <li>
<b><code>save_model_secs</code></b>: Number of seconds between the creation of model checkpoints. Defaults to 600 seconds. Pass 0 to disable checkpoints.</li> <li>
<b><code>recovery_wait_secs</code></b>: Number of seconds between checks that the model is ready. Used by supervisors when waiting for a chief supervisor to initialize or restore the model. Defaults to 30 seconds.</li> <li>
<b><code>stop_grace_secs</code></b>: Grace period, in seconds, given to running threads to stop when <code>stop()</code> is called. Defaults to 120 seconds.</li> <li>
<b><code>checkpoint_basename</code></b>: The basename for checkpoint saving.</li> <li>
<b><code>session_manager</code></b>: <code>SessionManager</code>, which manages Session creation and recovery. If it is <code>None</code>, a default <code>SessionManager</code> will be created with the set of arguments passed in for backwards compatibility.</li> <li>
<b><code>summary_writer</code></b>: <code>SummaryWriter</code> to use or <code>USE_DEFAULT</code>. Can be <code>None</code> to indicate that no summaries should be written.</li> <li>
<b><code>init_fn</code></b>: Optional callable used to initialize the model. Called after the optional <code>init_op</code> is called. The callable must accept one argument, the session being initialized.</li> </ul> <h4 id="returns_13">Returns:</h4> <p>A <code>Supervisor</code>.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility">Eager Compatibility</h4> <p><code>Supervisor</code>s are not supported when eager execution is enabled.</p> <h3 id="Loop"><code>Loop</code></h3> <pre class="prettyprint lang-python" data-language="python">Loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</pre> <p>Start a LooperThread that calls a function periodically.</p> <p>If <code>timer_interval_secs</code> is None the thread calls <code>target(*args, **kwargs)</code> repeatedly. Otherwise it calls it every <code>timer_interval_secs</code> seconds. The thread terminates when a stop is requested.</p> <p>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the <code>stop()</code> method.</p> <h4 id="args_1">Args:</h4> <ul> <li>
<b><code>timer_interval_secs</code></b>: Number. Time boundaries at which to call <code>target</code>.</li> <li>
<b><code>target</code></b>: A callable object.</li> <li>
<b><code>args</code></b>: Optional arguments to pass to <code>target</code> when calling it.</li> <li>
<b><code>kwargs</code></b>: Optional keyword arguments to pass to <code>target</code> when calling it.</li> </ul> <h4 id="returns_14">Returns:</h4> <p>The started thread.</p> <h3 id="PrepareSession"><code>PrepareSession</code></h3> <pre class="prettyprint lang-python" data-language="python">PrepareSession(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</pre> <p>Make sure the model is ready to be used.</p> <p>Create a session on 'master', recovering or initializing the model as needed, or wait for a session to be ready. If running as the chief and <code>start_standard_service</code> is set to True, also call the session manager to start the standard services.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code>master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code>tf.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code>config</code></b>: Optional ConfigProto proto used to configure the session, which is passed as-is to create the session.</li> <li>
<b><code>wait_for_checkpoint</code></b>: Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</li> <li>
<b><code>max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li> <li>
<b><code>start_standard_services</code></b>: Whether to start the standard services and the queue runners.</li> </ul> <h4 id="returns_15">Returns:</h4> <p>A Session object that can be used to drive the model.</p> <h3 id="RequestStop"><code>RequestStop</code></h3> <pre class="prettyprint lang-python" data-language="python">RequestStop(ex=None)
</pre> <p>Request that the coordinator stop the threads.</p> <p>See <code>Coordinator.request_stop()</code>.</p> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code>ex</code></b>: Optional <code>Exception</code>, or Python <code>exc_info</code> tuple as returned by <code>sys.exc_info()</code>. If this is the first call to <code>request_stop()</code> the corresponding exception is recorded and re-raised from <code>join()</code>.</li> </ul> <h3 id="ShouldStop"><code>ShouldStop</code></h3> <pre class="prettyprint lang-python" data-language="python">ShouldStop()
</pre> <p>Check if the coordinator was told to stop.</p> <p>See <code>Coordinator.should_stop()</code>.</p> <h4 id="returns_16">Returns:</h4> <p>True if the coordinator was told to stop, False otherwise.</p> <h3 id="StartQueueRunners"><code>StartQueueRunners</code></h3> <pre class="prettyprint lang-python" data-language="python">StartQueueRunners(
    sess,
    queue_runners=None
)
</pre> <p>Start threads for <code>QueueRunners</code>.</p> <p>Note that the queue runners collected in the graph key <code>QUEUE_RUNNERS</code> are already started automatically when you create a session with the supervisor, so unless you have non-collected queue runners to start you do not need to call this explicitly.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A <code>Session</code>.</li> <li>
<b><code>queue_runners</code></b>: A list of <code>QueueRunners</code>. If not specified, we'll use the list of queue runners gathered in the graph under the key <code>GraphKeys.QUEUE_RUNNERS</code>.</li> </ul> <h4 id="returns_17">Returns:</h4> <p>The list of threads started for the <code>QueueRunners</code>.</p> <h4 id="raises_1">Raises:</h4> <ul> <li>
<b><code>RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility_1">Eager Compatibility</h4> <p>Queues are not compatible with eager execution. To ingest data when eager execution is enabled, use the <a href="../data"><code>tf.data</code></a> API.</p> <h3 id="StartStandardServices"><code>StartStandardServices</code></h3> <pre class="prettyprint lang-python" data-language="python">StartStandardServices(sess)
</pre> <p>Start the standard services for 'sess'.</p> <p>This starts services in the background. The services started depend on the parameters to the constructor and may include:</p> <ul> <li>A Summary thread computing summaries every save_summaries_secs.</li> <li>A Checkpoint thread saving the model every save_model_secs.</li> <li>A StepCounter thread measure step time.</li> </ul> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A Session.</li> </ul> <h4 id="returns_18">Returns:</h4> <p>A list of threads that are running the standard services. You can use the Supervisor's Coordinator to join these threads with: sv.coord.Join(<list of threads>)</list></p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code>RuntimeError</code></b>: If called with a non-chief Supervisor.</li> <li>
<b><code>ValueError</code></b>: If not <code>logdir</code> was passed to the constructor as the services need a log directory.</li> </ul> <h3 id="Stop"><code>Stop</code></h3> <pre class="prettyprint lang-python" data-language="python">Stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</pre> <p>Stop the services and the coordinator.</p> <p>This does not close the session.</p> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code>threads</code></b>: Optional list of threads to join with the coordinator. If <code>None</code>, defaults to the threads running the standard services, the threads started for <code>QueueRunners</code>, and the threads started by the <code>loop()</code> method. To wait on additional threads, pass the list in this parameter.</li> <li>
<b><code>close_summary_writer</code></b>: Whether to close the <code>summary_writer</code>. Defaults to <code>True</code> if the summary writer was created by the supervisor, <code>False</code> otherwise.</li> <li>
<b><code>ignore_live_threads</code></b>: If <code>True</code> ignores threads that remain running after a grace period when joining threads via the coordinator, instead of raising a RuntimeError.</li> </ul> <h3 id="StopOnException"><code>StopOnException</code></h3> <pre class="prettyprint lang-python" data-language="python">StopOnException()
</pre> <p>Context handler to stop the supervisor when an exception is raised.</p> <p>See <code>Coordinator.stop_on_exception()</code>.</p> <h4 id="returns_19">Returns:</h4> <p>A context handler.</p> <h3 id="SummaryComputed"><code>SummaryComputed</code></h3> <pre class="prettyprint lang-python" data-language="python">SummaryComputed(
    sess,
    summary,
    global_step=None
)
</pre> <p>Indicate that a summary was computed.</p> <h4 id="args_7">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A <code>Session</code> object.</li> <li>
<b><code>summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li> <li>
<b><code>global_step</code></b>: Int. global step this summary is associated with. If <code>None</code>, it will try to fetch the current step.</li> </ul> <h4 id="raises_3">Raises:</h4> <ul> <li>
<b><code>TypeError</code></b>: if 'summary' is not a Summary proto or a string.</li> <li>
<b><code>RuntimeError</code></b>: if the Supervisor was created without a <code>logdir</code>.</li> </ul> <h3 id="WaitForStop"><code>WaitForStop</code></h3> <pre class="prettyprint lang-python" data-language="python">WaitForStop()
</pre> <p>Block waiting for the coordinator to stop.</p> <h3 id="loop"><code>loop</code></h3> <pre class="prettyprint lang-python" data-language="python">loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</pre> <p>Start a LooperThread that calls a function periodically.</p> <p>If <code>timer_interval_secs</code> is None the thread calls <code>target(*args, **kwargs)</code> repeatedly. Otherwise it calls it every <code>timer_interval_secs</code> seconds. The thread terminates when a stop is requested.</p> <p>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the <code>stop()</code> method.</p> <h4 id="args_8">Args:</h4> <ul> <li>
<b><code>timer_interval_secs</code></b>: Number. Time boundaries at which to call <code>target</code>.</li> <li>
<b><code>target</code></b>: A callable object.</li> <li>
<b><code>args</code></b>: Optional arguments to pass to <code>target</code> when calling it.</li> <li>
<b><code>kwargs</code></b>: Optional keyword arguments to pass to <code>target</code> when calling it.</li> </ul> <h4 id="returns_20">Returns:</h4> <p>The started thread.</p> <h3 id="managed_session"><code>managed_session</code></h3> <pre class="prettyprint lang-python" data-language="python">managed_session(
    *args,
    **kwds
)
</pre> <p>Returns a context manager for a managed session.</p> <p>This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the <code>with</code> block or from the services and stops the supervisor as needed.</p> <p>The context manager is typically used as follows:</p> <pre class="prettyprint lang-python" data-language="python">def train():
  sv = tf.train.Supervisor(...)
  with sv.managed_session(&lt;master&gt;) as sess:
    for step in xrange(..):
      if sv.should_stop():
        break
      sess.run(&lt;my training op&gt;)
      ...do other things needed at each training step...
</pre> <p>An exception raised from the <code>with</code> block or one of the service threads is raised again when the block exits. This is done after stopping all threads and closing the session. For example, an <code>AbortedError</code> exception, raised in case of preemption of one of the workers in a distributed model, is raised again when the block exits.</p> <p>If you want to retry the training loop in case of preemption you can do it as follows:</p> <pre class="prettyprint lang-python" data-language="python">def main(...):
  while True
    try:
      train()
    except tf.errors.Aborted:
      pass
</pre> <p>As a special case, exceptions used for control flow, such as <code>OutOfRangeError</code> which reports that input queues are exhausted, are not raised again from the <code>with</code> block: they indicate a clean termination of the training loop and are considered normal termination.</p> <h4 id="args_9">Args:</h4> <ul> <li>
<b><code>master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code>tf.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code>config</code></b>: Optional <code>ConfigProto</code> proto used to configure the session. Passed as-is to create the session.</li> <li>
<b><code>start_standard_services</code></b>: Whether to start the standard services, such as checkpoint, summary and step counter.</li> <li>
<b><code>close_summary_writer</code></b>: Whether to close the summary writer when closing the session. Defaults to True.</li> </ul> <h4 id="returns_21">Returns:</h4> <p>A context manager that yields a <code>Session</code> restored from the latest checkpoint or initialized from scratch if not checkpoint exists. The session is closed when the <code>with</code> block exits.</p> <h3 id="prepare_or_wait_for_session"><code>prepare_or_wait_for_session</code></h3> <pre class="prettyprint lang-python" data-language="python">prepare_or_wait_for_session(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</pre> <p>Make sure the model is ready to be used.</p> <p>Create a session on 'master', recovering or initializing the model as needed, or wait for a session to be ready. If running as the chief and <code>start_standard_service</code> is set to True, also call the session manager to start the standard services.</p> <h4 id="args_10">Args:</h4> <ul> <li>
<b><code>master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code>tf.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code>config</code></b>: Optional ConfigProto proto used to configure the session, which is passed as-is to create the session.</li> <li>
<b><code>wait_for_checkpoint</code></b>: Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</li> <li>
<b><code>max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li> <li>
<b><code>start_standard_services</code></b>: Whether to start the standard services and the queue runners.</li> </ul> <h4 id="returns_22">Returns:</h4> <p>A Session object that can be used to drive the model.</p> <h3 id="request_stop"><code>request_stop</code></h3> <pre class="prettyprint lang-python" data-language="python">request_stop(ex=None)
</pre> <p>Request that the coordinator stop the threads.</p> <p>See <code>Coordinator.request_stop()</code>.</p> <h4 id="args_11">Args:</h4> <ul> <li>
<b><code>ex</code></b>: Optional <code>Exception</code>, or Python <code>exc_info</code> tuple as returned by <code>sys.exc_info()</code>. If this is the first call to <code>request_stop()</code> the corresponding exception is recorded and re-raised from <code>join()</code>.</li> </ul> <h3 id="should_stop"><code>should_stop</code></h3> <pre class="prettyprint lang-python" data-language="python">should_stop()
</pre> <p>Check if the coordinator was told to stop.</p> <p>See <code>Coordinator.should_stop()</code>.</p> <h4 id="returns_23">Returns:</h4> <p>True if the coordinator was told to stop, False otherwise.</p> <h3 id="start_queue_runners"><code>start_queue_runners</code></h3> <pre class="prettyprint lang-python" data-language="python">start_queue_runners(
    sess,
    queue_runners=None
)
</pre> <p>Start threads for <code>QueueRunners</code>.</p> <p>Note that the queue runners collected in the graph key <code>QUEUE_RUNNERS</code> are already started automatically when you create a session with the supervisor, so unless you have non-collected queue runners to start you do not need to call this explicitly.</p> <h4 id="args_12">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A <code>Session</code>.</li> <li>
<b><code>queue_runners</code></b>: A list of <code>QueueRunners</code>. If not specified, we'll use the list of queue runners gathered in the graph under the key <code>GraphKeys.QUEUE_RUNNERS</code>.</li> </ul> <h4 id="returns_24">Returns:</h4> <p>The list of threads started for the <code>QueueRunners</code>.</p> <h4 id="raises_4">Raises:</h4> <ul> <li>
<b><code>RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility_2">Eager Compatibility</h4> <p>Queues are not compatible with eager execution. To ingest data when eager execution is enabled, use the <a href="../data"><code>tf.data</code></a> API.</p> <h3 id="start_standard_services"><code>start_standard_services</code></h3> <pre class="prettyprint lang-python" data-language="python">start_standard_services(sess)
</pre> <p>Start the standard services for 'sess'.</p> <p>This starts services in the background. The services started depend on the parameters to the constructor and may include:</p> <ul> <li>A Summary thread computing summaries every save_summaries_secs.</li> <li>A Checkpoint thread saving the model every save_model_secs.</li> <li>A StepCounter thread measure step time.</li> </ul> <h4 id="args_13">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A Session.</li> </ul> <h4 id="returns_25">Returns:</h4> <p>A list of threads that are running the standard services. You can use the Supervisor's Coordinator to join these threads with: sv.coord.Join(<list of threads>)</list></p> <h4 id="raises_5">Raises:</h4> <ul> <li>
<b><code>RuntimeError</code></b>: If called with a non-chief Supervisor.</li> <li>
<b><code>ValueError</code></b>: If not <code>logdir</code> was passed to the constructor as the services need a log directory.</li> </ul> <h3 id="stop"><code>stop</code></h3> <pre class="prettyprint lang-python" data-language="python">stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</pre> <p>Stop the services and the coordinator.</p> <p>This does not close the session.</p> <h4 id="args_14">Args:</h4> <ul> <li>
<b><code>threads</code></b>: Optional list of threads to join with the coordinator. If <code>None</code>, defaults to the threads running the standard services, the threads started for <code>QueueRunners</code>, and the threads started by the <code>loop()</code> method. To wait on additional threads, pass the list in this parameter.</li> <li>
<b><code>close_summary_writer</code></b>: Whether to close the <code>summary_writer</code>. Defaults to <code>True</code> if the summary writer was created by the supervisor, <code>False</code> otherwise.</li> <li>
<b><code>ignore_live_threads</code></b>: If <code>True</code> ignores threads that remain running after a grace period when joining threads via the coordinator, instead of raising a RuntimeError.</li> </ul> <h3 id="stop_on_exception"><code>stop_on_exception</code></h3> <pre class="prettyprint lang-python" data-language="python">stop_on_exception()
</pre> <p>Context handler to stop the supervisor when an exception is raised.</p> <p>See <code>Coordinator.stop_on_exception()</code>.</p> <h4 id="returns_26">Returns:</h4> <p>A context handler.</p> <h3 id="summary_computed"><code>summary_computed</code></h3> <pre class="prettyprint lang-python" data-language="python">summary_computed(
    sess,
    summary,
    global_step=None
)
</pre> <p>Indicate that a summary was computed.</p> <h4 id="args_15">Args:</h4> <ul> <li>
<b><code>sess</code></b>: A <code>Session</code> object.</li> <li>
<b><code>summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li> <li>
<b><code>global_step</code></b>: Int. global step this summary is associated with. If <code>None</code>, it will try to fetch the current step.</li> </ul> <h4 id="raises_6">Raises:</h4> <ul> <li>
<b><code>TypeError</code></b>: if 'summary' is not a Summary proto or a string.</li> <li>
<b><code>RuntimeError</code></b>: if the Supervisor was created without a <code>logdir</code>.</li> </ul> <h3 id="wait_for_stop"><code>wait_for_stop</code></h3> <pre class="prettyprint lang-python" data-language="python">wait_for_stop()
</pre> <p>Block waiting for the coordinator to stop.</p> <h2 id="class_members">Class Members</h2> <h3 id="USE_DEFAULT"><code>USE_DEFAULT</code></h3>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/train/Supervisor" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/train/Supervisor</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
