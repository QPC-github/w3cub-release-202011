
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch - TensorFlow 2.4 - W3cubDocs</title>
  
  <meta name="description" content=" Eases the porting of code that uses tf.nn.embedding_lookup(). ">
  <meta name="keywords" content="tf, raw, ops, enqueuetpuembeddingraggedtensorbatch, tensorflow, tensorflow~2.4">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.4/raw_ops/enqueuetpuembeddingraggedtensorbatch.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.4.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.4/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.4</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch</h1>       <p>Eases the porting of code that uses tf.nn.embedding_lookup().</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingRaggedTensorBatch"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch(
    sample_splits, embedding_indices, aggregation_weights, mode_override, table_ids,
    device_ordinal=-1, combiners=[], max_sequence_lengths=[], name=None
)
</pre>  <p>sample_splits[i], embedding_indices[i] and aggregation_weights[i] correspond to the ith feature. table_ids[i] indicates which embedding table to look up ith feature.</p> <p>The tensors at corresponding positions in two of the input lists, embedding_indices and aggregation_weights, must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding feature.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">sample_splits</code> </td> <td> A list of at least 1 <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. A list of rank 1 Tensors specifying the break points for splitting embedding_indices and aggregation_weights into rows. It corresponds to ids.row_splits in embedding_lookup(), when ids is a RaggedTensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">embedding_indices</code> </td> <td> A list with the same length as <code translate="no" dir="ltr">sample_splits</code> of <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. A list of rank 1 Tensors, indices into the embedding tables. It corresponds to ids.values in embedding_lookup(), when ids is a RaggedTensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">aggregation_weights</code> </td> <td> A list with the same length as <code translate="no" dir="ltr">sample_splits</code> of <code translate="no" dir="ltr">Tensor</code> objects with the same type in: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. A list of rank 1 Tensors containing per training example aggregation weights. It corresponds to the values field of a RaggedTensor with the same row_splits as ids in embedding_lookup(), when ids is a RaggedTensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">mode_override</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">string</code>. A string input that overrides the mode specified in the TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference', 'training', 'backward_pass_only'}. When set to 'unspecified', the mode set in TPUEmbeddingConfiguration is used, otherwise mode_override is used. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">table_ids</code> </td> <td> A list of <code translate="no" dir="ltr">ints</code>. A list of integers specifying the identifier of the embedding table (offset of TableDescriptor in the TPUEmbeddingConfiguration) to lookup the corresponding input. The ith input is looked up using table_ids[i]. The size of the table_ids list must be equal to that of sample_indices, embedding_indices and aggregation_weights. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">device_ordinal</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">-1</code>. The TPU device to use. Should be &gt;= 0 and less than the number of TPU cores in the task on which the node is placed. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">combiners</code> </td> <td> An optional list of <code translate="no" dir="ltr">strings</code>. Defaults to <code translate="no" dir="ltr">[]</code>. A list of string scalars, one for each embedding table that specify how to normalize the embedding activations after weighted summation. Supported combiners are 'mean', 'sum', or 'sqrtn'. It is invalid to have the sum of the weights be 0 for 'mean' or the sum of the squared weights be 0 for 'sqrtn'. If combiners isn't passed, the default is to use 'sum' for all tables. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_sequence_lengths</code> </td> <td> An optional list of <code translate="no" dir="ltr">ints</code>. Defaults to <code translate="no" dir="ltr">[]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The created Operation. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingRaggedTensorBatch" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/raw_ops/EnqueueTPUEmbeddingRaggedTensorBatch</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
