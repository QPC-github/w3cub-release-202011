
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>11.39. Concurrent and Parallel Haskell - Haskell 8 - W3cubDocs</title>
  
  <meta name="description" content=" GHC implements some major extensions to Haskell to support concurrent and parallel programming. Let us first establish terminology&#58; ">
  <meta name="keywords" content="concurrent, and, parallel, haskell, haskell~8">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/haskell~8/users_guide/parallel.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/haskell~8.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/haskell~8/" class="_nav-link" title="" style="margin-left:0;">Haskell 8</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _haskell">
				
				
<h1 id="lang-parallel">11.39. Concurrent and Parallel Haskell</h1>
<div class="_sphinx">   <p id="concurrent-and-parallel-haskell">GHC implements some major extensions to Haskell to support concurrent and parallel programming. Let us first establish terminology:</p> <ul class="simple"> <li>
<em>Parallelism</em> means running a Haskell program on multiple processors, with the goal of improving performance. Ideally, this should be done invisibly, and with no semantic changes.</li> <li>
<em>Concurrency</em> means implementing a program by using multiple I/O-performing threads. While a concurrent Haskell program <em>can</em> run on a parallel machine, the primary goal of using concurrency is not to gain performance, but rather because that is the simplest and most direct way to write the program. Since the threads perform I/O, the semantics of the program is necessarily non-deterministic.</li> </ul> <p>GHC supports both concurrency and parallelism.</p>  <h2 id="id1">11.39.1. Concurrent Haskell</h2> <p id="concurrent-haskell">Concurrent Haskell is the name given to GHC’s concurrency extension. It is enabled by default, so no special flags are required. The <a class="reference external" href="https://www.haskell.org/ghc/docs/papers/concurrent-haskell.ps.gz">Concurrent Haskell paper</a> is still an excellent resource, as is <a class="reference external" href="http://research.microsoft.com/%7Esimonpj/papers/marktoberdorf/">Tackling the awkward squad</a>.</p> <p>To the programmer, Concurrent Haskell introduces no new language constructs; rather, it appears simply as a library, <a class="reference external" href="../libraries/base-4.13.0.0/control-concurrent">Control.Concurrent</a>. The functions exported by this library include:</p> <ul class="simple"> <li>Forking and killing threads.</li> <li>Sleeping.</li> <li>Synchronised mutable variables, called <code>MVars</code>
</li> <li>Support for bound threads; see the paper <a class="reference external" href="http://community.haskell.org/~simonmar/papers/conc-ffi.pdf">Extending the FFI with concurrency</a>.</li> </ul>   <h2 id="software-transactional-memory">11.39.2. Software Transactional Memory</h2> <p>GHC now supports a new way to coordinate the activities of Concurrent Haskell threads, called Software Transactional Memory (STM). The <a class="reference external" href="https://wiki.haskell.org/Research_papers/Parallelism_and_concurrency#Lock_free_data_structures_and_transactional_memory">STM papers</a> are an excellent introduction to what STM is, and how to use it.</p> <p>The main library you need to use is the <a class="reference external" href="http://hackage.haskell.org/package/stm">stm library</a>. The main features supported are these:</p> <ul class="simple"> <li>Atomic blocks.</li> <li>Transactional variables.</li> <li>Operations for composing transactions: <code>retry</code>, and <code>orElse</code>.</li> <li>Data invariants.</li> </ul> <p>All these features are described in the papers mentioned earlier.</p>   <h2 id="parallel-haskell">11.39.3. Parallel Haskell</h2> <p id="index-1">GHC includes support for running Haskell programs in parallel on symmetric, shared-memory multi-processor (SMP). By default GHC runs your program on one processor; if you want it to run in parallel you must link your program with the <a class="reference internal" href="phases#ghc-flag--threaded"><code>-threaded</code></a>, and run it with the RTS <a class="reference internal" href="#"><code>-N ⟨x⟩</code></a> option; see <a class="reference internal" href="using-concurrent#using-smp"><span class="std std-ref">Using SMP parallelism</span></a>). The runtime will schedule the running Haskell threads among the available OS threads, running as many in parallel as you specified with the <a class="reference internal" href="#"><code>-N ⟨x⟩</code></a> RTS option.</p>   <h2 id="annotating-pure-code-for-parallelism">11.39.4. Annotating pure code for parallelism</h2> <p>Ordinary single-threaded Haskell programs will not benefit from enabling SMP parallelism alone: you must expose parallelism to the compiler. One way to do so is forking threads using Concurrent Haskell (<a class="reference internal" href="#concurrent-haskell"><span class="std std-ref">Concurrent Haskell</span></a>), but the simplest mechanism for extracting parallelism from pure code is to use the <code>par</code> combinator, which is closely related to (and often used with) <code>seq</code>. Both of these are available from the <a class="reference external" href="http://hackage.haskell.org/package/parallel">parallel library</a>:</p> <pre data-language="haskell">infixr 0 `par`
infixr 1 `pseq`

par  :: a -&gt; b -&gt; b
pseq :: a -&gt; b -&gt; b
</pre> <p>The expression <code>(x `par` y)</code> <em>sparks</em> the evaluation of <code>x</code> (to weak head normal form) and returns <code>y</code>. Sparks are queued for execution in FIFO order, but are not executed immediately. If the runtime detects that there is an idle CPU, then it may convert a spark into a real thread, and run the new thread on the idle CPU. In this way the available parallelism is spread amongst the real CPUs.</p> <p>For example, consider the following parallel version of our old nemesis, <code>nfib</code>:</p> <pre data-language="haskell">import Control.Parallel

nfib :: Int -&gt; Int
nfib n | n &lt;= 1 = 1
       | otherwise = par n1 (pseq n2 (n1 + n2 + 1))
                     where n1 = nfib (n-1)
                           n2 = nfib (n-2)
</pre> <p>For values of <code>n</code> greater than 1, we use <code>par</code> to spark a thread to evaluate <code>nfib (n-1)</code>, and then we use <code>pseq</code> to force the parent thread to evaluate <code>nfib (n-2)</code> before going on to add together these two subexpressions. In this divide-and-conquer approach, we only spark a new thread for one branch of the computation (leaving the parent to evaluate the other branch). Also, we must use <code>pseq</code> to ensure that the parent will evaluate <code>n2</code> <em>before</em> <code>n1</code> in the expression <code>(n1 + n2 + 1)</code>. It is not sufficient to reorder the expression as <code>(n2 + n1 + 1)</code>, because the compiler may not generate code to evaluate the addends from left to right.</p> <p>Note that we use <code>pseq</code> rather than <code>seq</code>. The two are almost equivalent, but differ in their runtime behaviour in a subtle way: <code>seq</code> can evaluate its arguments in either order, but <code>pseq</code> is required to evaluate its first argument before its second, which makes it more suitable for controlling the evaluation order in conjunction with <code>par</code>.</p> <p>When using <code>par</code>, the general rule of thumb is that the sparked computation should be required at a later time, but not too soon. Also, the sparked computation should not be too small, otherwise the cost of forking it in parallel will be too large relative to the amount of parallelism gained. Getting these factors right is tricky in practice.</p> <p>It is possible to glean a little information about how well <code>par</code> is working from the runtime statistics; see <a class="reference internal" href="runtime_control#rts-options-gc"><span class="std std-ref">RTS options to control the garbage collector</span></a>.</p> <p>More sophisticated combinators for expressing parallelism are available from the <code>Control.Parallel.Strategies</code> module in the <a class="reference external" href="http://hackage.haskell.org/package/parallel">parallel package</a>. This module builds functionality around <code>par</code>, expressing more elaborate patterns of parallel computation, such as parallel <code>map</code>.</p>   </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2002–2007 The University Court of the University of Glasgow. All rights reserved.<br>Licensed under the Glasgow Haskell Compiler License.<br>
    <a href="https://downloads.haskell.org/~ghc/8.8.3/docs/html/users_guide/parallel.html" class="_attribution-link">https://downloads.haskell.org/~ghc/8.8.3/docs/html/users_guide/parallel.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
