
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.contrib.layers.recompute_grad - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" Decorator that recomputes the function on the backwards pass. ">
  <meta name="keywords" content="tf, contrib, layers, recompute, grad, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/contrib/layers/recompute_grad.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.contrib.layers.recompute_grad</h1>       <p>Decorator that recomputes the function on the backwards pass.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.contrib.layers.recompute_grad(
    fn, use_data_dep=_USE_DEFAULT, tupleize_grads=False
)
</pre>  <p>To use this function, you must use <code translate="no" dir="ltr">ResourceVariable</code>s (i.e. `variable_scope(name, use_resource=True), which are the default in Eager mode and when running on TPU.</p> <aside class="warning"><strong>Warning:</strong><span> Because the function will be called again on the backwards pass, the user should be careful to not use ops in their function that mutate state or have randomness (for example, batch normalization or dropout). If the function does have such operations, it is recommended that the function take the <code translate="no" dir="ltr">is_recomputing</code> keyword argument which will be <code translate="no" dir="ltr">False</code> on the forward pass and <code translate="no" dir="ltr">True</code> on the backwards pass so that it can disable state changes when <code translate="no" dir="ltr">is_recomputing=True</code> (for example, not updating the moving averages in batch normalization).</span></aside>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">fn</code> </td> <td> a function that takes Tensors (all as positional arguments) and returns a tuple of Tensors. Note that <code translate="no" dir="ltr">fn</code> should not close over any other Tensors or Variables. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_data_dep</code> </td> <td> <code translate="no" dir="ltr">bool</code>, if <code translate="no" dir="ltr">True</code> will use a dummy data dependency to force the recompute to happen. If <code translate="no" dir="ltr">False</code> will use a control dependency. By default will be <code translate="no" dir="ltr">True</code> if in an XLA context and <code translate="no" dir="ltr">False</code> otherwise. XLA ignores control dependencies and so this data dependency is necessary. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">tupleize_grads</code> </td> <td> <code translate="no" dir="ltr">bool</code>, if <code translate="no" dir="ltr">True</code> will use control dependencies to ensure that all gradients are produced before any are consumed by downstream ops. If <code translate="no" dir="ltr">use_data_dep</code> is also <code translate="no" dir="ltr">True</code>, will use a data dependency instead of a control dependency. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A wrapped fn that is identical to fn when called, but its activations will be discarded and recomputed on the backwards pass (i.e. on a call to tf.gradients). </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">fn</code> closes over any Tensors or Variables. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/layers/recompute_grad" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/layers/recompute_grad</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
