
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.contrib.training.bucket - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" Lazy bucketing of input tensors according to which_bucket. ">
  <meta name="keywords" content="tf, contrib, training, bucket, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/contrib/training/bucket.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.contrib.training.bucket</h1>       <p>Lazy bucketing of input tensors according to <code translate="no" dir="ltr">which_bucket</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.contrib.training.bucket(
    tensors, which_bucket, batch_size, num_buckets, num_threads=1, capacity=32,
    bucket_capacities=None, shapes=None, dynamic_pad=False,
    allow_smaller_final_batch=False, keep_input=True, shared_name=None, name=None
)
</pre>  <p>The argument <code translate="no" dir="ltr">tensors</code> can be a list or a dictionary of tensors. The value returned by the function will be of the same type as <code translate="no" dir="ltr">tensors</code>.</p> <p>The tensors entering this function are put into the bucket given by <code translate="no" dir="ltr">which_bucket</code>. Each bucket has its own queue. When a bucket contains <code translate="no" dir="ltr">batch_size</code> elements, this minibatch is pushed onto a top queue. The tensors returned from this function are a the result of dequeueing the next minibatch from this top queue.</p> <p>This function is implemented using several queues. A <code translate="no" dir="ltr">QueueRunner</code> for the queues is added to the current <code translate="no" dir="ltr">Graph</code>'s <code translate="no" dir="ltr">QUEUE_RUNNER</code> collection.</p> <p>As the returned tensors are the result of a dequeue operation, evaluating them will throw a <a href="../../errors/outofrangeerror"><code translate="no" dir="ltr">tf.errors.OutOfRangeError</code></a> when the input queue is exhausted. If these tensors are feeding another input queue, its queue runner will catch this exception, however, if they are used in your main thread you are responsible for catching this yourself.</p> <blockquote class="note">
<strong>Note:</strong><span> If <code translate="no" dir="ltr">dynamic_pad</code> is <code translate="no" dir="ltr">False</code>, you must ensure that either (i) the <code translate="no" dir="ltr">shapes</code> argument is passed, or (ii) all of the tensors in <code translate="no" dir="ltr">tensors</code> must have fully-defined shapes. <code translate="no" dir="ltr">ValueError</code> will be raised if neither of these conditions holds.</span>
</blockquote> <p>If <code translate="no" dir="ltr">dynamic_pad</code> is <code translate="no" dir="ltr">True</code>, it is sufficient that the <em>rank</em> of the tensors is known, but individual dimensions may have shape <code translate="no" dir="ltr">None</code>. In this case, for each enqueue the dimensions with value <code translate="no" dir="ltr">None</code> may have a variable length; upon dequeue, the output tensors will be padded on the right to the maximum shape of the tensors in the current minibatch. For numbers, this padding takes value 0. For strings, this padding is the empty string. See <code translate="no" dir="ltr">PaddingFIFOQueue</code> for more info.</p> <p>If <code translate="no" dir="ltr">allow_smaller_final_batch</code> is <code translate="no" dir="ltr">True</code>, a smaller batch value than <code translate="no" dir="ltr">batch_size</code> is returned when the queues are closed and there are not enough elements to fill the batch, otherwise the pending elements are discarded. In addition, all output tensors' static shapes, as accessed via the <code translate="no" dir="ltr">get_shape()</code> method will have a 0th <code translate="no" dir="ltr">Dimension</code> value of <code translate="no" dir="ltr">None</code>, and operations that depend on fixed batch_size would fail.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensors</code> </td> <td> The list or dictionary of tensors, representing a single element, to bucket. Nested lists are not supported. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">which_bucket</code> </td> <td> An <code translate="no" dir="ltr">int32</code> scalar Tensor taking a value in <code translate="no" dir="ltr">[0, num_buckets)</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> The new batch size pulled from the queue (all queues will have the same size). If a list is passed in then each bucket will have a different batch_size. (python int, int32 scalar or iterable of integers of length num_buckets). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_buckets</code> </td> <td> A python integer, the number of buckets. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_threads</code> </td> <td> An integer. The number of threads enqueuing <code translate="no" dir="ltr">tensors</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">capacity</code> </td> <td> An integer. The maximum number of minibatches in the top queue, and also (by default) the maximum number of elements within each bucket. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bucket_capacities</code> </td> <td> (Optional) None or a list of integers, the capacities of each bucket. If None, capacity is used (default). If specified, it must be a list of integers of length num_buckets: the i-th element is used as capacity for the i-th bucket queue. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shapes</code> </td> <td> (Optional) The shapes for each example. Defaults to the inferred shapes for <code translate="no" dir="ltr">tensors</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dynamic_pad</code> </td> <td> Boolean. Allow variable dimensions in input shapes. The given dimensions are padded upon dequeue so that tensors within a batch have the same shapes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">allow_smaller_final_batch</code> </td> <td> (Optional) Boolean. If <code translate="no" dir="ltr">True</code>, allow the final batches to be smaller if there are insufficient items left in the queues. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">keep_input</code> </td> <td> A <code translate="no" dir="ltr">bool</code> scalar Tensor. If provided, this tensor controls whether the input is added to the queue or not. If it evaluates <code translate="no" dir="ltr">True</code>, then <code translate="no" dir="ltr">tensors</code> are added to the bucket; otherwise they are dropped. This tensor essentially acts as a filtering mechanism. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shared_name</code> </td> <td> (Optional). If set, the queues will be shared under the given name across multiple sessions. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (Optional) A name for the operations. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A tuple <code translate="no" dir="ltr">(bucket, outputs)</code> where <code translate="no" dir="ltr">bucket</code> is a <code translate="no" dir="ltr">int32</code> scalar tensor and <code translate="no" dir="ltr">outputs</code> is a list or dictionary of batched outputs corresponding to elements of <code translate="no" dir="ltr">tensors</code>. Every step will receive a new bucket of outputs. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the <code translate="no" dir="ltr">shapes</code> are not specified, and cannot be inferred from the elements of <code translate="no" dir="ltr">tensors</code> or if batch_size is a sequence but its length != num_buckets. Also if bucket_capacities is not None but its length != num_buckets. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/training/bucket" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/training/bucket</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
