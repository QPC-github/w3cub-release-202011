
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.contrib.training.SequenceQueueingStateSaver - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" SequenceQueueingStateSaver provides access to stateful values from input. ">
  <meta name="keywords" content="tf, contrib, training, sequencequeueingstatesaver, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/contrib/training/sequencequeueingstatesaver.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.contrib.training.SequenceQueueingStateSaver</h1>       <p>SequenceQueueingStateSaver provides access to stateful values from input.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.contrib.training.SequenceQueueingStateSaver(
    batch_size, num_unroll, input_length, input_key, input_sequences, input_context,
    initial_states, capacity=None, allow_small_batch=False, name=None
)
</pre>  <p>This class is meant to be used instead of, e.g., a <code translate="no" dir="ltr">Queue</code>, for splitting variable-length sequence inputs into segments of sequences with fixed length and batching them into mini-batches. It maintains contexts and state for a sequence across the segments. It can be used in conjunction with a <code translate="no" dir="ltr">QueueRunner</code> (see the example below).</p> <p>The <code translate="no" dir="ltr">SequenceQueueingStateSaver</code> (SQSS) accepts one example at a time via the inputs <code translate="no" dir="ltr">input_length</code>, <code translate="no" dir="ltr">input_key</code>, <code translate="no" dir="ltr">input_sequences</code> (a dict), <code translate="no" dir="ltr">input_context</code> (a dict), and <code translate="no" dir="ltr">initial_states</code> (a dict). The sequences, values in <code translate="no" dir="ltr">input_sequences</code>, may have variable first dimension (the <code translate="no" dir="ltr">padded_length</code>), though this dimension must always be a multiple of <code translate="no" dir="ltr">num_unroll</code>. All other dimensions must be fixed and accessible via <code translate="no" dir="ltr">get_shape</code> calls. The length prior to padding can be recorded in <code translate="no" dir="ltr">input_length</code>. The context values in <code translate="no" dir="ltr">input_context</code> must all have fixed and well defined dimensions. The initial state values must all have fixed and well defined dimensions.</p> <p>The SQSS splits the sequences of an input example into segments of length <code translate="no" dir="ltr">num_unroll</code>. Across examples minibatches of size <code translate="no" dir="ltr">batch_size</code> are formed. These minibatches contain a segment of the sequences, copy the context values, and maintain state, length, and key information of the original input examples. In the first segment of an example the state is still the initial state. It can then be updated; and updated state values are accessible in subsequent segments of the same example. After each segment <code translate="no" dir="ltr">batch.save_state()</code> must be called which is done by the state_saving_rnn. Without this call, the dequeue op associated with the SQSS will not run. Internally, SQSS has a queue for the input examples. Its <code translate="no" dir="ltr">capacity</code> is configurable. If set smaller than <code translate="no" dir="ltr">batch_size</code> then the dequeue op will block indefinitely. A small multiple of <code translate="no" dir="ltr">batch_size</code> is a good rule of thumb to prevent that queue from becoming a bottleneck and slowing down training. If set too large (and note that it defaults to unbounded) memory consumption goes up. Moreover, when iterating over the same input examples multiple times reusing the same <code translate="no" dir="ltr">key</code> the <code translate="no" dir="ltr">capacity</code> must be smaller than the number of examples.</p> <p>The prefetcher, which reads one unrolled, variable-length input sequence at a time, is accessible via <code translate="no" dir="ltr">prefetch_op</code>. The underlying <code translate="no" dir="ltr">Barrier</code> object is accessible via <code translate="no" dir="ltr">barrier</code>. Processed minibatches, as well as state read and write capabilities are accessible via <code translate="no" dir="ltr">next_batch</code>. Specifically, <code translate="no" dir="ltr">next_batch</code> provides access to all of the minibatched data, including the following, see <code translate="no" dir="ltr">NextQueuedSequenceBatch</code> for details:</p> <ul> <li>
<code translate="no" dir="ltr">total_length</code>, <code translate="no" dir="ltr">length</code>, <code translate="no" dir="ltr">insertion_index</code>, <code translate="no" dir="ltr">key</code>, <code translate="no" dir="ltr">next_key</code>,</li> <li>
<code translate="no" dir="ltr">sequence</code> (the index each minibatch entry's time segment index),</li> <li>
<code translate="no" dir="ltr">sequence_count</code> (the total time segment count for each minibatch entry),</li> <li>
<code translate="no" dir="ltr">context</code> (a dict of the copied minibatched context values),</li> <li>
<code translate="no" dir="ltr">sequences</code> (a dict of the split minibatched variable-length sequences),</li> <li>
<code translate="no" dir="ltr">state</code> (to access the states of the current segments of these entries)</li> <li>
<code translate="no" dir="ltr">save_state</code> (to save the states for the next segments of these entries)</li> </ul> <h4 id="example_usage" data-text="Example usage:" tabindex="0">Example usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">batch_size = 32
num_unroll = 20
lstm_size = 8
cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=lstm_size)
initial_state_values = tf.zeros(cell.state_size, dtype=tf.float32)

raw_data = get_single_input_from_input_reader()
length, key, sequences, context = my_parser(raw_data)
assert "input" in sequences.keys()
assert "label" in context.keys()
initial_states = {"lstm_state": initial_state_value}

stateful_reader = tf.SequenceQueueingStateSaver(
    batch_size, num_unroll,
    length=length, input_key=key, input_sequences=sequences,
    input_context=context, initial_states=initial_states,
    capacity=batch_size*100)

batch = stateful_reader.next_batch
inputs = batch.sequences["input"]
context_label = batch.context["label"]

inputs_by_time = tf.split(value=inputs, num_or_size_splits=num_unroll, axis=1)
assert len(inputs_by_time) == num_unroll

lstm_output, _ = tf.contrib.rnn.static_state_saving_rnn(
  cell,
  inputs_by_time,
  state_saver=batch,
  state_name="lstm_state")

# Start a prefetcher in the background
sess = tf.compat.v1.Session()
num_threads = 3
queue_runner = tf.compat.v1.train.QueueRunner(
    stateful_reader, [stateful_reader.prefetch_op] * num_threads)
tf.compat.v1.train.add_queue_runner(queue_runner)
tf.compat.v1.train.start_queue_runners(sess=session)

while True:
  # Step through batches, perform training or inference...
  session.run([lstm_output])
</pre>
<blockquote class="note">
<strong>Note:</strong><span> Usually the barrier is given to a QueueRunner as in the examples above. The QueueRunner will close the barrier if the prefetch_op receives an OutOfRange Error from upstream input queues (i.e., reaches the end of the input). If the barrier is closed no further new examples are added to the SQSS. The underlying barrier might, however, still contain further unroll-steps of examples that have not undergone all iterations. To gracefully finish all examples, the flag <code translate="no" dir="ltr">allow_small_batch</code> must be set to true, which causes the SQSS to issue progressively smaller mini-batches with the remaining examples.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> int or int32 scalar <code translate="no" dir="ltr">Tensor</code>, how large minibatches should be when accessing the <code translate="no" dir="ltr">state()</code> method and <code translate="no" dir="ltr">context</code>, <code translate="no" dir="ltr">sequences</code>, etc, properties. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_unroll</code> </td> <td> Python integer, how many time steps to unroll at a time. The input sequences of length <code translate="no" dir="ltr">k</code> are then split into <code translate="no" dir="ltr">k / num_unroll</code> many segments. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_length</code> </td> <td> An int32 scalar <code translate="no" dir="ltr">Tensor</code>, the length of the sequence prior to padding. This value may be at most <code translate="no" dir="ltr">padded_length</code> for any given input (see below for the definition of <code translate="no" dir="ltr">padded_length</code>). Batched and total lengths of the current iteration are made accessible via the <code translate="no" dir="ltr">length</code> and <code translate="no" dir="ltr">total_length</code> properties. The shape of input_length (scalar) must be fully specified. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_key</code> </td> <td> A string scalar <code translate="no" dir="ltr">Tensor</code>, the <strong>unique</strong> key for the given input. This is used to keep track of the split minibatch elements of this input. Batched keys of the current iteration are made accessible via the <code translate="no" dir="ltr">key</code> property. The shape of <code translate="no" dir="ltr">input_key</code> (scalar) must be fully specified. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_sequences</code> </td> <td> A dict mapping string names to <code translate="no" dir="ltr">Tensor</code> values. The values must all have matching first dimension, called <code translate="no" dir="ltr">padded_length</code>. The <code translate="no" dir="ltr">SequenceQueueingStateSaver</code> will split these tensors along this first dimension into minibatch elements of dimension <code translate="no" dir="ltr">num_unroll</code>. Batched and segmented sequences of the current iteration are made accessible via the <code translate="no" dir="ltr">sequences</code> property. <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">padded_length</code> may be dynamic, and may vary from input to input, but must always be a multiple of <code translate="no" dir="ltr">num_unroll</code>. The remainder of the shape (other than the first dimension) must be fully specified. </span>
</blockquote>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_context</code> </td> <td> A dict mapping string names to <code translate="no" dir="ltr">Tensor</code> values. The values are treated as "global" across all time splits of the given input, and will be copied across for all minibatch elements accordingly. Batched and copied context of the current iteration are made accessible via the <code translate="no" dir="ltr">context</code> property.<blockquote class="note">
<strong>Note:</strong><span> All input_context values must have fully defined shapes. </span>
</blockquote>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">initial_states</code> </td> <td> A dict mapping string state names to multi-dimensional values (e.g. constants or tensors). This input defines the set of states that will be kept track of during computing iterations, and which can be accessed via the <code translate="no" dir="ltr">state</code> and <code translate="no" dir="ltr">save_state</code> methods.<blockquote class="note">
<strong>Note:</strong><span> All initial_state values must have fully defined shapes. </span>
</blockquote>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">capacity</code> </td> <td> The max capacity of the SQSS in number of examples. Needs to be at least <code translate="no" dir="ltr">batch_size</code>. Defaults to unbounded. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">allow_small_batch</code> </td> <td> If true, the SQSS will return smaller batches when there aren't enough input examples to fill a whole batch and the end of the input has been reached (i.e., the underlying barrier has been closed). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> An op name string (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> if any of the inputs is not an expected type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if any of the input values is inconsistent, e.g. if not enough shape information is available from inputs to build the state saver. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">barrier</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">next_batch</code> </td> <td> The <code translate="no" dir="ltr">NextQueuedSequenceBatch</code> providing access to batched output data. <p>Also provides access to the <code translate="no" dir="ltr">state</code> and <code translate="no" dir="ltr">save_state</code> methods. The first time this gets called, it additionally prepares barrier reads and creates <code translate="no" dir="ltr">NextQueuedSequenceBatch</code> / next_batch objects. Subsequent calls simply return the previously created <code translate="no" dir="ltr">next_batch</code>.</p> <p>In order to access data in <code translate="no" dir="ltr">next_batch</code> without blocking, the <code translate="no" dir="ltr">prefetch_op</code> must have been run at least <code translate="no" dir="ltr">batch_size</code> times (ideally in a separate thread, or launched via a <code translate="no" dir="ltr">QueueRunner</code>). After processing a segment in <code translate="no" dir="ltr">next_batch()</code>, <code translate="no" dir="ltr">batch.save_state()</code> must be called which is done by the state_saving_rnn. Without this call, the dequeue op associated with the SQSS will not run. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_unroll</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">prefetch_op</code> </td> <td> The op used to prefetch new data into the state saver. <p>Running it once enqueues one new input example into the state saver. The first time this gets called, it additionally creates the prefetch_op. Subsequent calls simply return the previously created <code translate="no" dir="ltr">prefetch_op</code>.</p> <p>It should be run in a separate thread via e.g. a <code translate="no" dir="ltr">QueueRunner</code>. </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="0">Methods</h2> <h3 id="close" data-text="close" tabindex="0"><code translate="no" dir="ltr">close</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/contrib/training/python/training/sequence_queueing_state_saver.py#L953-L976">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
close(
    cancel_pending_enqueues=False, name=None
)
</pre> <p>Closes the barrier and the FIFOQueue.</p> <p>This operation signals that no more segments of new sequences will be enqueued. New segments of already inserted sequences may still be enqueued and dequeued if there is a sufficient number filling a batch or allow_small_batch is true. Otherwise dequeue operations will fail immediately.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">cancel_pending_enqueues</code> </td> <td> (Optional.) A boolean, defaulting to <code translate="no" dir="ltr">False</code>. If <code translate="no" dir="ltr">True</code>, all pending enqueues to the underlying queues will be cancelled, and completing already started sequences is not possible. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Optional name for the op. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The operation that closes the barrier and the FIFOQueue. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/training/SequenceQueueingStateSaver" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/training/SequenceQueueingStateSaver</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
