
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.keras.Model - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" Model groups layers into an object with training and inference features. ">
  <meta name="keywords" content="tf, keras, model, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/keras/model.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.keras.Model</h1>      <table class="tfo-notebook-buttons tfo-api" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L82-L2904">  View source on GitHub </a> </td> </table> <p><code translate="no" dir="ltr">Model</code> groups layers into an object with training and inference features.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="0">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code translate="no" dir="ltr">tf.keras.models.Model</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code translate="no" dir="ltr">tf.compat.v1.keras.Model</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code translate="no" dir="ltr">tf.compat.v1.keras.models.Model</code></a>, `tf.compat.v2.keras.Model`, `tf.compat.v2.keras.models.Model`</p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.Model(
    *args, **kwargs
)
</pre>  <p>There are two ways to instantiate a <code translate="no" dir="ltr">Model</code>:</p> <p>1 - With the "functional API", where you start from <code translate="no" dir="ltr">Input</code>, you chain layer calls to specify the model's forward pass, and finally you create your model from inputs and outputs:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
</pre> <p>2 - By subclassing the <code translate="no" dir="ltr">Model</code> class: in that case, you should define your layers in <code translate="no" dir="ltr">__init__</code> and you should implement the model's forward pass in <code translate="no" dir="ltr">call</code>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super(MyModel, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)

  def call(self, inputs):
    x = self.dense1(inputs)
    return self.dense2(x)

model = MyModel()
</pre> <p>If you subclass <code translate="no" dir="ltr">Model</code>, you can optionally have a <code translate="no" dir="ltr">training</code> argument (boolean) in <code translate="no" dir="ltr">call</code>, which you can use to specify a different behavior in training and inference:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super(MyModel, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
    self.dropout = tf.keras.layers.Dropout(0.5)

  def call(self, inputs, training=False):
    x = self.dense1(inputs)
    if training:
      x = self.dropout(x, training=training)
    return self.dense2(x)

model = MyModel()
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">layers</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">metrics_names</code> </td> <td> Returns the model's display labels for all outputs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">run_eagerly</code> </td> <td> Settable attribute indicating whether the model should run eagerly. <p>Running eagerly means that your model will be run step by step, like Python code. Your model might run slower, but it should become easier for you to debug it by stepping into individual layer calls.</p> <p>By default, we will attempt to compile your model to a static graph to deliver the best execution performance. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weights</code> </td> <td> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">state_updates</code> </td> <td> Returns the <code translate="no" dir="ltr">updates</code> from all layers that are stateful. <p>This is useful for separating training updates and state updates, e.g. when we need to update a layer's internal state during prediction. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">stateful</code> </td> <td> 
</td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="0">Methods</h2> <h3 id="compile" data-text="compile" tabindex="0"><code translate="no" dir="ltr">compile</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L184-L400">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
compile(
    optimizer='rmsprop', loss=None, metrics=None, loss_weights=None,
    sample_weight_mode=None, weighted_metrics=None, target_tensors=None,
    distribute=None, **kwargs
)
</pre> <p>Configures the model for training.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">optimizer</code> </td> <td> String (name of optimizer) or optimizer instance. See <a href="optimizers"><code translate="no" dir="ltr">tf.keras.optimizers</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss</code> </td> <td> String (name of objective function), objective function or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss"><code translate="no" dir="ltr">tf.losses.Loss</code></a> instance. See <a href="../losses"><code translate="no" dir="ltr">tf.losses</code></a>. If the model has multiple outputs, you can use a different loss on each output by passing a dictionary or a list of losses. The loss value that will be minimized by the model will then be the sum of all individual losses. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">metrics</code> </td> <td> List of metrics to be evaluated by the model during training and testing. Typically you will use <code translate="no" dir="ltr">metrics=['accuracy']</code>. To specify different metrics for different outputs of a multi-output model, you could also pass a dictionary, such as <code translate="no" dir="ltr">metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>. You can also pass a list (len = len(outputs)) of lists of metrics such as <code translate="no" dir="ltr">metrics=[['accuracy'], ['accuracy', 'mse']]</code> or <code translate="no" dir="ltr">metrics=['accuracy', ['accuracy', 'mse']]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_weights</code> </td> <td> Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs. The loss value that will be minimized by the model will then be the <em>weighted sum</em> of all individual losses, weighted by the <code translate="no" dir="ltr">loss_weights</code> coefficients. If a list, it is expected to have a 1:1 mapping to the model's outputs. If a tensor, it is expected to map output names (strings) to scalar coefficients. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight_mode</code> </td> <td> If you need to do timestep-wise sample weighting (2D weights), set this to <code translate="no" dir="ltr">"temporal"</code>. <code translate="no" dir="ltr">None</code> defaults to sample-wise weights (1D). If the model has multiple outputs, you can use a different <code translate="no" dir="ltr">sample_weight_mode</code> on each output by passing a dictionary or a list of modes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">weighted_metrics</code> </td> <td> List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">target_tensors</code> </td> <td> By default, Keras will create placeholders for the model's target, which will be fed with the target data during training. If instead you would like to use your own target tensors (in turn, Keras will not expect external Numpy data for these targets at training time), you can specify them via the <code translate="no" dir="ltr">target_tensors</code> argument. It can be a single tensor (for a single-output model), a list of tensors, or a dict mapping output names to target tensors. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">distribute</code> </td> <td> NOT SUPPORTED IN TF 2.0, please create and compile the model under distribution strategy scope instead of passing it to compile. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Any additional arguments. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of invalid arguments for <code translate="no" dir="ltr">optimizer</code>, <code translate="no" dir="ltr">loss</code>, <code translate="no" dir="ltr">metrics</code> or <code translate="no" dir="ltr">sample_weight_mode</code>. </td> </tr> </table> <h3 id="evaluate" data-text="evaluate" tabindex="0"><code translate="no" dir="ltr">evaluate</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L729-L832">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
evaluate(
    x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None,
    callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False
)
</pre> <p>Returns the loss value &amp; metrics values for the model in test mode.</p> <p>Computation is done in batches.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator/dataset). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> is your data is in the form of symbolic tensors, dataset, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional Numpy array of weights for the test samples, used for weighting the loss function. You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape <code translate="no" dir="ltr">(samples, sequence_length)</code>, to apply a different weight to every timestep of every sample. In this case you should make sure to specify <code translate="no" dir="ltr">sample_weight_mode="temporal"</code> in <code translate="no" dir="ltr">compile()</code>. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, instead pass sample weights as the third element of <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps</code> </td> <td> Integer or <code translate="no" dir="ltr">None</code>. Total number of steps (batches of samples) before declaring the evaluation round finished. Ignored with the default value of <code translate="no" dir="ltr">None</code>. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset and <code translate="no" dir="ltr">steps</code> is None, 'evaluate' will run until the dataset is exhausted. This argument is not supported with array inputs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during evaluation. See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> in case of invalid arguments. </td> </tr> </table> <h3 id="evaluate_generator" data-text="evaluate_generator" tabindex="0"><code translate="no" dir="ltr">evaluate_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L1298-L1363">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
evaluate_generator(
    generator, steps=None, callbacks=None, max_queue_size=10, workers=1,
    use_multiprocessing=False, verbose=0
)
</pre> <p>Evaluates the model on a data generator.</p> <p>The generator should return the same kind of data as accepted by <code translate="no" dir="ltr">test_on_batch</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">generator</code> </td> <td> Generator yielding tuples (inputs, targets) or (inputs, targets, sample_weights) or an instance of <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> object in order to avoid duplicate data when using multiprocessing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps</code> </td> <td> Total number of steps (batches of samples) to yield from <code translate="no" dir="ltr">generator</code> before stopping. Optional for <code translate="no" dir="ltr">Sequence</code>: if unspecified, will use the <code translate="no" dir="ltr">len(generator)</code> as a number of steps. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during evaluation. See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> maximum size for the generator queue </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> Verbosity mode, 0 or 1. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> in case of invalid arguments. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case the generator yields data in an invalid format. </td> </tr> </table> <h3 id="fit" data-text="fit" tabindex="0"><code translate="no" dir="ltr">fit</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L534-L727">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
fit(
    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,
    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,
    sample_weight=None, initial_epoch=0, steps_per_epoch=None,
    validation_steps=None, validation_freq=1, max_queue_size=10, workers=1,
    use_multiprocessing=False, **kwargs
)
</pre> <p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. Should return a tuple of either <code translate="no" dir="ltr">(inputs, targets)</code> or <code translate="no" dir="ltr">(inputs, targets, sample_weights)</code>.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> returning <code translate="no" dir="ltr">(inputs, targets)</code> or <code translate="no" dir="ltr">(inputs, targets, sample weights)</code>. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, generator, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from <code translate="no" dir="ltr">x</code>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> if your data is in the form of symbolic tensors, datasets, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">epochs</code> </td> <td> Integer. Number of epochs to train the model. An epoch is an iteration over the entire <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> data provided. Note that in conjunction with <code translate="no" dir="ltr">initial_epoch</code>, <code translate="no" dir="ltr">epochs</code> is to be understood as "final epoch". The model is not trained for a number of iterations given by <code translate="no" dir="ltr">epochs</code>, but merely until the epoch of index <code translate="no" dir="ltr">epochs</code> is reached. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Note that the progress bar is not particularly useful when logged to a file, so verbose=2 is recommended when not running interactively (eg, in a production environment). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during training. See <a href="callbacks"><code translate="no" dir="ltr">tf.keras.callbacks</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_split</code> </td> <td> Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> data provided, before shuffling. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_data</code> </td> <td> Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. <code translate="no" dir="ltr">validation_data</code> will override <code translate="no" dir="ltr">validation_split</code>. <code translate="no" dir="ltr">validation_data</code> could be: <li>tuple <code translate="no" dir="ltr">(x_val, y_val)</code> of Numpy arrays or tensors</li> <li>tuple <code translate="no" dir="ltr">(x_val, y_val, val_sample_weights)</code> of Numpy arrays</li> <li>dataset For the first two cases, <code translate="no" dir="ltr">batch_size</code> must be provided. For the last case, <code translate="no" dir="ltr">validation_steps</code> must be provided. </li>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">shuffle</code> </td> <td> Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when <code translate="no" dir="ltr">steps_per_epoch</code> is not <code translate="no" dir="ltr">None</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">class_weight</code> </td> <td> Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to "pay more attention" to samples from an under-represented class. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape <code translate="no" dir="ltr">(samples, sequence_length)</code>, to apply a different weight to every timestep of every sample. In this case you should make sure to specify <code translate="no" dir="ltr">sample_weight_mode="temporal"</code> in <code translate="no" dir="ltr">compile()</code>. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, generator, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, instead provide the sample_weights as the third element of <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">initial_epoch</code> </td> <td> Integer. Epoch at which to start training (useful for resuming a previous training run). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps_per_epoch</code> </td> <td> Integer or <code translate="no" dir="ltr">None</code>. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default <code translate="no" dir="ltr">None</code> is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted. This argument is not supported with array inputs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_steps</code> </td> <td> Only relevant if <code translate="no" dir="ltr">validation_data</code> is provided and is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If validation_data is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset and 'validation_steps' is None, validation will run until the <code translate="no" dir="ltr">validation_data</code> dataset is exhausted. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_freq</code> </td> <td> Only relevant if validation data is provided. Integer or <code translate="no" dir="ltr">collections_abc.Container</code> instance (e.g. list, tuple, etc.). If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. <code translate="no" dir="ltr">validation_freq=2</code> runs validation every 2 epochs. If a Container, specifies the epochs on which to run validation, e.g. <code translate="no" dir="ltr">validation_freq=[1, 2, 10]</code> runs validation at the end of the 1st, 2nd, and 10th epochs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Used for backwards compatibility. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">History</code> object. Its <code translate="no" dir="ltr">History.history</code> attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable). </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">RuntimeError</code> </td> <td> If the model was never compiled. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of mismatch between the provided input data and what the model expects. </td> </tr> </table> <h3 id="fit_generator" data-text="fit_generator" tabindex="0"><code translate="no" dir="ltr">fit_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L1162-L1296">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
fit_generator(
    generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None,
    validation_data=None, validation_steps=None, validation_freq=1,
    class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False,
    shuffle=True, initial_epoch=0
)
</pre> <p>Fits the model on data yielded batch-by-batch by a Python generator.</p> <p>The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.</p> <p>The use of <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> guarantees the ordering and guarantees the single use of every input per epoch when using <code translate="no" dir="ltr">use_multiprocessing=True</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">generator</code> </td> <td> A generator or an instance of <code translate="no" dir="ltr">Sequence</code> (<a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a>) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either <ul> <li>a tuple <code translate="no" dir="ltr">(inputs, targets)</code>
</li> <li>a tuple <code translate="no" dir="ltr">(inputs, targets, sample_weights)</code>. This tuple (a single output of the generator) makes a single batch. Therefore, all arrays in this tuple must have the same length (equal to the size of this batch). Different batches may have different sizes. For example, the last batch of the epoch is commonly smaller than the others, if the size of the dataset is not divisible by the batch size. The generator is expected to loop over its data indefinitely. An epoch finishes when <code translate="no" dir="ltr">steps_per_epoch</code> batches have been seen by the model. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps_per_epoch</code> </td> <td> Total number of steps (batches of samples) to yield from <code translate="no" dir="ltr">generator</code> before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of samples of your dataset divided by the batch size. Optional for <code translate="no" dir="ltr">Sequence</code>: if unspecified, will use the <code translate="no" dir="ltr">len(generator)</code> as a number of steps. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">epochs</code> </td> <td> Integer, total number of iterations on the data. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> Verbosity mode, 0, 1, or 2. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of callbacks to be called during training. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_data</code> </td> <td> This can be either <li>a generator for the validation data</li> <li>a tuple (inputs, targets)</li> <li>a tuple (inputs, targets, sample_weights). </li>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_steps</code> </td> <td> Only relevant if <code translate="no" dir="ltr">validation_data</code> is a generator. Total number of steps (batches of samples) to yield from <code translate="no" dir="ltr">generator</code> before stopping. Optional for <code translate="no" dir="ltr">Sequence</code>: if unspecified, will use the <code translate="no" dir="ltr">len(validation_data)</code> as a number of steps. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">validation_freq</code> </td> <td> Only relevant if validation data is provided. Integer or <code translate="no" dir="ltr">collections_abc.Container</code> instance (e.g. list, tuple, etc.). If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. <code translate="no" dir="ltr">validation_freq=2</code> runs validation every 2 epochs. If a Container, specifies the epochs on which to run validation, e.g. <code translate="no" dir="ltr">validation_freq=[1, 2, 10]</code> runs validation at the end of the 1st, 2nd, and 10th epochs. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">class_weight</code> </td> <td> Dictionary mapping class indices to a weight for the class. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Integer. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shuffle</code> </td> <td> Boolean. Whether to shuffle the order of the batches at the beginning of each epoch. Only used with instances of <code translate="no" dir="ltr">Sequence</code> (<a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a>). Has no effect when <code translate="no" dir="ltr">steps_per_epoch</code> is not <code translate="no" dir="ltr">None</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">initial_epoch</code> </td> <td> Epoch at which to start training (useful for resuming a previous training run) </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">History</code> object. </td> </tr> 
</table> <h4 id="example" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def generate_arrays_from_file(path):
    while 1:
        f = open(path)
        for line in f:
            # create numpy arrays of input data
            # and labels, from each line in the file
            x1, x2, y = process_line(line)
            yield ({'input_1': x1, 'input_2': x2}, {'output': y})
        f.close()

model.fit_generator(generate_arrays_from_file('/my_file.txt'),
                    steps_per_epoch=10000, epochs=10)
</pre> <p>Raises: ValueError: In case the generator yields data in an invalid format.</p> <h3 id="get_layer" data-text="get_layer" tabindex="0"><code translate="no" dir="ltr">get_layer</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L500-L531">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_layer(
    name=None, index=None
)
</pre> <p>Retrieves a layer based on either its name (unique) or index.</p> <p>If <code translate="no" dir="ltr">name</code> and <code translate="no" dir="ltr">index</code> are both provided, <code translate="no" dir="ltr">index</code> will take precedence. Indices are based on order of horizontal graph traversal (bottom-up).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> String, name of layer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">index</code> </td> <td> Integer, index of layer. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A layer instance. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of invalid layer name or index. </td> </tr> </table> <h3 id="load_weights" data-text="load_weights" tabindex="0"><code translate="no" dir="ltr">load_weights</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L175-L182">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
load_weights(
    filepath, by_name=False
)
</pre> <p>Loads all layer weights, either from a TensorFlow or an HDF5 file.</p> <h3 id="predict" data-text="predict" tabindex="0"><code translate="no" dir="ltr">predict</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L834-L908">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
predict(
    x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,
    workers=1, use_multiprocessing=False
)
</pre> <p>Generates output predictions for the input samples.</p> <p>Computation is done in batches.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input samples. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">batch_size</code> </td> <td> Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> is your data is in the form of symbolic tensors, dataset, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> Verbosity mode, 0 or 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps</code> </td> <td> Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of <code translate="no" dir="ltr">None</code>. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset and <code translate="no" dir="ltr">steps</code> is None, <code translate="no" dir="ltr">predict</code> will run until the input dataset is exhausted. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during prediction. See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Numpy array(s) of predictions. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of mismatch between the provided input data and the model's expectations, or in case a stateful model receives a number of samples that is not a multiple of the batch size. </td> </tr> </table> <h3 id="predict_generator" data-text="predict_generator" tabindex="0"><code translate="no" dir="ltr">predict_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L1365-L1420">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
predict_generator(
    generator, steps=None, callbacks=None, max_queue_size=10, workers=1,
    use_multiprocessing=False, verbose=0
)
</pre> <p>Generates predictions for the input samples from a data generator.</p> <p>The generator should return the same kind of data as accepted by <code translate="no" dir="ltr">predict_on_batch</code>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">generator</code> </td> <td> Generator yielding batches of input samples or an instance of <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> object in order to avoid duplicate data when using multiprocessing. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">steps</code> </td> <td> Total number of steps (batches of samples) to yield from <code translate="no" dir="ltr">generator</code> before stopping. Optional for <code translate="no" dir="ltr">Sequence</code>: if unspecified, will use the <code translate="no" dir="ltr">len(generator)</code> as a number of steps. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">callbacks</code> </td> <td> List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during prediction. See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks">callbacks</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_queue_size</code> </td> <td> Maximum size for the generator queue. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">workers</code> </td> <td> Integer. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_multiprocessing</code> </td> <td> Boolean. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">verbose</code> </td> <td> verbosity mode, 0 or 1. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Numpy array(s) of predictions. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case the generator yields data in an invalid format. </td> </tr> </table> <h3 id="predict_on_batch" data-text="predict_on_batch" tabindex="0"><code translate="no" dir="ltr">predict_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L1114-L1160">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
predict_on_batch(
    x
)
</pre> <p>Returns predictions for a single batch of samples.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. </li>
</ul>
</td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Numpy array(s) of predictions. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of mismatch between given number of inputs and expectations of the model. </td> </tr> </table> <h3 id="reset_metrics" data-text="reset_metrics" tabindex="0"><code translate="no" dir="ltr">reset_metrics</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L910-L918">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
reset_metrics()
</pre> <p>Resets the state of metrics.</p> <h3 id="reset_states" data-text="reset_states" tabindex="0"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L443-L446">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
reset_states()
</pre> <h3 id="save" data-text="save" tabindex="0"><code translate="no" dir="ltr">save</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L1122-L1171">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
save(
    filepath, overwrite=True, include_optimizer=True, save_format=None,
    signatures=None
)
</pre> <p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p> <h4 id="the_savefile_includes" data-text="The savefile includes:" tabindex="0">The savefile includes:</h4> <ul> <li>The model architecture, allowing to re-instantiate the model.</li> <li>The model weights.</li> <li>The state of the optimizer, allowing to resume training exactly where you left off.</li> </ul> <p>This allows you to save the entirety of the state of a model in a single file.</p> <p>Saved models can be reinstantiated via <a href="models/load_model"><code translate="no" dir="ltr">keras.models.load_model</code></a>. The model returned by <code translate="no" dir="ltr">load_model</code> is a compiled model ready to be used (unless the saved model was never compiled in the first place).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> <tr class="alt"> <td colspan="2"> filepath: String, path to SavedModel or H5 file to save the model. overwrite: Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt. include_optimizer: If True, save optimizer's state together. save_format: Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. The default is currently 'h5', but will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently disabled (use <a href="experimental/export_saved_model"><code translate="no" dir="ltr">tf.keras.experimental.export_saved_model</code></a> instead). </td> </tr> <tr> <td> <code translate="no" dir="ltr">signatures</code> </td> <td> Signatures to save with the SavedModel. Applicable to the 'tf' format only. Please see the <code translate="no" dir="ltr">signatures</code> argument in <a href="../saved_model/save"><code translate="no" dir="ltr">tf.saved_model.save</code></a> for details. </td> </tr> </table> <h4 id="example_2" data-text="Example:" tabindex="0">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">from keras.models import load_model

model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'
del model  # deletes the existing model

# returns a compiled model
# identical to the previous one
model = load_model('my_model.h5')
</pre> <h3 id="save_weights" data-text="save_weights" tabindex="0"><code translate="no" dir="ltr">save_weights</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L1173-L1292">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
save_weights(
    filepath, overwrite=True, save_format=None
)
</pre> <p>Saves all layer weights.</p> <p>Either saves in HDF5 or in TensorFlow format based on the <code translate="no" dir="ltr">save_format</code> argument.</p> <p>When saving in HDF5 format, the weight file has:</p> <ul> <li>
<code translate="no" dir="ltr">layer_names</code> (attribute), a list of strings (ordered names of model layers).</li> <li>For every layer, a <code translate="no" dir="ltr">group</code> named <code translate="no" dir="ltr">layer.name</code> <ul> <li>For every such layer group, a group attribute <code translate="no" dir="ltr">weight_names</code>, a list of strings (ordered names of weights tensor of the layer).</li> <li>For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</li> </ul>
</li> </ul> <p>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a>, including any <code translate="no" dir="ltr">Layer</code> instances or <code translate="no" dir="ltr">Optimizer</code> instances assigned to object attributes. For networks constructed from inputs and outputs using <code translate="no" dir="ltr">tf.keras.Model(inputs, outputs)</code>, <code translate="no" dir="ltr">Layer</code> instances used by the network are tracked/saved automatically. For user-defined classes which inherit from <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a>, <code translate="no" dir="ltr">Layer</code> instances must be assigned to object attributes, typically in the constructor. See the documentation of <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> and <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a> for details.</p> <p>While the formats are the same, do not mix <code translate="no" dir="ltr">save_weights</code> and <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a>. Checkpoints saved by <a href="model#save_weights"><code translate="no" dir="ltr">Model.save_weights</code></a> should be loaded using <a href="model#load_weights"><code translate="no" dir="ltr">Model.load_weights</code></a>. Checkpoints saved using <a href="../train/checkpoint#save"><code translate="no" dir="ltr">tf.train.Checkpoint.save</code></a> should be restored using the corresponding <a href="../train/checkpoint#restore"><code translate="no" dir="ltr">tf.train.Checkpoint.restore</code></a>. Prefer <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> over <code translate="no" dir="ltr">save_weights</code> for training checkpoints.</p> <p>The TensorFlow format matches objects and variables by starting at a root object, <code translate="no" dir="ltr">self</code> for <code translate="no" dir="ltr">save_weights</code>, and greedily matching attribute names. For <a href="model#save"><code translate="no" dir="ltr">Model.save</code></a> this is the <code translate="no" dir="ltr">Model</code>, and for <a href="../train/checkpoint#save"><code translate="no" dir="ltr">Checkpoint.save</code></a> this is the <code translate="no" dir="ltr">Checkpoint</code> even if the <code translate="no" dir="ltr">Checkpoint</code> has a model attached. This means saving a <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a> using <code translate="no" dir="ltr">save_weights</code> and loading into a <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> with a <code translate="no" dir="ltr">Model</code> attached (or vice versa) will not match the <code translate="no" dir="ltr">Model</code>'s variables. See the <a href="https://www.tensorflow.org/alpha/guide/checkpoints">guide to training checkpoints</a> for details on the TensorFlow format.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">filepath</code> </td> <td> String, path to the file to save the weights to. When saving in TensorFlow format, this is the prefix used for checkpoint files (multiple files are generated). Note that the '.h5' suffix causes weights to be saved in HDF5 format. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">overwrite</code> </td> <td> Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">save_format</code> </td> <td> Either 'tf' or 'h5'. A <code translate="no" dir="ltr">filepath</code> ending in '.h5' or '.keras' will default to HDF5 if <code translate="no" dir="ltr">save_format</code> is <code translate="no" dir="ltr">None</code>. Otherwise <code translate="no" dir="ltr">None</code> defaults to 'tf'. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ImportError</code> </td> <td> If h5py is not available when attempting to save in HDF5 format. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> For invalid/unknown format arguments. </td> </tr> </table> <h3 id="summary" data-text="summary" tabindex="0"><code translate="no" dir="ltr">summary</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L1434-L1461">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
summary(
    line_length=None, positions=None, print_fn=None
)
</pre> <p>Prints a string summary of the network.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">line_length</code> </td> <td> Total length of printed lines (e.g. set this to adapt the display to different terminal window sizes). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">positions</code> </td> <td> Relative or absolute positions of log elements in each line. If not provided, defaults to <code translate="no" dir="ltr">[.33, .55, .67, 1.]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">print_fn</code> </td> <td> Print function to use. Defaults to <code translate="no" dir="ltr">print</code>. It will be called on each line of the summary. You can set it to a custom function in order to capture the string summary. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">summary()</code> is called before the model is built. </td> </tr> </table> <h3 id="test_on_batch" data-text="test_on_batch" tabindex="0"><code translate="no" dir="ltr">test_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L1026-L1112">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
test_on_batch(
    x, y=None, sample_weight=None, reset_metrics=True
)
</pre> <p>Test the model on a single batch of samples.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional array of the same length as x, containing weights to apply to the model's loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode="temporal" in compile(). This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reset_metrics</code> </td> <td> If <code translate="no" dir="ltr">True</code>, the metrics returned will be only for this batch. If <code translate="no" dir="ltr">False</code>, the metrics will be statefully accumulated across batches. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of invalid user-provided arguments. </td> </tr> </table> <h3 id="to_json" data-text="to_json" tabindex="0"><code translate="no" dir="ltr">to_json</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L1392-L1407">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_json(
    **kwargs
)
</pre> <p>Returns a JSON string containing the network configuration.</p> <p>To load a network from a JSON save file, use <a href="models/model_from_json"><code translate="no" dir="ltr">keras.models.model_from_json(json_string, custom_objects={})</code></a>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Additional keyword arguments to be passed to <code translate="no" dir="ltr">json.dumps()</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A JSON string. </td> </tr> 
</table> <h3 id="to_yaml" data-text="to_yaml" tabindex="0"><code translate="no" dir="ltr">to_yaml</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/network.py#L1409-L1432">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
to_yaml(
    **kwargs
)
</pre> <p>Returns a yaml string containing the network configuration.</p> <p>To load a network from a yaml save file, use <a href="models/model_from_yaml"><code translate="no" dir="ltr">keras.models.model_from_yaml(yaml_string, custom_objects={})</code></a>.</p> <p><code translate="no" dir="ltr">custom_objects</code> should be a dictionary mapping the names of custom losses / layers / etc to the corresponding functions / classes.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Additional keyword arguments to be passed to <code translate="no" dir="ltr">yaml.dump()</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A YAML string. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ImportError</code> </td> <td> if yaml module is not found. </td> </tr> </table> <h3 id="train_on_batch" data-text="train_on_batch" tabindex="0"><code translate="no" dir="ltr">train_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/keras/engine/training.py#L920-L1024">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
train_on_batch(
    x, y=None, sample_weight=None, class_weight=None, reset_metrics=True
)
</pre> <p>Runs a single gradient update on a single batch of data.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. </li>
</ul>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional array of the same length as x, containing weights to apply to the model's loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode="temporal" in compile(). This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">class_weight</code> </td> <td> Optional dictionary mapping class indices (integers) to a weight (float) to apply to the model's loss for the samples from this class during training. This can be useful to tell the model to "pay more attention" to samples from an under-represented class. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reset_metrics</code> </td> <td> If <code translate="no" dir="ltr">True</code>, the metrics returned will be only for this batch. If <code translate="no" dir="ltr">False</code>, the metrics will be statefully accumulated across batches. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Scalar training loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> In case of invalid user-provided arguments. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
