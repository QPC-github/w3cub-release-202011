
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>linear_model.PassiveAggressiveRegressor() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Passive Aggressive Regressor ">
  <meta name="keywords" content="sklearn, linear, model, passiveaggressiveregressor, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_learn/modules/generated/sklearn.linear_model.passiveaggressiveregressor.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/scikit_learn.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="sklearn-linear-model-passiveaggressiveregressor">sklearn.linear_model.PassiveAggressiveRegressor</h1> <dl class="class"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor">
<code>class sklearn.linear_model.PassiveAggressiveRegressor(C=1.0, fit_intercept=True, max_iter=None, tol=None, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss=’epsilon_insensitive’, epsilon=0.1, random_state=None, warm_start=False, average=False, n_iter=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/passive_aggressive.py#L263"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Passive Aggressive Regressor</p> <p>Read more in the <a class="reference internal" href="../linear_model#passive-aggressive"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>C : float</code> </dt> <dd>
<p class="first last">Maximum step size (regularization). Defaults to 1.0.</p> </dd> <dt>
<code>fit_intercept : bool</code> </dt> <dd>
<p class="first last">Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</p> </dd> <dt>
<code>max_iter : int, optional</code> </dt> <dd>
<p class="first">The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the <code>fit</code> method, and not the <code>partial_fit</code>. Defaults to 5. Defaults to 1000 from 0.21, or if tol is not None.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.19.</span></p> </div> </dd> <dt>
<code>tol : float or None, optional</code> </dt> <dd>
<p class="first">The stopping criterion. If it is not None, the iterations will stop when (loss &gt; previous_loss - tol). Defaults to None. Defaults to 1e-3 from 0.21.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.19.</span></p> </div> </dd> <dt>
<code>early_stopping : bool, default=False</code> </dt> <dd>
<p class="first">Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.20.</span></p> </div> </dd> <dt>
<code>validation_fraction : float, default=0.1</code> </dt> <dd>
<p class="first">The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.20.</span></p> </div> </dd> <dt>
<code>n_iter_no_change : int, default=5</code> </dt> <dd>
<p class="first">Number of iterations with no improvement to wait before early stopping.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.20.</span></p> </div> </dd> <dt>
<code>shuffle : bool, default=True</code> </dt> <dd>
<p class="first last">Whether or not the training data should be shuffled after each epoch.</p> </dd> <dt>
<code>verbose : integer, optional</code> </dt> <dd>
<p class="first last">The verbosity level</p> </dd> <dt>
<code>loss : string, optional</code> </dt> <dd>
<p class="first last">The loss function to be used: epsilon_insensitive: equivalent to PA-I in the reference paper. squared_epsilon_insensitive: equivalent to PA-II in the reference paper.</p> </dd> <dt>
<code>epsilon : float</code> </dt> <dd>
<p class="first last">If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</p> </dd> <dt>
<code>random_state : int, RandomState instance or None, optional, default=None</code> </dt> <dd>
<p class="first last">The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p> </dd> <dt>
<code>warm_start : bool, optional</code> </dt> <dd>
<p class="first">When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See <a class="reference internal" href="http://scikit-learn.org/stable/glossary.html#term-warm-start"><span class="xref std std-term">the Glossary</span></a>.</p> <p class="last">Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.</p> </dd> <dt>
<code>average : bool or int, optional</code> </dt> <dd>
<p class="first">When set to True, computes the averaged SGD weights and stores the result in the <code>coef_</code> attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.19: </span>parameter <em>average</em> to use weights averaging in SGD</p> </div> </dd> <dt>
<code>n_iter : int, optional</code> </dt> <dd>
<p class="first">The number of passes over the training data (aka epochs). Defaults to None. Deprecated, will be removed in 0.21.</p> <div class="last versionchanged"> <p><span class="versionmodified">Changed in version 0.19: </span>Deprecated</p> </div> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>coef_ : array, shape = [1, n_features] if n_classes == 2 else [n_classes, n_features]</code> </dt> <dd>
<p class="first last">Weights assigned to the features.</p> </dd> <dt>
<code>intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]</code> </dt> <dd>
<p class="first last">Constants in decision function.</p> </dd> <dt>
<code>n_iter_ : int</code> </dt> <dd>
<p class="first last">The actual number of iterations to reach the stopping criterion.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code>SGDRegressor</code></a></p> </div> <h4 class="rubric">References</h4> <p>Online Passive-Aggressive Algorithms &lt;<a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf">http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf</a>&gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.linear_model import PassiveAggressiveRegressor
&gt;&gt;&gt; from sklearn.datasets import make_regression
&gt;&gt;&gt;
&gt;&gt;&gt; X, y = make_regression(n_features=4, random_state=0)
&gt;&gt;&gt; regr = PassiveAggressiveRegressor(max_iter=100, random_state=0)
&gt;&gt;&gt; regr.fit(X, y)
PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',
              max_iter=100, n_iter=None, n_iter_no_change=5,
              random_state=0, shuffle=True, tol=None,
              validation_fraction=0.1, verbose=0, warm_start=False)
&gt;&gt;&gt; print(regr.coef_)
[20.48736655 34.18818427 67.59122734 87.94731329]
&gt;&gt;&gt; print(regr.intercept_)
[-0.02306214]
&gt;&gt;&gt; print(regr.predict([[0, 0, 0, 0]]))
[-0.02306214]
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.densify" title="sklearn.linear_model.PassiveAggressiveRegressor.densify"><code>densify</code></a>()</td> <td>Convert coefficient matrix to dense array format.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.fit" title="sklearn.linear_model.PassiveAggressiveRegressor.fit"><code>fit</code></a>(X, y[, coef_init, intercept_init])</td> <td>Fit linear model with Passive Aggressive algorithm.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.get_params" title="sklearn.linear_model.PassiveAggressiveRegressor.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.partial_fit" title="sklearn.linear_model.PassiveAggressiveRegressor.partial_fit"><code>partial_fit</code></a>(X, y)</td> <td>Fit linear model with Passive Aggressive algorithm.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.predict" title="sklearn.linear_model.PassiveAggressiveRegressor.predict"><code>predict</code></a>(X)</td> <td>Predict using the linear model</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.score" title="sklearn.linear_model.PassiveAggressiveRegressor.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the coefficient of determination R^2 of the prediction.</td> </tr> <tr>
<td>
<code>set_params</code>(*args, **kwargs)</td> <td></td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.PassiveAggressiveRegressor.sparsify" title="sklearn.linear_model.PassiveAggressiveRegressor.sparsify"><code>sparsify</code></a>()</td> <td>Convert coefficient matrix to sparse format.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.__init__">
<code>__init__(C=1.0, fit_intercept=True, max_iter=None, tol=None, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss=’epsilon_insensitive’, epsilon=0.1, random_state=None, warm_start=False, average=False, n_iter=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/passive_aggressive.py#L406"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.densify">
<code>densify()</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/base.py#L314"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Convert coefficient matrix to dense array format.</p> <p>Converts the <code>coef_</code> member (back) to a numpy.ndarray. This is the default format of <code>coef_</code> and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : estimator</code> </dt>  </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.fit">
<code>fit(X, y, coef_init=None, intercept_init=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/passive_aggressive.py#L455"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit linear model with Passive Aggressive algorithm.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix}, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">Training data</p> </dd> <dt>
<code>y : numpy array of shape [n_samples]</code> </dt> <dd>
<p class="first last">Target values</p> </dd> <dt>
<code>coef_init : array, shape = [n_features]</code> </dt> <dd>
<p class="first last">The initial coefficients to warm-start the optimization.</p> </dd> <dt>
<code>intercept_init : array, shape = [1]</code> </dt> <dd>
<p class="first last">The initial intercept to warm-start the optimization.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : returns an instance of self.</code> </dt>  </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L166"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>deep : boolean, optional</code> </dt> <dd>
<p class="first last">If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : mapping of string to any</code> </dt> <dd>
<p class="first last">Parameter names mapped to their values.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.partial_fit">
<code>partial_fit(X, y)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/passive_aggressive.py#L432"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit linear model with Passive Aggressive algorithm.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix}, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">Subset of training data</p> </dd> <dt>
<code>y : numpy array of shape [n_samples]</code> </dt> <dd>
<p class="first last">Subset of target values</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : returns an instance of self.</code> </dt>  </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/stochastic_gradient.py#L1259"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix}, shape (n_samples, n_features)</code> </dt>  </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt><strong>array, shape (n_samples,)</strong></dt> <dd>
<p class="first last">Predicted target values per element in X.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L296"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the coefficient of determination R^2 of the prediction.</p> <p>The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = (n_samples, n_features)</code> </dt> <dd>
<p class="first last">Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<code>y : array-like, shape = (n_samples) or (n_samples, n_outputs)</code> </dt> <dd>
<p class="first last">True values for X.</p> </dd> <dt>
<code>sample_weight : array-like, shape = [n_samples], optional</code> </dt> <dd>
<p class="first last">Sample weights.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>score : float</code> </dt> <dd>
<p class="first last">R^2 of self.predict(X) wrt. y.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.PassiveAggressiveRegressor.sparsify">
<code>sparsify()</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/linear_model/base.py#L332"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Convert coefficient matrix to sparse format.</p> <p>Converts the <code>coef_</code> member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.</p> <p>The <code>intercept_</code> member is not converted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : estimator</code> </dt>  </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>For non-sparse models, i.e. when there are not many zeros in <code>coef_</code>, this may actually <em>increase</em> memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with <code>(coef_ == 0).sum()</code>, must be more than 50% for this to provide significant benefits.</p> <p>After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.</p> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    © 2007–2018 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html" class="_attribution-link">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
