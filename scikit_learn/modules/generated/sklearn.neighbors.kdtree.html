
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>neighbors.KDTree - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" KDTree for fast generalized N-point problems ">
  <meta name="keywords" content="sklearn, neighbors, kdtree, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_learn/modules/generated/sklearn.neighbors.kdtree.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/scikit_learn.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="sklearn-neighbors-kdtree">sklearn.neighbors.KDTree</h1> <dl class="class"> <dt id="sklearn.neighbors.KDTree">
<code>class sklearn.neighbors.KDTree</code> </dt> <dd>
<p>KDTree for fast generalized N-point problems</p> <p>KDTree(X, leaf_size=40, metric=’minkowski’, **kwargs)</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">n_samples is the number of points in the data set, and n_features is the dimension of the parameter space. Note: if X is a C-contiguous array of doubles then data will not be copied. Otherwise, an internal copy will be made.</p> </dd> <dt>
<code>leaf_size : positive integer (default = 40)</code> </dt> <dd>
<p class="first last">Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified <code>leaf_size</code>, a leaf node is guaranteed to satisfy <code>leaf_size &lt;= n_points &lt;= 2 * leaf_size</code>, except in the case that <code>n_samples &lt; leaf_size</code>.</p> </dd> <dt>
<code>metric : string or DistanceMetric object</code> </dt> <dd>
<p class="first last">the distance metric to use for the tree. Default=’minkowski’ with p=2 (that is, a euclidean metric). See the documentation of the DistanceMetric class for a list of available metrics. kd_tree.valid_metrics gives a list of the metrics which are valid for KDTree.</p> </dd> <dt><strong>Additional keywords are passed to the distance metric class.</strong></dt>  </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>data : memory view</code> </dt> <dd>
<p class="first last">The training data</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">Examples</h4> <p>Query for k-nearest neighbors</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; X = np.random.random((10, 3))  # 10 points in 3 dimensions
&gt;&gt;&gt; tree = KDTree(X, leaf_size=2)              
&gt;&gt;&gt; dist, ind = tree.query(X[:1], k=3)                
&gt;&gt;&gt; print(ind)  # indices of 3 closest neighbors
[0 3 1]
&gt;&gt;&gt; print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
</pre> <p>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pickle
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; X = np.random.random((10, 3))  # 10 points in 3 dimensions
&gt;&gt;&gt; tree = KDTree(X, leaf_size=2)        
&gt;&gt;&gt; s = pickle.dumps(tree)                     
&gt;&gt;&gt; tree_copy = pickle.loads(s)                
&gt;&gt;&gt; dist, ind = tree_copy.query(X[:1], k=3)     
&gt;&gt;&gt; print(ind)  # indices of 3 closest neighbors
[0 3 1]
&gt;&gt;&gt; print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
</pre> <p>Query for neighbors within a given radius</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; X = np.random.random((10, 3))  # 10 points in 3 dimensions
&gt;&gt;&gt; tree = KDTree(X, leaf_size=2)     
&gt;&gt;&gt; print(tree.query_radius(X[:1], r=0.3, count_only=True))
3
&gt;&gt;&gt; ind = tree.query_radius(X[:1], r=0.3)  
&gt;&gt;&gt; print(ind)  # indices of neighbors within distance 0.3
[3 0 1]
</pre> <p>Compute a gaussian kernel density estimate:</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(1)
&gt;&gt;&gt; X = np.random.random((100, 3))
&gt;&gt;&gt; tree = KDTree(X)                
&gt;&gt;&gt; tree.kernel_density(X[:3], h=0.1, kernel='gaussian')
array([ 6.94114649,  7.83281226,  7.2071716 ])
</pre> <p>Compute a two-point auto-correlation function</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; X = np.random.random((30, 3))
&gt;&gt;&gt; r = np.linspace(0, 1, 5)
&gt;&gt;&gt; tree = KDTree(X)                
&gt;&gt;&gt; tree.two_point_correlation(X, r)
array([ 30,  62, 278, 580, 820])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.neighbors.KDTree.kernel_density" title="sklearn.neighbors.KDTree.kernel_density"><code>kernel_density</code></a>(self, X, h[, kernel, atol, …])</td> <td>Compute the kernel density estimate at points X with the given kernel, using the distance metric specified at tree creation.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.neighbors.KDTree.query" title="sklearn.neighbors.KDTree.query"><code>query</code></a>(X[, k, return_distance, dualtree, …])</td> <td>query the tree for the k nearest neighbors</td> </tr> <tr>
<td><a class="reference internal" href="#sklearn.neighbors.KDTree.query_radius" title="sklearn.neighbors.KDTree.query_radius"><code>query_radius</code></a></td> <td>query_radius(self, X, r, count_only = False):</td> </tr> <tr>
<td><a class="reference internal" href="#sklearn.neighbors.KDTree.two_point_correlation" title="sklearn.neighbors.KDTree.two_point_correlation"><code>two_point_correlation</code></a></td> <td>Compute the two-point correlation function</td> </tr>  </table> <table class="docutils">   <tr>
<td><strong>get_arrays</strong></td> <td> </td> </tr> <tr>
<td><strong>get_n_calls</strong></td> <td> </td> </tr> <tr>
<td><strong>get_tree_stats</strong></td> <td> </td> </tr> <tr>
<td><strong>reset_n_calls</strong></td> <td> </td> </tr>  </table> <dl class="method"> <dt id="sklearn.neighbors.KDTree.__init__">
<code>__init__($self, /, *args, **kwargs)</code> </dt> <dd>
<p>Initialize self. See help(type(self)) for accurate signature.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.neighbors.KDTree.kernel_density">
<code>kernel_density(self, X, h, kernel=’gaussian’, atol=0, rtol=1E-8, breadth_first=True, return_log=False)</code> </dt> <dd>
<p>Compute the kernel density estimate at points X with the given kernel, using the distance metric specified at tree creation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">An array of points to query. Last dimension should match dimension of training data.</p> </dd> <dt>
<code>h : float</code> </dt> <dd>
<p class="first last">the bandwidth of the kernel</p> </dd> <dt>
<code>kernel : string</code> </dt> <dd>
<p class="first last">specify the kernel to use. Options are - ‘gaussian’ - ‘tophat’ - ‘epanechnikov’ - ‘exponential’ - ‘linear’ - ‘cosine’ Default is kernel = ‘gaussian’</p> </dd> <dt>
<code>atol, rtol : float (default = 0)</code> </dt> <dd>
<p class="first last">Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies <code>abs(K_true - K_ret) &lt; atol + rtol * K_ret</code> The default is zero (i.e. machine precision) for both.</p> </dd> <dt>
<code>breadth_first : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.</p> </dd> <dt>
<code>return_log : boolean (default = False)</code> </dt> <dd>
<p class="first last">return the logarithm of the result. This can be more accurate than returning the result itself for narrow kernels.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>density : ndarray</code> </dt> <dd>
<p class="first last">The array of (log)-density evaluations, shape = X.shape[:-1]</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.neighbors.KDTree.query">
<code>query(X, k=1, return_distance=True, dualtree=False, breadth_first=False)</code> </dt> <dd>
<p>query the tree for the k nearest neighbors</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">An array of points to query</p> </dd> <dt>
<code>k : integer (default = 1)</code> </dt> <dd>
<p class="first last">The number of nearest neighbors to return</p> </dd> <dt>
<code>return_distance : boolean (default = True)</code> </dt> <dd>
<p class="first last">if True, return a tuple (d, i) of distances and indices if False, return array i</p> </dd> <dt>
<code>dualtree : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, use the dual tree formalism for the query: a tree is built for the query points, and the pair of trees is used to efficiently search this space. This can lead to better performance as the number of points grows large.</p> </dd> <dt>
<code>breadth_first : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, then query the nodes in a breadth-first manner. Otherwise, query the nodes in a depth-first manner.</p> </dd> <dt>
<code>sort_results : boolean (default = True)</code> </dt> <dd>
<p class="first last">if True, then distances and indices of each point are sorted on return, so that the first column contains the closest points. Otherwise, neighbors are returned in an arbitrary order.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>i : if return_distance == False</code> </dt>  <dt>
<code>(d,i) : if return_distance == True</code> </dt>  <dt>
<code>d : array of doubles - shape: x.shape[:-1] + (k,)</code> </dt> <dd>
<p class="first last">each entry gives the list of distances to the neighbors of the corresponding point</p> </dd> <dt>
<code>i : array of integers - shape: x.shape[:-1] + (k,)</code> </dt> <dd>
<p class="first last">each entry gives the list of indices of neighbors of the corresponding point</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.neighbors.KDTree.query_radius">
<code>query_radius()</code> </dt> <dd>
<p>query_radius(self, X, r, count_only = False):</p> <p>query the tree for neighbors within a radius r</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">An array of points to query</p> </dd> <dt>
<code>r : distance within which neighbors are returned</code> </dt> <dd>
<p class="first last">r can be a single value, or an array of values of shape x.shape[:-1] if different radii are desired for each point.</p> </dd> <dt>
<code>return_distance : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, return distances to neighbors of each point if False, return only neighbors Note that unlike the query() method, setting return_distance=True here adds to the computation time. Not all distances need to be calculated explicitly for return_distance=False. Results are not sorted by default: see <code>sort_results</code> keyword.</p> </dd> <dt>
<code>count_only : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, return only the count of points within distance r if False, return the indices of all points within distance r If return_distance==True, setting count_only=True will result in an error.</p> </dd> <dt>
<code>sort_results : boolean (default = False)</code> </dt> <dd>
<p class="first last">if True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>count : if count_only == True</code> </dt>  <dt>
<code>ind : if count_only == False and return_distance == False</code> </dt>  <dt>
<code>(ind, dist) : if count_only == False and return_distance == True</code> </dt>  <dt>
<code>count : array of integers, shape = X.shape[:-1]</code> </dt> <dd>
<p class="first last">each entry gives the number of neighbors within a distance r of the corresponding point.</p> </dd> <dt>
<code>ind : array of objects, shape = X.shape[:-1]</code> </dt> <dd>
<p class="first last">each element is a numpy integer array listing the indices of neighbors of the corresponding point. Note that unlike the results of a k-neighbors query, the returned neighbors are not sorted by distance by default.</p> </dd> <dt>
<code>dist : array of objects, shape = X.shape[:-1]</code> </dt> <dd>
<p class="first last">each element is a numpy double array listing the distances corresponding to indices in i.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.neighbors.KDTree.two_point_correlation">
<code>two_point_correlation()</code> </dt> <dd>
<p>Compute the two-point correlation function</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">An array of points to query. Last dimension should match dimension of training data.</p> </dd> <dt>
<code>r : array_like</code> </dt> <dd>
<p class="first last">A one-dimensional array of distances</p> </dd> <dt>
<code>dualtree : boolean (default = False)</code> </dt> <dd>
<p class="first last">If true, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>counts : ndarray</code> </dt> <dd>
<p class="first last">counts[i] contains the number of pairs of points with distance less than or equal to r[i]</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    © 2007–2018 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html" class="_attribution-link">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
