
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>ensemble.BaggingClassifier() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" A Bagging classifier. ">
  <meta name="keywords" content="sklearn, ensemble, baggingclassifier, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_learn/modules/generated/sklearn.ensemble.baggingclassifier.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/scikit_learn.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="sklearn-ensemble-baggingclassifier">sklearn.ensemble.BaggingClassifier</h1> <dl class="class"> <dt id="sklearn.ensemble.BaggingClassifier">
<code>class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L426"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>A Bagging classifier.</p> <p>A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.</p> <p>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting <a class="reference internal" href="#rb1846455d0e5-1" id="id1">[1]</a>. If samples are drawn with replacement, then the method is known as Bagging <a class="reference internal" href="#rb1846455d0e5-2" id="id2">[2]</a>. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces <a class="reference internal" href="#rb1846455d0e5-3" id="id3">[3]</a>. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches <a class="reference internal" href="#rb1846455d0e5-4" id="id4">[4]</a>.</p> <p>Read more in the <a class="reference internal" href="../ensemble#bagging"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>base_estimator : object or None, optional (default=None)</code> </dt> <dd>
<p class="first last">The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree.</p> </dd> <dt>
<code>n_estimators : int, optional (default=10)</code> </dt> <dd>
<p class="first last">The number of base estimators in the ensemble.</p> </dd> <dt>
<code>max_samples : int or float, optional (default=1.0)</code> </dt> <dd>
<p class="first">The number of samples to draw from X to train each base estimator.</p> <ul class="last simple"> <li>If int, then draw <code>max_samples</code> samples.</li> <li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li> </ul> </dd> <dt>
<code>max_features : int or float, optional (default=1.0)</code> </dt> <dd>
<p class="first">The number of features to draw from X to train each base estimator.</p> <ul class="last simple"> <li>If int, then draw <code>max_features</code> features.</li> <li>If float, then draw <code>max_features * X.shape[1]</code> features.</li> </ul> </dd> <dt>
<code>bootstrap : boolean, optional (default=True)</code> </dt> <dd>
<p class="first last">Whether samples are drawn with replacement.</p> </dd> <dt>
<code>bootstrap_features : boolean, optional (default=False)</code> </dt> <dd>
<p class="first last">Whether features are drawn with replacement.</p> </dd> <dt>
<code>oob_score : bool, optional (default=False)</code> </dt> <dd>
<p class="first last">Whether to use out-of-bag samples to estimate the generalization error.</p> </dd> <dt>
<code>warm_start : bool, optional (default=False)</code> </dt> <dd>
<p class="first">When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See <a class="reference internal" href="http://scikit-learn.org/stable/glossary.html#term-warm-start"><span class="xref std std-term">the Glossary</span></a>.</p> <div class="last versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p> </div> </dd> <dt>
<code>n_jobs : int or None, optional (default=None)</code> </dt> <dd>
<p class="first last">The number of jobs to run in parallel for both <code>fit</code> and <code>predict</code>. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v0.12.6.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="http://scikit-learn.org/stable/glossary.html#term-n-jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> <dt>
<code>random_state : int, RandomState instance or None, optional (default=None)</code> </dt> <dd>
<p class="first last">If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p> </dd> <dt>
<code>verbose : int, optional (default=0)</code> </dt> <dd>
<p class="first last">Controls the verbosity when fitting and predicting.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>base_estimator_ : estimator</code> </dt> <dd>
<p class="first last">The base estimator from which the ensemble is grown.</p> </dd> <dt>
<code>estimators_ : list of estimators</code> </dt> <dd>
<p class="first last">The collection of fitted base estimators.</p> </dd> <dt>
<code>estimators_samples_ : list of arrays</code> </dt> <dd>
<p class="first last">The subset of drawn samples for each base estimator.</p> </dd> <dt>
<code>estimators_features_ : list of arrays</code> </dt> <dd>
<p class="first last">The subset of drawn features for each base estimator.</p> </dd> <dt>
<code>classes_ : array of shape = [n_classes]</code> </dt> <dd>
<p class="first last">The classes labels.</p> </dd> <dt>
<code>n_classes_ : int or list</code> </dt> <dd>
<p class="first last">The number of classes.</p> </dd> <dt>
<code>oob_score_ : float</code> </dt> <dd>
<p class="first last">Score of the training dataset obtained using an out-of-bag estimate.</p> </dd> <dt>
<code>oob_decision_function_ : array of shape = [n_samples, n_classes]</code> </dt> <dd>
<p class="first last">Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, <code>oob_decision_function_</code> might contain NaN.</p> </dd> </dl> </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="rb1846455d0e5-1" rules="none">   <tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id5">2</a>)</em> L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rb1846455d0e5-2" rules="none">   <tr>
<td class="label">[2]</td>
<td>
<em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id6">2</a>)</em> L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rb1846455d0e5-3" rules="none">   <tr>
<td class="label">[3]</td>
<td>
<em>(<a class="fn-backref" href="#id3">1</a>, <a class="fn-backref" href="#id7">2</a>)</em> T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="rb1846455d0e5-4" rules="none">   <tr>
<td class="label">[4]</td>
<td>
<em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id8">2</a>)</em> G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</td>
</tr>  </table> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.decision_function" title="sklearn.ensemble.BaggingClassifier.decision_function"><code>decision_function</code></a>(X)</td> <td>Average of the decision functions of the base classifiers.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.fit" title="sklearn.ensemble.BaggingClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</td> <td>Build a Bagging ensemble of estimators from the training set (X, y).</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.get_params" title="sklearn.ensemble.BaggingClassifier.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict" title="sklearn.ensemble.BaggingClassifier.predict"><code>predict</code></a>(X)</td> <td>Predict class for X.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_log_proba" title="sklearn.ensemble.BaggingClassifier.predict_log_proba"><code>predict_log_proba</code></a>(X)</td> <td>Predict class log-probabilities for X.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_proba" title="sklearn.ensemble.BaggingClassifier.predict_proba"><code>predict_proba</code></a>(X)</td> <td>Predict class probabilities for X.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.score" title="sklearn.ensemble.BaggingClassifier.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the mean accuracy on the given test data and labels.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.set_params" title="sklearn.ensemble.BaggingClassifier.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.__init__">
<code>__init__(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L548"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/utils/metaestimators.py#L757"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Average of the decision functions of the base classifiers.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix} of shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>score : array, shape = [n_samples, k]</code> </dt> <dd>
<p class="first last">The decision function of the input samples. The columns correspond to the classes in sorted order, as they appear in the attribute <code>classes_</code>. Regression and binary classification are special cases with <code>k == 1</code>, otherwise <code>k==n_classes</code>.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="sklearn.ensemble.BaggingClassifier.estimators_samples_">
<code>estimators_samples_</code> </dt> <dd>
<p>The subset of drawn samples for each base estimator.</p> <p>Returns a dynamically generated list of indices identifying the samples used for fitting each member of the ensemble, i.e., the in-bag samples.</p> <p>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L221"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="docutils"> <dt>Build a Bagging ensemble of estimators from the training</dt> <dd>set (X, y).</dd> </dl> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix} of shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> <dt>
<code>y : array-like, shape = [n_samples]</code> </dt> <dd>
<p class="first last">The target values (class labels in classification, real numbers in regression).</p> </dd> <dt>
<code>sample_weight : array-like, shape = [n_samples] or None</code> </dt> <dd>
<p class="first last">Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : object</code> </dt>  </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L166"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>deep : boolean, optional</code> </dt> <dd>
<p class="first last">If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : mapping of string to any</code> </dt> <dd>
<p class="first last">Parameter names mapped to their values.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L625"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class for X.</p> <p>The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix} of shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>y : array of shape = [n_samples]</code> </dt> <dd>
<p class="first last">The predicted classes.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_log_proba">
<code>predict_log_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L699"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class log-probabilities for X.</p> <p>The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix} of shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>p : array of shape = [n_samples, n_classes]</code> </dt> <dd>
<p class="first last">The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute <code>classes_</code>.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/ensemble/bagging.py#L647"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class probabilities for X.</p> <p>The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix} of shape = [n_samples, n_features]</code> </dt> <dd>
<p class="first last">The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>p : array of shape = [n_samples, n_classes]</code> </dt> <dd>
<p class="first last">The class probabilities of the input samples. The order of the classes corresponds to that in the attribute <code>classes_</code>.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L263"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = (n_samples, n_features)</code> </dt> <dd>
<p class="first last">Test samples.</p> </dd> <dt>
<code>y : array-like, shape = (n_samples) or (n_samples, n_outputs)</code> </dt> <dd>
<p class="first last">True labels for X.</p> </dd> <dt>
<code>sample_weight : array-like, shape = [n_samples], optional</code> </dt> <dd>
<p class="first last">Sample weights.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>score : float</code> </dt> <dd>
<p class="first last">Mean accuracy of self.predict(X) wrt. y.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L189"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt><strong>self</strong></dt>  </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    © 2007–2018 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" class="_attribution-link">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
