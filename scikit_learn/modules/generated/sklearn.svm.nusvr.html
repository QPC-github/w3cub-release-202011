
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>svm.NuSVR() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Nu Support Vector Regression. ">
  <meta name="keywords" content="sklearn, svm, nusvr, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/scikit_learn/modules/generated/sklearn.svm.nusvr.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="sklearn-svm-nusvr">sklearn.svm.NuSVR</h1> <dl class="class"> <dt id="sklearn.svm.NuSVR">
<code>class sklearn.svm.NuSVR(nu=0.5, C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/svm/classes.py#L881"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Nu Support Vector Regression.</p> <p>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</p> <p>The implementation is based on libsvm.</p> <p>Read more in the <a class="reference internal" href="../svm#svm-regression"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>nu : float, optional</code> </dt> <dd>
<p class="first last">An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.</p> </dd> <dt>
<code>C : float, optional (default=1.0)</code> </dt> <dd>
<p class="first last">Penalty parameter C of the error term.</p> </dd> <dt>
<code>kernel : string, optional (default=’rbf’)</code> </dt> <dd>
<p class="first last">Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.</p> </dd> <dt>
<code>degree : int, optional (default=3)</code> </dt> <dd>
<p class="first last">Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.</p> </dd> <dt>
<code>gamma : float, optional (default=’auto’)</code> </dt> <dd>
<p class="first">Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.</p> <p class="last">Current default is ‘auto’ which uses 1 / n_features, if <code>gamma='scale'</code> is passed then it uses 1 / (n_features * X.std()) as value of gamma. The current default of gamma, ‘auto’, will change to ‘scale’ in version 0.22. ‘auto_deprecated’, a deprecated version of ‘auto’ is used as a default indicating that no explicit value of gamma was passed.</p> </dd> <dt>
<code>coef0 : float, optional (default=0.0)</code> </dt> <dd>
<p class="first last">Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.</p> </dd> <dt>
<code>shrinking : boolean, optional (default=True)</code> </dt> <dd>
<p class="first last">Whether to use the shrinking heuristic.</p> </dd> <dt>
<code>tol : float, optional (default=1e-3)</code> </dt> <dd>
<p class="first last">Tolerance for stopping criterion.</p> </dd> <dt>
<code>cache_size : float, optional</code> </dt> <dd>
<p class="first last">Specify the size of the kernel cache (in MB).</p> </dd> <dt>
<code>verbose : bool, default: False</code> </dt> <dd>
<p class="first last">Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.</p> </dd> <dt>
<code>max_iter : int, optional (default=-1)</code> </dt> <dd>
<p class="first last">Hard limit on iterations within solver, or -1 for no limit.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>support_ : array-like, shape = [n_SV]</code> </dt> <dd>
<p class="first last">Indices of support vectors.</p> </dd> <dt>
<code>support_vectors_ : array-like, shape = [nSV, n_features]</code> </dt> <dd>
<p class="first last">Support vectors.</p> </dd> <dt>
<code>dual_coef_ : array, shape = [1, n_SV]</code> </dt> <dd>
<p class="first last">Coefficients of the support vector in the decision function.</p> </dd> <dt>
<code>coef_ : array, shape = [1, n_features]</code> </dt> <dd>
<p class="first">Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</p> <p class="last"><code>coef_</code> is readonly property derived from <code>dual_coef_</code> and <code>support_vectors_</code>.</p> </dd> <dt>
<code>intercept_ : array, shape = [1]</code> </dt> <dd>
<p class="first last">Constants in decision function.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="sklearn.svm.nusvc#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code>NuSVC</code></a>
</dt> <dd>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</dd> <dt>
 <a class="reference internal" href="sklearn.svm.svr#sklearn.svm.SVR" title="sklearn.svm.SVR"><code>SVR</code></a>
</dt> <dd>epsilon Support Vector Machine for regression implemented with libsvm.</dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.svm import NuSVR
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; n_samples, n_features = 10, 5
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; y = np.random.randn(n_samples)
&gt;&gt;&gt; X = np.random.randn(n_samples, n_features)
&gt;&gt;&gt; clf = NuSVR(gamma='scale', C=1.0, nu=0.1)
&gt;&gt;&gt; clf.fit(X, y)  
NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='scale',
      kernel='rbf', max_iter=-1, nu=0.1, shrinking=True, tol=0.001,
      verbose=False)
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.svm.NuSVR.fit" title="sklearn.svm.NuSVR.fit"><code>fit</code></a>(X, y[, sample_weight])</td> <td>Fit the SVM model according to the given training data.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.svm.NuSVR.get_params" title="sklearn.svm.NuSVR.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.svm.NuSVR.predict" title="sklearn.svm.NuSVR.predict"><code>predict</code></a>(X)</td> <td>Perform regression on samples in X.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.svm.NuSVR.score" title="sklearn.svm.NuSVR.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the coefficient of determination R^2 of the prediction.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.svm.NuSVR.set_params" title="sklearn.svm.NuSVR.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.svm.NuSVR.__init__">
<code>__init__(nu=0.5, C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/svm/classes.py#L991"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.svm.NuSVR.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/svm/base.py#L108"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the SVM model according to the given training data.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix}, shape (n_samples, n_features)</code> </dt> <dd>
<p class="first last">Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).</p> </dd> <dt>
<code>y : array-like, shape (n_samples,)</code> </dt> <dd>
<p class="first last">Target values (class labels in classification, real numbers in regression)</p> </dd> <dt>
<code>sample_weight : array-like, shape (n_samples,)</code> </dt> <dd>
<p class="first last">Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>self : object</code> </dt>  </dl> </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</p> <p>If X is a dense array, then the other methods will not support sparse matrices as input.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.NuSVR.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L166"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>deep : boolean, optional</code> </dt> <dd>
<p class="first last">If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>params : mapping of string to any</code> </dt> <dd>
<p class="first last">Parameter names mapped to their values.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.NuSVR.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/svm/base.py#L310"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform regression on samples in X.</p> <p>For an one-class model, +1 (inlier) or -1 (outlier) is returned.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : {array-like, sparse matrix}, shape (n_samples, n_features)</code> </dt> <dd>
<p class="first last">For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>y_pred : array, shape (n_samples,)</code> </dt>  </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.NuSVR.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L296"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the coefficient of determination R^2 of the prediction.</p> <p>The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first docutils"> <dt>
<code>X : array-like, shape = (n_samples, n_features)</code> </dt> <dd>
<p class="first last">Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<code>y : array-like, shape = (n_samples) or (n_samples, n_outputs)</code> </dt> <dd>
<p class="first last">True values for X.</p> </dd> <dt>
<code>sample_weight : array-like, shape = [n_samples], optional</code> </dt> <dd>
<p class="first last">Sample weights.</p> </dd> </dl> </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>score : float</code> </dt> <dd>
<p class="first last">R^2 of self.predict(X) wrt. y.</p> </dd> </dl> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.NuSVR.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/base.py#L189"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<dl class="first last docutils"> <dt><strong>self</strong></dt>  </dl> </td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-svm-nusvr">Examples using <code>sklearn.svm.NuSVR</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="Demonstrate how model complexity influences both prediction accuracy and computational performa...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_model_complexity_influence_thumb.png" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/applications/plot_model_complexity_influence#sphx-glr-auto-examples-applications-plot-model-complexity-influence-py"><span class="std std-ref">Model Complexity Influence</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2018 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html" class="_attribution-link">http://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
