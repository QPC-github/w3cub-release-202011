
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>A Guide to TF Layers&#58; Building a Convolutional Neural Network - TensorFlow Guide - W3cubDocs</title>
  
  <meta name="description" content="The TensorFlow layers module provides a high-level API that makes it easy to construct a neural network. It provides methods that facilitate the &hellip;">
  <meta name="keywords" content="guide, tf, layers, building, convolutional, neural, network, tensorflow, tensorflow~guide">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~guide/tutorials/layers.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-4205f3012478879f8c56fe996c2028fb79885cdfa2a555f0246a77154592eefd5cbfab91f37f1715fe7ccfe78d4f5ebf2a64b27344118d69549f74bb7bb03769.css">
  <script src="/assets/application-6642e8a44fdf75b0cdac9f6b93996611b714089b67b28678421f881289dbb80a0bed9f9975268d4499e9e1498c5157b8af1460631c66e1efd65cea387e868f4e.js" type="text/javascript"></script>
  <script src="/json/tensorflow~guide.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~guide/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Guide</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> A Guide to TF Layers: Building a Convolutional Neural Network </h1>     <p>The TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/layers"><code>layers</code> module</a> provides a high-level API that makes it easy to construct a neural network. It provides methods that facilitate the creation of dense (fully connected) layers and convolutional layers, adding activation functions, and applying dropout regularization. In this tutorial, you'll learn how to use <code>layers</code> to build a convolutional neural network model to recognize the handwritten digits in the MNIST data set.</p> <p><img alt="handwritten digits 0–9 from the MNIST data set" src="data:image/png;base64,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"></p> <p><strong>The <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> comprises 60,000 training examples and 10,000 test examples of the handwritten digits 0–9, formatted as 28x28-pixel monochrome images.</strong></p> <h2 id="getting_started">Getting Started</h2> <p>Let's set up the skeleton for our TensorFlow program. Create a file called <code>cnn_mnist.py</code>, and add the following code:</p> <pre class="prettyprint lang-python" data-language="python">from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

# Imports
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

# Our application logic will be added here

if __name__ == "__main__":
  tf.app.run()
</pre> <p>As you work through the tutorial, you'll add code to construct, train, and evaluate the convolutional neural network. The complete, final code can be <a href="https://www.github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/examples/tutorials/layers/cnn_mnist.py">found here</a>.</p> <h2 id="intro_to_convolutional_neural_networks">Intro to Convolutional Neural Networks</h2> <p>Convolutional neural networks (CNNs) are the current state-of-the-art model architecture for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains three components:</p> <ul> <li> <p><strong>Convolutional layers</strong>, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU activation function</a> to the output to introduce nonlinearities into the model.</p> </li> <li> <p><strong>Pooling layers</strong>, which <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer">downsample the image data</a> extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.</p> </li> <li> <p><strong>Dense (fully connected) layers</strong>, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.</p> </li> </ul> <p>Typically, a CNN is composed of a stack of convolutional modules that perform feature extraction. Each module consists of a convolutional layer followed by a pooling layer. The last convolutional module is followed by one or more dense layers that perform classification. The final dense layer in a CNN contains a single node for each target class in the model (all the possible classes the model may predict), with a <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> activation function to generate a value between 0–1 for each node (the sum of all these softmax values is equal to 1). We can interpret the softmax values for a given image as relative measurements of how likely it is that the image falls into each target class.</p> <blockquote> <strong>Note:</strong><span> For a more comprehensive walkthrough of CNN architecture, see Stanford University's <a href="https://cs231n.github.io/convolutional-networks/"> Convolutional Neural Networks for Visual Recognition course materials</a>.</span> </blockquote> <h2 id="building_the_cnn_mnist_classifier">Building the CNN MNIST Classifier</h2> <p>Let's build a model to classify the images in the MNIST dataset using the following CNN architecture:</p> <ol> <li>
<strong>Convolutional Layer #1</strong>: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function</li> <li>
<strong>Pooling Layer #1</strong>: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)</li> <li>
<strong>Convolutional Layer #2</strong>: Applies 64 5x5 filters, with ReLU activation function</li> <li>
<strong>Pooling Layer #2</strong>: Again, performs max pooling with a 2x2 filter and stride of 2</li> <li>
<strong>Dense Layer #1</strong>: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)</li> <li>
<strong>Dense Layer #2 (Logits Layer)</strong>: 10 neurons, one for each digit target class (0–9).</li> </ol> <p>The <a href="https://www.tensorflow.org/api_docs/python/tf/layers"><code>tf.layers</code></a> module contains methods to create each of the three layer types above:</p> <ul> <li>
<code>conv2d()</code>. Constructs a two-dimensional convolutional layer. Takes number of filters, filter kernel size, padding, and activation function as arguments.</li> <li>
<code>max_pooling2d()</code>. Constructs a two-dimensional pooling layer using the max-pooling algorithm. Takes pooling filter size and stride as arguments.</li> <li>
<code>dense()</code>. Constructs a dense layer. Takes number of neurons and activation function as arguments.</li> </ul> <p>Each of these methods accepts a tensor as input and returns a transformed tensor as output. This makes it easy to connect one layer to another: just take the output from one layer-creation method and supply it as input to another.</p> <p>Open <code>cnn_mnist.py</code> and add the following <code>cnn_model_fn</code> function, which conforms to the interface expected by TensorFlow's Estimator API (more on this later in <a href="#create_the_estimator">Create the Estimator</a>). <code>cnn_mnist.py</code> takes MNIST feature data, labels, and <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys">model mode</a> (<code>TRAIN</code>, <code>EVAL</code>, <code>PREDICT</code>) as arguments; configures the CNN; and returns predictions, loss, and a training operation:</p> <pre class="prettyprint lang-python" data-language="python">def cnn_model_fn(features, labels, mode):
  """Model function for CNN."""
  # Input Layer
  input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

  # Convolutional Layer #1
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)

  # Pooling Layer #1
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

  # Convolutional Layer #2 and Pooling Layer #2
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

  # Dense Layer
  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
  dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

  # Logits Layer
  logits = tf.layers.dense(inputs=dropout, units=10)

  predictions = {
      # Generate predictions (for PREDICT and EVAL mode)
      "classes": tf.argmax(input=logits, axis=1),
      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
      # `logging_hook`.
      "probabilities": tf.nn.softmax(logits, name="softmax_tensor")
  }

  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  # Calculate Loss (for both TRAIN and EVAL modes)
  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

  # Configure the Training Op (for TRAIN mode)
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

  # Add evaluation metrics (for EVAL mode)
  eval_metric_ops = {
      "accuracy": tf.metrics.accuracy(
          labels=labels, predictions=predictions["classes"])}
  return tf.estimator.EstimatorSpec(
      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
</pre> <p>The following sections (with headings corresponding to each code block above) dive deeper into the <a href="https://www.tensorflow.org/api_docs/python/tf/layers"><code>tf.layers</code></a> code used to create each layer, as well as how to calculate loss, configure the training op, and generate predictions. If you're already experienced with CNNs and <a href="../get_started/custom_estimators">TensorFlow <code>Estimator</code>s</a>, and find the above code intuitive, you may want to skim these sections or just skip ahead to <a href="#training_and_evaluating_the_cnn_mnist_classifier">"Training and Evaluating the CNN MNIST Classifier"</a>.</p> <h3 id="input_layer">Input Layer</h3> <p>The methods in the <code>layers</code> module for creating convolutional and pooling layers for two-dimensional image data expect input tensors to have a shape of <code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>, <em>channels</em>]</code> by default. This behavior can be changed using the <code><em>data_format</em></code> parameter; defined as follows:</p> <ul> <li>
<em><code>batch_size</code></em>. Size of the subset of examples to use when performing gradient descent during training.</li> <li>
<em><code>image_height</code></em>. Height of the example images.</li> <li>
<em><code>image_width</code></em>. Width of the example images.</li> <li>
<em><code>channels</code></em>. Number of color channels in the example images. For color images, the number of channels is 3 (red, green, blue). For monochrome images, there is just 1 channel (black).</li> <li>
<em><code>image_height</code></em>. Height of the example images.</li> <li>
<em><code>data_format</code></em>. A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. <code>channels_last</code> corresponds to inputs with shape <code>(batch, ..., channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, ...)</code>.</li> </ul> <p>Here, our MNIST dataset is composed of monochrome 28x28 pixel images, so the desired shape for our input layer is <code>[<em>batch_size</em>, 28, 28, 1]</code>.</p> <p>To convert our input feature map (<code>features</code>) to this shape, we can perform the following <code>reshape</code> operation:</p> <pre class="prettyprint lang-python" data-language="python">input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])
</pre> <p>Note that we've indicated <code>-1</code> for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in <code>features["x"]</code>, holding the size of all other dimensions constant. This allows us to treat <code>batch_size</code> as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, <code>features["x"]</code> will contain 3,920 values (one value for each pixel in each image), and <code>input_layer</code> will have a shape of <code>[5, 28, 28, 1]</code>. Similarly, if we feed examples in batches of 100, <code>features["x"]</code> will contain 78,400 values, and <code>input_layer</code> will have a shape of <code>[100, 28, 28, 1]</code>.</p> <h3 id="convolutional_layer_1">Convolutional Layer #1</h3> <p>In our first convolutional layer, we want to apply 32 5x5 filters to the input layer, with a ReLU activation function. We can use the <code>conv2d()</code> method in the <code>layers</code> module to create this layer as follows:</p> <pre class="prettyprint lang-python" data-language="python">conv1 = tf.layers.conv2d(
    inputs=input_layer,
    filters=32,
    kernel_size=[5, 5],
    padding="same",
    activation=tf.nn.relu)
</pre> <p>The <code>inputs</code> argument specifies our input tensor, which must have the shape <code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>, <em>channels</em>]</code>. Here, we're connecting our first convolutional layer to <code>input_layer</code>, which has the shape <code>[<em>batch_size</em>, 28, 28, 1]</code>.</p> <blockquote> <strong>Note:</strong><span> <code>conv2d()</code> will instead accept a shape of <code>[<em>batch_size</em>, <em>channels</em>, <em>image_height</em>, <em>image_width</em>]</code> when passed the argument <code>data_format=channels_first</code>.</span> </blockquote> <p>The <code>filters</code> argument specifies the number of filters to apply (here, 32), and <code>kernel_size</code> specifies the dimensions of the filters as <code>[<em>height</em>, <em>width</em>]</code> (here, <code>[5, 5]</code>).</p> <p class="tip"><b>TIP:</b> If filter height and width have the same value, you can instead specify a single integer for <code>kernel_size</code>—e.g., <code>kernel_size=5</code>.</p> <p>The <code>padding</code> argument specifies one of two enumerated values (case-insensitive): <code>valid</code> (default value) or <code>same</code>. To specify that the output tensor should have the same height and width values as the input tensor, we set <code>padding=same</code> here, which instructs TensorFlow to add 0 values to the edges of the input tensor to preserve height and width of 28. (Without padding, a 5x5 convolution over a 28x28 tensor will produce a 24x24 tensor, as there are 24x24 locations to extract a 5x5 tile from a 28x28 grid.)</p> <p>The <code>activation</code> argument specifies the activation function to apply to the output of the convolution. Here, we specify ReLU activation with <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu"><code>tf.nn.relu</code></a>.</p> <p>Our output tensor produced by <code>conv2d()</code> has a shape of <code>[<em>batch_size</em>, 28, 28, 32]</code>: the same height and width dimensions as the input, but now with 32 channels holding the output from each of the filters.</p> <h3 id="pooling_layer_1">Pooling Layer #1</h3> <p>Next, we connect our first pooling layer to the convolutional layer we just created. We can use the <code>max_pooling2d()</code> method in <code>layers</code> to construct a layer that performs max pooling with a 2x2 filter and stride of 2:</p> <pre class="prettyprint lang-python" data-language="python">pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
</pre> <p>Again, <code>inputs</code> specifies the input tensor, with a shape of <code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>, <em>channels</em>]</code>. Here, our input tensor is <code>conv1</code>, the output from the first convolutional layer, which has a shape of <code>[<em>batch_size</em>, 28, 28, 32]</code>.</p> <blockquote> <strong>Note:</strong><span> As with <code>conv2d()</code>, <code>max_pooling2d()</code> will instead accept a shape of <code>[<em>batch_size</em>, <em>channels</em>, <em>image_height</em>, <em>image_width</em>]</code> when passed the argument <code>data_format=channels_first</code>.</span> </blockquote> <p>The <code>pool_size</code> argument specifies the size of the max pooling filter as <code>[<em>height</em>, <em>width</em>]</code> (here, <code>[2, 2]</code>). If both dimensions have the same value, you can instead specify a single integer (e.g., <code>pool_size=2</code>).</p> <p>The <code>strides</code> argument specifies the size of the stride. Here, we set a stride of 2, which indicates that the subregions extracted by the filter should be separated by 2 pixels in both the height and width dimensions (for a 2x2 filter, this means that none of the regions extracted will overlap). If you want to set different stride values for height and width, you can instead specify a tuple or list (e.g., <code>stride=[3, 6]</code>).</p> <p>Our output tensor produced by <code>max_pooling2d()</code> (<code>pool1</code>) has a shape of <code>[<em>batch_size</em>, 14, 14, 32]</code>: the 2x2 filter reduces height and width by 50% each.</p> <h3 id="convolutional_layer_2_and_pooling_layer_2">Convolutional Layer #2 and Pooling Layer #2</h3> <p>We can connect a second convolutional and pooling layer to our CNN using <code>conv2d()</code> and <code>max_pooling2d()</code> as before. For convolutional layer #2, we configure 64 5x5 filters with ReLU activation, and for pooling layer #2, we use the same specs as pooling layer #1 (a 2x2 max pooling filter with stride of 2):</p> <pre class="prettyprint lang-python" data-language="python">conv2 = tf.layers.conv2d(
    inputs=pool1,
    filters=64,
    kernel_size=[5, 5],
    padding="same",
    activation=tf.nn.relu)

pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
</pre> <p>Note that convolutional layer #2 takes the output tensor of our first pooling layer (<code>pool1</code>) as input, and produces the tensor <code>conv2</code> as output. <code>conv2</code> has a shape of <code>[<em>batch_size</em>, 14, 14, 64]</code>, the same height and width as <code>pool1</code> (due to <code>padding="same"</code>), and 64 channels for the 64 filters applied.</p> <p>Pooling layer #2 takes <code>conv2</code> as input, producing <code>pool2</code> as output. <code>pool2</code> has shape <code>[<em>batch_size</em>, 7, 7, 64]</code> (50% reduction of height and width from <code>conv2</code>).</p> <h3 id="dense_layer">Dense Layer</h3> <p>Next, we want to add a dense layer (with 1,024 neurons and ReLU activation) to our CNN to perform classification on the features extracted by the convolution/pooling layers. Before we connect the layer, however, we'll flatten our feature map (<code>pool2</code>) to shape <code>[<em>batch_size</em>, <em>features</em>]</code>, so that our tensor has only two dimensions:</p> <pre class="prettyprint lang-python" data-language="python">pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
</pre> <p>In the <code>reshape()</code> operation above, the <code>-1</code> signifies that the <em><code>batch_size</code></em> dimension will be dynamically calculated based on the number of examples in our input data. Each example has 7 (<code>pool2</code> height) * 7 (<code>pool2</code> width) * 64 (<code>pool2</code> channels) features, so we want the <code>features</code> dimension to have a value of 7 * 7 * 64 (3136 in total). The output tensor, <code>pool2_flat</code>, has shape <code>[<em>batch_size</em>, 3136]</code>.</p> <p>Now, we can use the <code>dense()</code> method in <code>layers</code> to connect our dense layer as follows:</p> <pre class="prettyprint lang-python" data-language="python">dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
</pre> <p>The <code>inputs</code> argument specifies the input tensor: our flattened feature map, <code>pool2_flat</code>. The <code>units</code> argument specifies the number of neurons in the dense layer (1,024). The <code>activation</code> argument takes the activation function; again, we'll use <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu"><code>tf.nn.relu</code></a> to add ReLU activation.</p> <p>To help improve the results of our model, we also apply dropout regularization to our dense layer, using the <code>dropout</code> method in <code>layers</code>:</p> <pre class="prettyprint lang-python" data-language="python">dropout = tf.layers.dropout(
    inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
</pre> <p>Again, <code>inputs</code> specifies the input tensor, which is the output tensor from our dense layer (<code>dense</code>).</p> <p>The <code>rate</code> argument specifies the dropout rate; here, we use <code>0.4</code>, which means 40% of the elements will be randomly dropped out during training.</p> <p>The <code>training</code> argument takes a boolean specifying whether or not the model is currently being run in training mode; dropout will only be performed if <code>training</code> is <code>True</code>. Here, we check if the <code>mode</code> passed to our model function <code>cnn_model_fn</code> is <code>TRAIN</code> mode.</p> <p>Our output tensor <code>dropout</code> has shape <code>[<em>batch_size</em>, 1024]</code>.</p> <h3 id="logits_layer">Logits Layer</h3> <p>The final layer in our neural network is the logits layer, which will return the raw values for our predictions. We create a dense layer with 10 neurons (one for each target class 0–9), with linear activation (the default):</p> <pre class="prettyprint lang-python" data-language="python">logits = tf.layers.dense(inputs=dropout, units=10)
</pre> <p>Our final output tensor of the CNN, <code>logits</code>, has shape <code>[<em>batch_size</em>, 10]</code>.</p> <h3 id="generate_predictions">Generate Predictions</h3> <p>The logits layer of our model returns our predictions as raw values in a <code>[<em>batch_size</em>, 10]</code>-dimensional tensor. Let's convert these raw values into two different formats that our model function can return:</p> <ul> <li>The <strong>predicted class</strong> for each example: a digit from 0–9.</li> <li>The <strong>probabilities</strong> for each possible target class for each example: the probability that the example is a 0, is a 1, is a 2, etc.</li> </ul> <p>For a given example, our predicted class is the element in the corresponding row of the logits tensor with the highest raw value. We can find the index of this element using the <a href="https://www.tensorflow.org/api_docs/python/tf/argmax"><code>tf.argmax</code></a> function:</p> <pre class="prettyprint lang-python" data-language="python">tf.argmax(input=logits, axis=1)
</pre> <p>The <code>input</code> argument specifies the tensor from which to extract maximum values—here <code>logits</code>. The <code>axis</code> argument specifies the axis of the <code>input</code> tensor along which to find the greatest value. Here, we want to find the largest value along the dimension with index of 1, which corresponds to our predictions (recall that our logits tensor has shape <code>[<em>batch_size</em>, 10]</code>).</p> <p>We can derive probabilities from our logits layer by applying softmax activation using <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax"><code>tf.nn.softmax</code></a>:</p> <pre class="prettyprint lang-python" data-language="python">tf.nn.softmax(logits, name="softmax_tensor")
</pre> <blockquote> <strong>Note:</strong><span> We use the <code>name</code> argument to explicitly name this operation <code>softmax_tensor</code>, so we can reference it later. (We'll set up logging for the softmax values in <a href="#set_up_a_logging_hook">"Set Up a Logging Hook"</a>).</span> </blockquote> <p>We compile our predictions in a dict, and return an <code>EstimatorSpec</code> object:</p> <pre class="prettyprint lang-python" data-language="python">predictions = {
    "classes": tf.argmax(input=logits, axis=1),
    "probabilities": tf.nn.softmax(logits, name="softmax_tensor")
}
if mode == tf.estimator.ModeKeys.PREDICT:
  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)
</pre> <h3 id="calculate_loss">Calculate Loss</h3> <p>For both training and evaluation, we need to define a <a href="https://en.wikipedia.org/wiki/Loss_function">loss function</a> that measures how closely the model's predictions match the target classes. For multiclass classification problems like MNIST, <a href="https://en.wikipedia.org/wiki/Cross_entropy">cross entropy</a> is typically used as the loss metric. The following code calculates cross entropy when the model runs in either <code>TRAIN</code> or <code>EVAL</code> mode:</p> <pre class="prettyprint lang-python" data-language="python">onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
loss = tf.losses.softmax_cross_entropy(
    onehot_labels=onehot_labels, logits=logits)
</pre> <p>Let's take a closer look at what's happening above.</p> <p>Our <code>labels</code> tensor contains a list of predictions for our examples, e.g. <code>[1, 9, ...]</code>. In order to calculate cross-entropy, first we need to convert <code>labels</code> to the corresponding <a href="https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science">one-hot encoding</a>:</p> <pre class="prettyprint lang-none" data-language="cpp">[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
 ...]
</pre> <p>We use the <a href="https://www.tensorflow.org/api_docs/python/tf/one_hot"><code>tf.one_hot</code></a> function to perform this conversion. <code>tf.one_hot()</code> has two required arguments:</p> <ul> <li>
<code>indices</code>. The locations in the one-hot tensor that will have "on values"—i.e., the locations of <code>1</code> values in the tensor shown above.</li> <li>
<code>depth</code>. The depth of the one-hot tensor—i.e., the number of target classes. Here, the depth is <code>10</code>.</li> </ul> <p>The following code creates the one-hot tensor for our labels, <code>onehot_labels</code>:</p> <pre class="prettyprint lang-python" data-language="python">onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
</pre> <p>Because <code>labels</code> contains a series of values from 0–9, <code>indices</code> is just our <code>labels</code> tensor, with values cast to integers. The <code>depth</code> is <code>10</code> because we have 10 possible target classes, one for each digit.</p> <p>Next, we compute cross-entropy of <code>onehot_labels</code> and the softmax of the predictions from our logits layer. <code>tf.losses.softmax_cross_entropy()</code> takes <code>onehot_labels</code> and <code>logits</code> as arguments, performs softmax activation on <code>logits</code>, calculates cross-entropy, and returns our <code>loss</code> as a scalar <code>Tensor</code>:</p> <pre class="prettyprint lang-python" data-language="python">loss = tf.losses.softmax_cross_entropy(
    onehot_labels=onehot_labels, logits=logits)
</pre> <h3 id="configure_the_training_op">Configure the Training Op</h3> <p>In the previous section, we defined loss for our CNN as the softmax cross-entropy of the logits layer and our labels. Let's configure our model to optimize this loss value during training. We'll use a learning rate of 0.001 and <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> as the optimization algorithm:</p> <pre class="prettyprint lang-python" data-language="python">if mode == tf.estimator.ModeKeys.TRAIN:
  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
  train_op = optimizer.minimize(
      loss=loss,
      global_step=tf.train.get_global_step())
  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
</pre> <blockquote> <strong>Note:</strong><span> For a more in-depth look at configuring training ops for Estimator model functions, see <a href="../get_started/custom_estimators#defining_the_training_op_for_the_model">"Defining the training op for the model"</a> in the <a href="../get_started/custom_estimators">"Creating Estimators in tf.estimator."</a> tutorial.</span> </blockquote> <h3 id="add_evaluation_metrics">Add evaluation metrics</h3> <p>To add accuracy metric in our model, we define <code>eval_metric_ops</code> dict in EVAL mode as follows:</p> <pre class="prettyprint lang-python" data-language="python">eval_metric_ops = {
    "accuracy": tf.metrics.accuracy(
        labels=labels, predictions=predictions["classes"])}
return tf.estimator.EstimatorSpec(
    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
</pre> <h2 id="training_and_evaluating_the_cnn_mnist_classifier">Training and Evaluating the CNN MNIST Classifier</h2> <p>We've coded our MNIST CNN model function; now we're ready to train and evaluate it.</p> <h3 id="load_training_and_test_data">Load Training and Test Data</h3> <p>First, let's load our training and test data. Add a <code>main()</code> function to <code>cnn_mnist.py</code> with the following code:</p> <pre class="prettyprint lang-python" data-language="python">def main(unused_argv):
  # Load training and eval data
  mnist = tf.contrib.learn.datasets.load_dataset("mnist")
  train_data = mnist.train.images # Returns np.array
  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
  eval_data = mnist.test.images # Returns np.array
  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
</pre> <p>We store the training feature data (the raw pixel values for 55,000 images of hand-drawn digits) and training labels (the corresponding value from 0–9 for each image) as <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html">numpy arrays</a> in <code>train_data</code> and <code>train_labels</code>, respectively. Similarly, we store the evaluation feature data (10,000 images) and evaluation labels in <code>eval_data</code> and <code>eval_labels</code>, respectively.</p> <h3 id="create_the_estimator">Create the Estimator</h3> <p>Next, let's create an <code>Estimator</code> (a TensorFlow class for performing high-level model training, evaluation, and inference) for our model. Add the following code to <code>main()</code>:</p> <pre class="prettyprint lang-python" data-language="python"># Create the Estimator
mnist_classifier = tf.estimator.Estimator(
    model_fn=cnn_model_fn, model_dir="/tmp/mnist_convnet_model")
</pre> <p>The <code>model_fn</code> argument specifies the model function to use for training, evaluation, and prediction; we pass it the <code>cnn_model_fn</code> we created in <a href="#building_the_cnn_mnist_classifier">"Building the CNN MNIST Classifier."</a> The <code>model_dir</code> argument specifies the directory where model data (checkpoints) will be saved (here, we specify the temp directory <code>/tmp/mnist_convnet_model</code>, but feel free to change to another directory of your choice).</p> <blockquote> <strong>Note:</strong><span> For an in-depth walkthrough of the TensorFlow <code>Estimator</code> API, see the tutorial <a href="../get_started/custom_estimators">"Creating Estimators in tf.estimator."</a></span> </blockquote> <h3 id="set_up_a_logging_hook">Set Up a Logging Hook</h3> <p>Since CNNs can take a while to train, let's set up some logging so we can track progress during training. We can use TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook"><code>tf.train.SessionRunHook</code></a> to create a <a href="https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook"><code>tf.train.LoggingTensorHook</code></a> that will log the probability values from the softmax layer of our CNN. Add the following to <code>main()</code>:</p> <pre class="prettyprint lang-python" data-language="python"># Set up logging for predictions
  tensors_to_log = {"probabilities": "softmax_tensor"}
  logging_hook = tf.train.LoggingTensorHook(
      tensors=tensors_to_log, every_n_iter=50)
</pre> <p>We store a dict of the tensors we want to log in <code>tensors_to_log</code>. Each key is a label of our choice that will be printed in the log output, and the corresponding label is the name of a <code>Tensor</code> in the TensorFlow graph. Here, our <code>probabilities</code> can be found in <code>softmax_tensor</code>, the name we gave our softmax operation earlier when we generated the probabilities in <code>cnn_model_fn</code>.</p> <blockquote> <strong>Note:</strong><span> If you don't explicitly assign a name to an operation via the <code>name</code> argument, TensorFlow will assign a default name. A couple easy ways to discover the names applied to operations are to visualize your graph on <a href="../programmers_guide/graph_viz">TensorBoard</a>) or to enable the <a href="../programmers_guide/debugger">TensorFlow Debugger (tfdbg)</a>.</span> </blockquote> <p>Next, we create the <code>LoggingTensorHook</code>, passing <code>tensors_to_log</code> to the <code>tensors</code> argument. We set <code>every_n_iter=50</code>, which specifies that probabilities should be logged after every 50 steps of training.</p> <h3 id="train_the_model">Train the Model</h3> <p>Now we're ready to train our model, which we can do by creating <code>train_input_fn</code> and calling <code>train()</code> on <code>mnist_classifier</code>. Add the following to <code>main()</code>:</p> <pre class="prettyprint lang-python" data-language="python"># Train the model
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": train_data},
    y=train_labels,
    batch_size=100,
    num_epochs=None,
    shuffle=True)
mnist_classifier.train(
    input_fn=train_input_fn,
    steps=20000,
    hooks=[logging_hook])
</pre> <p>In the <code>numpy_input_fn</code> call, we pass the training feature data and labels to <code>x</code> (as a dict) and <code>y</code>, respectively. We set a <code>batch_size</code> of <code>100</code> (which means that the model will train on minibatches of 100 examples at each step). <code>num_epochs=None</code> means that the model will train until the specified number of steps is reached. We also set <code>shuffle=True</code> to shuffle the training data. In the <code>train</code> call, we set <code>steps=20000</code> (which means the model will train for 20,000 steps total). We pass our <code>logging_hook</code> to the <code>hooks</code> argument, so that it will be triggered during training.</p> <h3 id="evaluate_the_model">Evaluate the Model</h3> <p>Once training is complete, we want to evaluate our model to determine its accuracy on the MNIST test set. We call the <code>evaluate</code> method, which evaluates the metrics we specified in <code>eval_metric_ops</code> argument in the <code>model_fn</code>. Add the following to <code>main()</code>:</p> <pre class="prettyprint lang-python" data-language="python"># Evaluate the model and print results
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": eval_data},
    y=eval_labels,
    num_epochs=1,
    shuffle=False)
eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
print(eval_results)
</pre> <p>To create <code>eval_input_fn</code>, we set <code>num_epochs=1</code>, so that the model evaluates the metrics over one epoch of data and returns the result. We also set <code>shuffle=False</code> to iterate through the data sequentially.</p> <h3 id="run_the_model">Run the Model</h3> <p>We've coded the CNN model function, <code>Estimator</code>, and the training/evaluation logic; now let's see the results. Run <code>cnn_mnist.py</code>.</p> <blockquote> <strong>Note:</strong><span> Training CNNs is quite computationally intensive. Estimated completion time of <code>cnn_mnist.py</code> will vary depending on your processor, but will likely be upwards of 1 hour on CPU. To train more quickly, you can decrease the number of <code>steps</code> passed to <code>train()</code>, but note that this will affect accuracy.</span> </blockquote> <p>As the model trains, you'll see log output like the following:</p> <pre class="prettyprint lang-python" data-language="python">INFO:tensorflow:loss = 2.36026, step = 1
INFO:tensorflow:probabilities = [[ 0.07722801  0.08618255  0.09256398, ...]]
...
INFO:tensorflow:loss = 2.13119, step = 101
INFO:tensorflow:global_step/sec: 5.44132
...
INFO:tensorflow:Loss for final step: 0.553216.

INFO:tensorflow:Restored model from /tmp/mnist_convnet_model
INFO:tensorflow:Eval steps [0,inf) for training step 20000.
INFO:tensorflow:Input iterator is exhausted.
INFO:tensorflow:Saving evaluation summary for step 20000: accuracy = 0.9733, loss = 0.0902271
{'loss': 0.090227105, 'global_step': 20000, 'accuracy': 0.97329998}
</pre> <p>Here, we've achieved an accuracy of 97.3% on our test data set.</p> <h2 id="additional_resources">Additional Resources</h2> <p>To learn more about TensorFlow Estimators and CNNs in TensorFlow, see the following resources:</p> <ul> <li>
<a href="../get_started/custom_estimators">Creating Estimators in tf.estimator</a> provides an introduction to the TensorFlow Estimator API. It walks through configuring an Estimator, writing a model function, calculating loss, and defining a training op.</li> <li>
<a href="deep_cnn">Convolutional Neural Networks</a> walks through how to build a MNIST CNN classification model <em>without estimators</em> using lower-level TensorFlow operations.</li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    © 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/tutorials/layers" class="_attribution-link">https://www.tensorflow.org/tutorials/layers</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
